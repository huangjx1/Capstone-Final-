{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0feb9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import re\n",
    "import optuna\n",
    "import warnings\n",
    "from optuna.samplers import TPESampler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn import metrics,linear_model\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression,Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44196547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean off the errors in seaborn and matplotlib\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1646df",
   "metadata": {},
   "source": [
    "# Using data for merged_house_data (5% removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a91f00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_house_data = pd.read_csv('./dataset_asof_051121/merged_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25e05549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9240, 45)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05384534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for the baseline RMSE score\n",
    "merged_house_data['baseline'] =merged_house_data.price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ae295591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2355449.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a random prediction by predicting all observation by the mean of my training set, ML model RMSE should be better than this baseline values\n",
    "np.round(mean_squared_error(merged_house_data['price'], merged_house_data['baseline'], squared = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7101cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project name</th>\n",
       "      <th>street name</th>\n",
       "      <th>tenure</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>price</th>\n",
       "      <th>nett price</th>\n",
       "      <th>areasq</th>\n",
       "      <th>type of area</th>\n",
       "      <th>floor level</th>\n",
       "      <th>...</th>\n",
       "      <th>postal district_26.0</th>\n",
       "      <th>postal district_27.0</th>\n",
       "      <th>postal district_28.0</th>\n",
       "      <th>type_Detached</th>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <th>type_Terrace</th>\n",
       "      <th>type of sale_New Sale</th>\n",
       "      <th>type of sale_Resale</th>\n",
       "      <th>type of sale_Sub Sale</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>PEARL ISLAND</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16550000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>8940.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.974609e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                project name   street name  tenure  no. of units  \\\n",
       "0      0  LANDED HOUSING DEVELOPMENT  PEARL ISLAND      86           1.0   \n",
       "\n",
       "        price nett price  areasq type of area floor level  ...  \\\n",
       "0  16550000.0          -  8940.0         Land           -  ...   \n",
       "\n",
       "   postal district_26.0 postal district_27.0  postal district_28.0  \\\n",
       "0                     0                    0                     0   \n",
       "\n",
       "   type_Detached  type_Semi-detached  type_Terrace  type of sale_New Sale  \\\n",
       "0              1                   0             0                      0   \n",
       "\n",
       "   type of sale_Resale  type of sale_Sub Sale      baseline  \n",
       "0                    1                      0  3.974609e+06  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d67c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the baseline column\n",
    "merged_house_data =merged_house_data.drop('baseline', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c968df4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize =(5,10))\n",
    "sns.heatmap(merged_house_data.corr()[['price']].sort_values('price', ascending =False), annot=True, vmin = -1, vmax = 1, cmap = 'coolwarm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46756b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8a1f9",
   "metadata": {},
   "source": [
    "### Linear Regression for this data set (5% removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "72fa3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_house_data.drop(columns =['price', 'unit price psf', 'index', 'project name', 'street name', 'nett price', 'type of area','floor level','date of sale',])\n",
    "y = merged_house_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf4b8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f2377",
   "metadata": {},
   "source": [
    "### Using Standardscalar as values in the features have huge values apart, dummified and exact interger values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9ea96dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bae062a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "lr = LinearRegression()\n",
    "#fit using the training data\n",
    "lr.fit(Z_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b59eac",
   "metadata": {},
   "source": [
    "### Doing a check on the MSE/RMSE on between the train and the predicted values from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd60618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_train = lr.predict(Z_train)\n",
    "#print(\"MSE IS {}\".format(int(metrics.mean_squared_error(y_train, y_pred_train))))\n",
    "#print(\"The RSME IS {}\".format(int(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train)))))\n",
    "# The ML model is doing better than the baseline RMSE of 2355449.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "009d7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(model,X_train,X_test, y_train, y_test, title):\n",
    "    print(title)\n",
    "    \n",
    "    print('\\nBaseline Score RMSE is 2355449')\n",
    "    #Training Score\n",
    "    print('\\nTrain Score')\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    train_mse = int(metrics.mean_squared_error(y_train, y_pred_train))\n",
    "    train_rmse = int(np.sqrt(metrics.mean_squared_error(y_train, y_pred_train)))\n",
    "    print(\"MSE IS {}\".format(train_mse))\n",
    "    print(\"RSME IS {}\".format(train_rmse))\n",
    "    \n",
    "    #Test Score\n",
    "    print('\\nTest')\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_mse = int(metrics.mean_squared_error(y_test, y_pred_test))\n",
    "    test_rmse = int(np.sqrt(metrics.mean_squared_error(y_test, y_pred_test)))\n",
    "    \n",
    "    print(\"MSE IS {}\".format(test_mse))\n",
    "    print(\"RSME IS {}\".format(test_rmse))\n",
    "    \n",
    "    #%percentage difference\n",
    "    print(('\\nTrain Test % Difference'))\n",
    "    print(f'{round((test_rmse - train_rmse)/test_rmse * 100,2)}%')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da783ab",
   "metadata": {},
   "source": [
    "### Compare with Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e4e8af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Model Train Test & Baseline Score\n",
      "\n",
      "Baseline Score RMSE is 2355449\n",
      "\n",
      "Train Score\n",
      "MSE IS 887612997079\n",
      "RSME IS 942132\n",
      "\n",
      "Test\n",
      "MSE IS 1009026734401\n",
      "RSME IS 1004503\n",
      "\n",
      "Train Test % Difference\n",
      "6.21%\n"
     ]
    }
   ],
   "source": [
    "print_result(model=lr,\n",
    "            X_train = Z_train,\n",
    "             X_test = Z_test,\n",
    "             y_train = y_train,\n",
    "             y_test = y_test,\n",
    "            title='Comparison of Model Train Test & Baseline Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f65e7d",
   "metadata": {},
   "source": [
    "### Compare with test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f83f90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score\n",
      "MSE IS 1009026734401\n",
      "RSME IS 1004503\n"
     ]
    }
   ],
   "source": [
    "#print_result(model=lr,\n",
    "             #y_actual = y_test,\n",
    "            #X=Z_test,\n",
    "            #title='Test Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "190cc7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008977094445.178\n",
      "1004478.5186579044\n"
     ]
    }
   ],
   "source": [
    "#y_pred_test = lr.predict(Z_test)\n",
    "#print(metrics.mean_squared_error(y_test, y_pred_test))\n",
    "#print(np.sqrt(metrics.mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a722483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = np.sqrt(metrics.mean_squared_error(y_train, y_pred_train))\n",
    "#b = np.sqrt(metrics.mean_squared_error(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86a25292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.206587778720262"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#(b - a)/b *100\n",
    "# 6% error ovefitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46ae74",
   "metadata": {},
   "source": [
    "Overfitting from linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c216fb8",
   "metadata": {},
   "source": [
    "## Using Lasso Regression to penalize the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "529857db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State the parameters you want to search for lasso regularisation\n",
    "# we want to go through 10000, 50000, 100000 different alpha values\n",
    "parameters = {\n",
    "                'alpha': [10000, 50000, 100000]\n",
    "             }\n",
    "\n",
    "# Instantiate the model\n",
    "lasso = Lasso()\n",
    "\n",
    "# Instantiate Gridsearch (use previous instantiated parameters and model)\n",
    "lasso_lr = GridSearchCV(lasso, parameters, \n",
    "                     scoring='neg_mean_squared_error', \n",
    "                     cv=5, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "08f5b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "lasso_lr.fit(Z_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0c325caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10000}\n"
     ]
    }
   ],
   "source": [
    "print(lasso_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "41c29ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = linear_model.Lasso(alpha = 10000, max_iter=10000000, tol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "450a18fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10000, max_iter=10000000, tol=0.1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d90837",
   "metadata": {},
   "source": [
    "### Doing a check on the MSE/RMSE on between the train and the predicted values from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "92a3cc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Model Train Test & Baseline Score\n",
      "\n",
      "Baseline Score RMSE is 2355449\n",
      "\n",
      "Train Score\n",
      "MSE IS 910663332604\n",
      "RSME IS 954286\n",
      "\n",
      "Test\n",
      "MSE IS 1028266666030\n",
      "RSME IS 1014034\n",
      "\n",
      "Train Test % Difference\n",
      "5.89%\n"
     ]
    }
   ],
   "source": [
    "print_result(model=lasso_reg,\n",
    "            X_train = Z_train,\n",
    "             X_test = Z_test,\n",
    "             y_train = y_train,\n",
    "             y_test = y_test,\n",
    "            title='Comparison of Model Train Test & Baseline Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "68d963d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910567356891.2185\n",
      "954236.5308932678\n"
     ]
    }
   ],
   "source": [
    "y_pred_lasso_train =lasso_reg.predict(Z_train)\n",
    "print(metrics.mean_squared_error(y_train, y_pred_lasso_train))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_train, y_pred_lasso_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cff1f7",
   "metadata": {},
   "source": [
    "### Compare with test and test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2331f9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027649467295.3228\n",
      "1013730.4707343677\n"
     ]
    }
   ],
   "source": [
    "y_pred_lasso_test =lasso_reg.predict(Z_test)\n",
    "print(metrics.mean_squared_error(y_test, y_pred_lasso_test))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred_lasso_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1bb79c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.868812426837799"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1013730.4707343677 - 954236.5308932678)/1013730.4707343677 *100\n",
    "#Lasso is still overfitted\n",
    "# A reduction of only 0.4% , this may indicates that another regressor model is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daaed0c",
   "metadata": {},
   "source": [
    "### To check for colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb2eb06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>areasq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.107167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no. of units</th>\n",
       "      <td>0.008888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>areasq</th>\n",
       "      <td>0.107167</td>\n",
       "      <td>0.082425</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tenure  no. of units    areasq\n",
       "tenure        1.000000      0.008888  0.107167\n",
       "no. of units  0.008888      1.000000  0.082425\n",
       "areasq        0.107167      0.082425  1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house_data[['tenure', 'no. of units','areasq']].corr()\n",
    "#There is not much corelation between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41f21c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>areasq</th>\n",
       "      <th>type_Detached</th>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <th>type_Terrace</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.107167</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>-0.032755</td>\n",
       "      <td>0.217158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no. of units</th>\n",
       "      <td>0.008888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082425</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>-0.007891</td>\n",
       "      <td>0.061880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>areasq</th>\n",
       "      <td>0.107167</td>\n",
       "      <td>0.082425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722404</td>\n",
       "      <td>0.147510</td>\n",
       "      <td>-0.600283</td>\n",
       "      <td>0.809494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_Detached</th>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>0.722404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.237468</td>\n",
       "      <td>-0.417887</td>\n",
       "      <td>0.677885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <td>0.005661</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>0.147510</td>\n",
       "      <td>-0.237468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.783277</td>\n",
       "      <td>0.118857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_Terrace</th>\n",
       "      <td>-0.032755</td>\n",
       "      <td>-0.007891</td>\n",
       "      <td>-0.600283</td>\n",
       "      <td>-0.417887</td>\n",
       "      <td>-0.783277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.544994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.217158</td>\n",
       "      <td>0.061880</td>\n",
       "      <td>0.809494</td>\n",
       "      <td>0.677885</td>\n",
       "      <td>0.118857</td>\n",
       "      <td>-0.544994</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tenure  no. of units    areasq  type_Detached  \\\n",
       "tenure              1.000000      0.008888  0.107167       0.042907   \n",
       "no. of units        0.008888      1.000000  0.082425       0.015809   \n",
       "areasq              0.107167      0.082425  1.000000       0.722404   \n",
       "type_Detached       0.042907      0.015809  0.722404       1.000000   \n",
       "type_Semi-detached  0.005661     -0.002381  0.147510      -0.237468   \n",
       "type_Terrace       -0.032755     -0.007891 -0.600283      -0.417887   \n",
       "price               0.217158      0.061880  0.809494       0.677885   \n",
       "\n",
       "                    type_Semi-detached  type_Terrace     price  \n",
       "tenure                        0.005661     -0.032755  0.217158  \n",
       "no. of units                 -0.002381     -0.007891  0.061880  \n",
       "areasq                        0.147510     -0.600283  0.809494  \n",
       "type_Detached                -0.237468     -0.417887  0.677885  \n",
       "type_Semi-detached            1.000000     -0.783277  0.118857  \n",
       "type_Terrace                 -0.783277      1.000000 -0.544994  \n",
       "price                         0.118857     -0.544994  1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house_data[['tenure', 'no. of units','areasq','type_Detached', 'type_Semi-detached','type_Terrace','price']].corr()\n",
    "# Area sq is the most related to the price of the houses, we can see under type_detached that is also related, \n",
    "# the ascending classification of grade of houses should be terrace, semi-detached follwoed by detached, these features should be included during feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db91de6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market segment_CCR</th>\n",
       "      <th>market segment_OCR</th>\n",
       "      <th>market segment_RCR</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>market segment_CCR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.567501</td>\n",
       "      <td>-0.183527</td>\n",
       "      <td>0.506760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market segment_OCR</th>\n",
       "      <td>-0.567501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.705236</td>\n",
       "      <td>-0.367331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market segment_RCR</th>\n",
       "      <td>-0.183527</td>\n",
       "      <td>-0.705236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.506760</td>\n",
       "      <td>-0.367331</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    market segment_CCR  market segment_OCR  \\\n",
       "market segment_CCR            1.000000           -0.567501   \n",
       "market segment_OCR           -0.567501            1.000000   \n",
       "market segment_RCR           -0.183527           -0.705236   \n",
       "price                         0.506760           -0.367331   \n",
       "\n",
       "                    market segment_RCR     price  \n",
       "market segment_CCR           -0.183527  0.506760  \n",
       "market segment_OCR           -0.705236 -0.367331  \n",
       "market segment_RCR            1.000000  0.002202  \n",
       "price                         0.002202  1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house_data[['market segment_CCR', 'market segment_OCR','market segment_RCR', 'price']].corr()\n",
    "#OCR seems to be slightly co-related to RCR, this is expected as CCR and RCR prices will fetch more, however for RCR, there is not much co -relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22413b3c",
   "metadata": {},
   "source": [
    "### Next, when performing linear regression, we need to check for multi- regression assumptions\n",
    "\n",
    "Linearity: The mean values of the outcome variable for each increment of the predictor(s) lie along a straight line. In other words, there is a linear relationship between predictors and target.\n",
    "\n",
    "No perfect multicollinearity: There should be no perfect linear relationship between two or more of the predictors.\n",
    "\n",
    "Normally distributed errors: the residuals are random, normally distributed with a mean of 0.\n",
    "\n",
    "Homoscedasticity: The variance of the residual terms should be constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "775e0bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Refit selected lasso model\n",
    "y_pred_lasso_test =lasso_reg.predict(Z_test)\n",
    "\n",
    "# Visualizing actual prices vs predicted values\n",
    "plt.scatter(y_test, y_pred_lasso_test)\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Actual Cost Price vs Predicted Cost Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "128dc3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Residual vs fit plot\n",
    "plt.scatter(y_pred_lasso_test, y_test - y_pred_lasso_test)\n",
    "plt.title(\"Residual vs Fit Plot\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09791d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The linear regression model\n",
    "#We can see that there is an increase variance when as the predicted value increase, this suggest that the relationship is not linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25baf02a",
   "metadata": {},
   "source": [
    "### Using XGboost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b9e62ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "45d34946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-23 10:49:31,675]\u001b[0m A new study created in memory with name: no-name-09f64d4e-2493-4782-9abb-4191cd617cfa\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:32,345]\u001b[0m Trial 0 finished with value: -933604.5129993318 and parameters: {'colsample_bytree': 0.4370861069626263, 'learning_rate': 0.9556428757689246, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 131, 'reg_lambda': 3.6303224667798554e-07, 'reg_alpha': 3.809220577048033e-08, 'sub_sample': 0.8795585311974417}. Best is trial 0 with value: -933604.5129993318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:32,701]\u001b[0m Trial 1 finished with value: -978713.780035497 and parameters: {'colsample_bytree': 0.6410035105688879, 'learning_rate': 0.737265320016441, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 267, 'reg_lambda': 1.3285903900544182e-06, 'reg_alpha': 6.580360277501306e-07, 'sub_sample': 0.2650640588680905}. Best is trial 0 with value: -933604.5129993318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:33,258]\u001b[0m Trial 2 finished with value: -868643.7285992067 and parameters: {'colsample_bytree': 0.373818018663584, 'learning_rate': 0.5722807884690141, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 222, 'reg_lambda': 2.4827821051950883e-07, 'reg_alpha': 8.345387083873532e-06, 'sub_sample': 0.4297256589643226}. Best is trial 2 with value: -868643.7285992067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:33,598]\u001b[0m Trial 3 finished with value: -979473.8533597025 and parameters: {'colsample_bytree': 0.5104629857953323, 'learning_rate': 0.8066583652537123, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 219, 'reg_lambda': 2.9140978279786215e-08, 'reg_alpha': 0.011897302909454906, 'sub_sample': 0.2534717113185624}. Best is trial 2 with value: -868643.7285992067.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:34,139]\u001b[0m Trial 4 finished with value: -917207.9046466653 and parameters: {'colsample_bytree': 0.1585464336867516, 'learning_rate': 0.9539969835279999, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 161, 'reg_lambda': 9.478096804784244e-08, 'reg_alpha': 0.06955530592645753, 'sub_sample': 0.4961372443656412}. Best is trial 2 with value: -868643.7285992067.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:34,454]\u001b[0m Trial 5 finished with value: -1033995.7439450198 and parameters: {'colsample_bytree': 0.20983441136030095, 'learning_rate': 0.5456592191001431, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 152, 'reg_lambda': 0.042191293826476094, 'reg_alpha': 1.3095158546031483e-05, 'sub_sample': 0.5680612190600297}. Best is trial 2 with value: -868643.7285992067.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:35,248]\u001b[0m Trial 6 finished with value: -850336.4319451274 and parameters: {'colsample_bytree': 0.5920392514089517, 'learning_rate': 0.26636900997297436, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 288, 'reg_lambda': 8.8771488946556, 'reg_alpha': 0.00952795699161383, 'sub_sample': 0.9296868115208051}. Best is trial 6 with value: -850336.4319451274.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:35,544]\u001b[0m Trial 7 finished with value: -1057856.6774464229 and parameters: {'colsample_bytree': 0.17964325184672755, 'learning_rate': 0.27638457617723067, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 178, 'reg_lambda': 5.169997317292732e-06, 'reg_alpha': 1.9380951355796903, 'sub_sample': 0.4210779940242304}. Best is trial 6 with value: -850336.4319451274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:35,874]\u001b[0m Trial 8 finished with value: -1001126.2471982015 and parameters: {'colsample_bytree': 0.3528410587186427, 'learning_rate': 0.5884264748424236, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 114, 'reg_lambda': 73.9382838287635, 'reg_alpha': 0.5277736371601186, 'sub_sample': 0.2788441133807552}. Best is trial 6 with value: -850336.4319451274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:36,304]\u001b[0m Trial 9 finished with value: -939351.9399541861 and parameters: {'colsample_bytree': 0.10496990541124217, 'learning_rate': 0.8339152856093507, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 255, 'reg_lambda': 5.50106171658889e-08, 'reg_alpha': 3.842884090673403e-05, 'sub_sample': 0.20428215357261675}. Best is trial 6 with value: -850336.4319451274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:37,277]\u001b[0m Trial 10 finished with value: -849885.6094177031 and parameters: {'colsample_bytree': 0.9497157666716347, 'learning_rate': 0.10539746466023536, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 297, 'reg_lambda': 11.930206277066471, 'reg_alpha': 39.6011191452442, 'sub_sample': 0.9790910709802578}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:38,650]\u001b[0m Trial 11 finished with value: -872247.1994947452 and parameters: {'colsample_bytree': 0.9522656887511342, 'learning_rate': 0.10326321505087403, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 82.82843195255043, 'reg_alpha': 73.24607527580478, 'sub_sample': 0.971643831619738}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:39,738]\u001b[0m Trial 12 finished with value: -853797.9927695193 and parameters: {'colsample_bytree': 0.9925005566564994, 'learning_rate': 0.10376349477481495, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 0.5154377331302434, 'reg_alpha': 90.4650741825025, 'sub_sample': 0.7633847055950665}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:40,679]\u001b[0m Trial 13 finished with value: -859213.0736580251 and parameters: {'colsample_bytree': 0.7310463358543839, 'learning_rate': 0.31176902969578846, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 256, 'reg_lambda': 0.7443377343642432, 'reg_alpha': 0.0006426234450833537, 'sub_sample': 0.7339148735304308}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:41,332]\u001b[0m Trial 14 finished with value: -853116.1554908588 and parameters: {'colsample_bytree': 0.8333053471044078, 'learning_rate': 0.26682484317247296, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 275, 'reg_lambda': 0.0014616829044245118, 'reg_alpha': 0.004929458493315183, 'sub_sample': 0.9964152904250921}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:42,131]\u001b[0m Trial 15 finished with value: -861179.6201430622 and parameters: {'colsample_bytree': 0.8218224088720183, 'learning_rate': 0.37686433229944233, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 232, 'reg_lambda': 2.8786246481953217, 'reg_alpha': 3.0431882979437432, 'sub_sample': 0.7851478927791123}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:42,618]\u001b[0m Trial 16 finished with value: -879939.8742530901 and parameters: {'colsample_bytree': 0.631019612870097, 'learning_rate': 0.18997714992008555, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 300, 'reg_lambda': 0.006685114074448871, 'reg_alpha': 0.001254938913499503, 'sub_sample': 0.6755216196437899}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:43,609]\u001b[0m Trial 17 finished with value: -897489.564408676 and parameters: {'colsample_bytree': 0.8555853425344547, 'learning_rate': 0.3819631408644582, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 192, 'reg_lambda': 7.721327045288563e-05, 'reg_alpha': 0.09682723982480992, 'sub_sample': 0.8786200034493581}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:44,590]\u001b[0m Trial 18 finished with value: -863896.1925703008 and parameters: {'colsample_bytree': 0.648062452359644, 'learning_rate': 0.4874068746132497, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 237, 'reg_lambda': 10.57856263862654, 'reg_alpha': 11.21066879773542, 'sub_sample': 0.8741985610125552}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:45,375]\u001b[0m Trial 19 finished with value: -878379.1626898763 and parameters: {'colsample_bytree': 0.7569125565135283, 'learning_rate': 0.18270204876571042, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 277, 'reg_lambda': 0.04063362854387539, 'reg_alpha': 0.0001608332737138239, 'sub_sample': 0.6327832920564574}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:46,296]\u001b[0m Trial 20 finished with value: -870587.9400937082 and parameters: {'colsample_bytree': 0.5152419744027459, 'learning_rate': 0.4587664824783376, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 244, 'reg_lambda': 6.512840564702056e-05, 'reg_alpha': 0.1561394389960054, 'sub_sample': 0.9422418277221798}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:47,269]\u001b[0m Trial 21 finished with value: -861148.9392899129 and parameters: {'colsample_bytree': 0.9021335114379557, 'learning_rate': 0.22814339467809336, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 276, 'reg_lambda': 0.0018857090553590263, 'reg_alpha': 0.011939414825319683, 'sub_sample': 0.9914943215365554}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:48,042]\u001b[0m Trial 22 finished with value: -850910.4824991694 and parameters: {'colsample_bytree': 0.760951959930388, 'learning_rate': 0.35016411236168055, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 278, 'reg_lambda': 0.3113554476014648, 'reg_alpha': 0.005430396954125455, 'sub_sample': 0.8189167041371102}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:48,629]\u001b[0m Trial 23 finished with value: -873613.3264974303 and parameters: {'colsample_bytree': 0.7468655799630234, 'learning_rate': 0.3519266214685217, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 287, 'reg_lambda': 9.314791988008906, 'reg_alpha': 4.1752770154213754e-07, 'sub_sample': 0.8207526281801711}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:49,298]\u001b[0m Trial 24 finished with value: -853859.6211840309 and parameters: {'colsample_bytree': 0.6865648725563052, 'learning_rate': 0.1625757180336071, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 260, 'reg_lambda': 0.18939806457497166, 'reg_alpha': 0.000432850173469886, 'sub_sample': 0.9065335144189295}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:50,019]\u001b[0m Trial 25 finished with value: -860085.7064730952 and parameters: {'colsample_bytree': 0.5951690040447837, 'learning_rate': 0.43994010348418594, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 202, 'reg_lambda': 4.7697414720168085, 'reg_alpha': 0.004120315562433079, 'sub_sample': 0.831024415005845}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:50,994]\u001b[0m Trial 26 finished with value: -859440.3934779894 and parameters: {'colsample_bytree': 0.9125553024888383, 'learning_rate': 0.23940932236056786, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 284, 'reg_lambda': 0.060710522429045045, 'reg_alpha': 11.841817624351407, 'sub_sample': 0.700545475199338}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:51,626]\u001b[0m Trial 27 finished with value: -859714.5869510613 and parameters: {'colsample_bytree': 0.8126140610927197, 'learning_rate': 0.32094635743890687, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 300, 'reg_lambda': 19.40568992459695, 'reg_alpha': 0.039246135778984524, 'sub_sample': 0.6014961801127194}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:52,169]\u001b[0m Trial 28 finished with value: -883144.846022419 and parameters: {'colsample_bytree': 0.9870517963846744, 'learning_rate': 0.1562730832803332, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 246, 'reg_lambda': 1.5675000125495413, 'reg_alpha': 0.5876206357100467, 'sub_sample': 0.9165735761298702}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:52,833]\u001b[0m Trial 29 finished with value: -888855.6573717515 and parameters: {'colsample_bytree': 0.43366190791100945, 'learning_rate': 0.6401427485130929, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 267, 'reg_lambda': 0.19065749193856238, 'reg_alpha': 7.685598825469086e-05, 'sub_sample': 0.8486176681656262}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:53,713]\u001b[0m Trial 30 finished with value: -881451.3975011207 and parameters: {'colsample_bytree': 0.9073533849881921, 'learning_rate': 0.4134473069506087, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 211, 'reg_lambda': 0.009781281194707928, 'reg_alpha': 2.67578861029397e-08, 'sub_sample': 0.7902449048597063}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:54,449]\u001b[0m Trial 31 finished with value: -854484.620086489 and parameters: {'colsample_bytree': 0.8187658316426017, 'learning_rate': 0.2707216050047674, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 278, 'reg_lambda': 0.0005769682595963247, 'reg_alpha': 0.0032791092447550236, 'sub_sample': 0.9972904027418773}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:55,118]\u001b[0m Trial 32 finished with value: -857210.3435435556 and parameters: {'colsample_bytree': 0.5670128916957982, 'learning_rate': 0.2969001412673752, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 267, 'reg_lambda': 0.0003237472906068104, 'reg_alpha': 0.014361204686808017, 'sub_sample': 0.9309861095940098}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:55,650]\u001b[0m Trial 33 finished with value: -883902.5771603817 and parameters: {'colsample_bytree': 0.8643776355674103, 'learning_rate': 0.2176521467414675, 'max_depth': 2, 'min_child_weight': 5, 'n_estimators': 285, 'reg_lambda': 0.29309572182689814, 'reg_alpha': 0.002655768495937925, 'sub_sample': 0.9459759109279896}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:56,280]\u001b[0m Trial 34 finished with value: -885933.9109489475 and parameters: {'colsample_bytree': 0.7198790966445354, 'learning_rate': 0.12042542219348114, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 271, 'reg_lambda': 23.761152781455745, 'reg_alpha': 4.000496867675905e-07, 'sub_sample': 0.873967900526285}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:57,213]\u001b[0m Trial 35 finished with value: -856232.8622702719 and parameters: {'colsample_bytree': 0.7788086802617232, 'learning_rate': 0.2552986187872246, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 287, 'reg_lambda': 8.54765955684409e-06, 'reg_alpha': 3.908524239774264e-06, 'sub_sample': 0.9949665906036286}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:57,780]\u001b[0m Trial 36 finished with value: -862971.8249988769 and parameters: {'colsample_bytree': 0.45675831928276905, 'learning_rate': 0.5047350001515383, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 252, 'reg_lambda': 1.3660821314636955, 'reg_alpha': 0.00021880105565647132, 'sub_sample': 0.9154497718976886}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:58,408]\u001b[0m Trial 37 finished with value: -857594.6740584483 and parameters: {'colsample_bytree': 0.6725656225861563, 'learning_rate': 0.32899829146626075, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 227, 'reg_lambda': 0.0049021836730544326, 'reg_alpha': 0.20602602846100132, 'sub_sample': 0.7272245623004943}. Best is trial 10 with value: -849885.6094177031.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:49:59,261]\u001b[0m Trial 38 finished with value: -848349.4155767377 and parameters: {'colsample_bytree': 0.9429719796217397, 'learning_rate': 0.14791434498713293, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 137, 'reg_lambda': 1.0633582693547669e-08, 'reg_alpha': 0.016661351376777527, 'sub_sample': 0.8257424230499745}. Best is trial 38 with value: -848349.4155767377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:49:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:00,560]\u001b[0m Trial 39 finished with value: -849685.5131695659 and parameters: {'colsample_bytree': 0.9456196477232659, 'learning_rate': 0.16317398088920498, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 123, 'reg_lambda': 3.8049235109997783e-07, 'reg_alpha': 0.03370478819469885, 'sub_sample': 0.5074573538514838}. Best is trial 38 with value: -848349.4155767377.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:01,425]\u001b[0m Trial 40 finished with value: -840014.2346011804 and parameters: {'colsample_bytree': 0.32593518880607525, 'learning_rate': 0.14342882354385297, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 1.7516411422696726e-08, 'reg_alpha': 0.0346549711566849, 'sub_sample': 0.47861838878245666}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:02,291]\u001b[0m Trial 41 finished with value: -851678.2798004003 and parameters: {'colsample_bytree': 0.27784655445800777, 'learning_rate': 0.14660819492151034, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 106, 'reg_lambda': 1.3557201098474209e-08, 'reg_alpha': 0.02621056936960869, 'sub_sample': 0.47141311614161757}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:03,209]\u001b[0m Trial 42 finished with value: -849687.1373787988 and parameters: {'colsample_bytree': 0.2880290281290438, 'learning_rate': 0.20469220774889646, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 136, 'reg_lambda': 5.240265172827261e-07, 'reg_alpha': 0.5500770539623833, 'sub_sample': 0.39881750543587347}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:04,019]\u001b[0m Trial 43 finished with value: -850968.5650700657 and parameters: {'colsample_bytree': 0.3492523474871984, 'learning_rate': 0.19407438811833233, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 134, 'reg_lambda': 3.3270765612803325e-07, 'reg_alpha': 0.6186348534073025, 'sub_sample': 0.32678997348366295}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:04,777]\u001b[0m Trial 44 finished with value: -871812.5952648129 and parameters: {'colsample_bytree': 0.2598363130494557, 'learning_rate': 0.14206835683933042, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 128, 'reg_lambda': 1.2727766343793787e-06, 'reg_alpha': 3.996655610998242, 'sub_sample': 0.39955325151193216}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:05,500]\u001b[0m Trial 45 finished with value: -850090.3840029478 and parameters: {'colsample_bytree': 0.2910006553602151, 'learning_rate': 0.20540338634190555, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 153, 'reg_lambda': 1.4615305459519362e-07, 'reg_alpha': 21.787148223974647, 'sub_sample': 0.5106119373019417}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:06,607]\u001b[0m Trial 46 finished with value: -847246.9650323575 and parameters: {'colsample_bytree': 0.9406891715287105, 'learning_rate': 0.10603891330103432, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 123, 'reg_lambda': 3.4550482577130415e-08, 'reg_alpha': 1.14261431668746, 'sub_sample': 0.387315665322435}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:07,138]\u001b[0m Trial 47 finished with value: -931155.7586050391 and parameters: {'colsample_bytree': 0.12966813026391757, 'learning_rate': 0.6682957987608801, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 122, 'reg_lambda': 3.513600386631378e-08, 'reg_alpha': 1.22366847870634, 'sub_sample': 0.36933265452249525}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:07,765]\u001b[0m Trial 48 finished with value: -919901.4666575693 and parameters: {'colsample_bytree': 0.21394516427357552, 'learning_rate': 0.8789897792548713, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 1.1376783540416763e-08, 'reg_alpha': 0.27407640765572944, 'sub_sample': 0.4534015807900504}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:08,464]\u001b[0m Trial 49 finished with value: -856430.333503685 and parameters: {'colsample_bytree': 0.40191847621008014, 'learning_rate': 0.10362084911739708, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 139, 'reg_lambda': 9.364404674614759e-07, 'reg_alpha': 0.07131965572746683, 'sub_sample': 0.1141213361004021}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:09,471]\u001b[0m Trial 50 finished with value: -1024018.6423646904 and parameters: {'colsample_bytree': 0.9438958871069105, 'learning_rate': 0.9889298712426184, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 143, 'reg_lambda': 9.404589677408855e-08, 'reg_alpha': 1.3005212476878765, 'sub_sample': 0.5692060173074528}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:10,741]\u001b[0m Trial 51 finished with value: -847896.9082081899 and parameters: {'colsample_bytree': 0.9982538704126143, 'learning_rate': 0.13745004410934433, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 168, 'reg_lambda': 4.084558650750156e-06, 'reg_alpha': 5.717926711169839, 'sub_sample': 0.5334880040406572}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:11,879]\u001b[0m Trial 52 finished with value: -850289.1164954068 and parameters: {'colsample_bytree': 0.9973790849247497, 'learning_rate': 0.16896486732635888, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 170, 'reg_lambda': 6.769387240782398e-06, 'reg_alpha': 7.132161258071792, 'sub_sample': 0.5106856656548119}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:13,018]\u001b[0m Trial 53 finished with value: -850265.3361851744 and parameters: {'colsample_bytree': 0.9647913047248675, 'learning_rate': 0.1318592334024617, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 116, 'reg_lambda': 7.038412088982518e-07, 'reg_alpha': 0.040697860334303435, 'sub_sample': 0.33567488875964374}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:14,093]\u001b[0m Trial 54 finished with value: -859533.9914257624 and parameters: {'colsample_bytree': 0.8838304703664892, 'learning_rate': 0.22983224239306788, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 152, 'reg_lambda': 3.4443505883696464e-06, 'reg_alpha': 0.37453258378388854, 'sub_sample': 0.5400371661676006}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:15,058]\u001b[0m Trial 55 finished with value: -856468.6262702501 and parameters: {'colsample_bytree': 0.9195091995586185, 'learning_rate': 0.1010496181947293, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 115, 'reg_lambda': 2.8691431007165155e-08, 'reg_alpha': 0.102066435628553, 'sub_sample': 0.4155699131386561}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:15,853]\u001b[0m Trial 56 finished with value: -840797.5181051306 and parameters: {'colsample_bytree': 0.3340324546963965, 'learning_rate': 0.18759447558653553, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 163, 'reg_lambda': 1.871833826281045e-07, 'reg_alpha': 2.1754594179838405, 'sub_sample': 0.4642360008108475}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:16,647]\u001b[0m Trial 57 finished with value: -849161.3257521008 and parameters: {'colsample_bytree': 0.322814908816876, 'learning_rate': 0.17007054686937678, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 180, 'reg_lambda': 1.5619766161736086e-07, 'reg_alpha': 3.235486571913685, 'sub_sample': 0.6352208702928722}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:17,281]\u001b[0m Trial 58 finished with value: -847574.1177815609 and parameters: {'colsample_bytree': 0.3501958387712163, 'learning_rate': 0.29015195947828243, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 183, 'reg_lambda': 1.4521618881376553e-07, 'reg_alpha': 37.2957199593608, 'sub_sample': 0.6023184654123228}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:17,879]\u001b[0m Trial 59 finished with value: -849299.9172936088 and parameters: {'colsample_bytree': 0.22267184547657376, 'learning_rate': 0.2539989411407583, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 172, 'reg_lambda': 7.066809123863163e-08, 'reg_alpha': 37.26772194397352, 'sub_sample': 0.46548795909608753}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:18,624]\u001b[0m Trial 60 finished with value: -851517.0508383447 and parameters: {'colsample_bytree': 0.4918827294912599, 'learning_rate': 0.3016994175927608, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 160, 'reg_lambda': 3.17317612888863e-08, 'reg_alpha': 99.30737706781157, 'sub_sample': 0.5493243273662904}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:19,370]\u001b[0m Trial 61 finished with value: -840086.2923016989 and parameters: {'colsample_bytree': 0.349043540380784, 'learning_rate': 0.13715637568888134, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 185, 'reg_lambda': 1.9504758243061297e-07, 'reg_alpha': 5.9159474683604945, 'sub_sample': 0.641530166491843}. Best is trial 40 with value: -840014.2346011804.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:20,184]\u001b[0m Trial 62 finished with value: -835667.9807935274 and parameters: {'colsample_bytree': 0.38958081503943176, 'learning_rate': 0.14197157528731996, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 187, 'reg_lambda': 2.62467011479093e-06, 'reg_alpha': 25.92288653756792, 'sub_sample': 0.6400506533046643}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:20,953]\u001b[0m Trial 63 finished with value: -842069.4618075297 and parameters: {'colsample_bytree': 0.3835000083152824, 'learning_rate': 0.13301425308437634, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 187, 'reg_lambda': 1.6252143111300042e-05, 'reg_alpha': 28.94456656494736, 'sub_sample': 0.6472814754798574}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:21,781]\u001b[0m Trial 64 finished with value: -836071.1588512062 and parameters: {'colsample_bytree': 0.3803937998243614, 'learning_rate': 0.19196411080359183, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 188, 'reg_lambda': 3.0828161691818026e-05, 'reg_alpha': 17.220528577309903, 'sub_sample': 0.638863246737833}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:22,696]\u001b[0m Trial 65 finished with value: -840095.669893529 and parameters: {'colsample_bytree': 0.3881740342095872, 'learning_rate': 0.1971799775938494, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 191, 'reg_lambda': 3.3211895841828864e-05, 'reg_alpha': 17.499031034243714, 'sub_sample': 0.6688614645112708}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:23,549]\u001b[0m Trial 66 finished with value: -839819.5427799865 and parameters: {'colsample_bytree': 0.39476873575747606, 'learning_rate': 0.19735177801763074, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 190, 'reg_lambda': 2.7391072326569422e-05, 'reg_alpha': 12.487654843419445, 'sub_sample': 0.6646195011904967}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:24,344]\u001b[0m Trial 67 finished with value: -841309.3154578104 and parameters: {'colsample_bytree': 0.4132325811334903, 'learning_rate': 0.20131491481402167, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 196, 'reg_lambda': 3.136563546223413e-05, 'reg_alpha': 14.83825088439452, 'sub_sample': 0.6759346622431275}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:25,171]\u001b[0m Trial 68 finished with value: -846413.019041068 and parameters: {'colsample_bytree': 0.31904063461917, 'learning_rate': 0.22065440558652474, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 206, 'reg_lambda': 0.00016691322139710234, 'reg_alpha': 8.825823000718811, 'sub_sample': 0.5903995413348228}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:26,320]\u001b[0m Trial 69 finished with value: -843001.540978693 and parameters: {'colsample_bytree': 0.46544775838675617, 'learning_rate': 0.24185609601859226, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 216, 'reg_lambda': 1.7619869439890266e-06, 'reg_alpha': 1.8277934114020198, 'sub_sample': 0.7266494933610681}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:27,240]\u001b[0m Trial 70 finished with value: -840724.9109858122 and parameters: {'colsample_bytree': 0.3769269304802029, 'learning_rate': 0.18852812721082965, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 194, 'reg_lambda': 7.640082976895373e-05, 'reg_alpha': 54.2331561549723, 'sub_sample': 0.6689142548725034}. Best is trial 62 with value: -835667.9807935274.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:28,125]\u001b[0m Trial 71 finished with value: -835435.462389064 and parameters: {'colsample_bytree': 0.36993289113758815, 'learning_rate': 0.18709104537817253, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 191, 'reg_lambda': 7.25022822441453e-05, 'reg_alpha': 63.05257416973543, 'sub_sample': 0.6702958065423423}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:28,996]\u001b[0m Trial 72 finished with value: -842619.9437187692 and parameters: {'colsample_bytree': 0.3808225418212142, 'learning_rate': 0.18483520764376177, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 191, 'reg_lambda': 2.710058599893938e-05, 'reg_alpha': 57.040755529604645, 'sub_sample': 0.6739051136463026}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:29,933]\u001b[0m Trial 73 finished with value: -925797.0155335417 and parameters: {'colsample_bytree': 0.4201431954806512, 'learning_rate': 0.7680083583928295, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 203, 'reg_lambda': 0.00012073919000810564, 'reg_alpha': 20.44096177424103, 'sub_sample': 0.7675711556282396}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:30,789]\u001b[0m Trial 74 finished with value: -850108.1546928483 and parameters: {'colsample_bytree': 0.5253482100465505, 'learning_rate': 0.26546209962739337, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 196, 'reg_lambda': 4.522513649862285e-05, 'reg_alpha': 68.27056591352785, 'sub_sample': 0.6953171395842258}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:31,643]\u001b[0m Trial 75 finished with value: -849356.1651666526 and parameters: {'colsample_bytree': 0.4546949500399662, 'learning_rate': 0.22446992358610454, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 208, 'reg_lambda': 1.761822955608531e-05, 'reg_alpha': 12.133462856549752, 'sub_sample': 0.6238763244848792}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:32,353]\u001b[0m Trial 76 finished with value: -852886.2319657373 and parameters: {'colsample_bytree': 0.24724177530601613, 'learning_rate': 0.17378525821500926, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 178, 'reg_lambda': 0.0003035300474614267, 'reg_alpha': 6.519409238303068, 'sub_sample': 0.6498023041798887}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:33,088]\u001b[0m Trial 77 finished with value: -849411.3046788435 and parameters: {'colsample_bytree': 0.3728626663160079, 'learning_rate': 0.2757809047826258, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 215, 'reg_lambda': 1.056307129289005e-05, 'reg_alpha': 21.506554124062735, 'sub_sample': 0.7036103962958326}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:33,440]\u001b[0m Trial 78 finished with value: -989030.9611067952 and parameters: {'colsample_bytree': 0.3080393277001519, 'learning_rate': 0.3443057664791289, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 188, 'reg_lambda': 0.00015063468834810797, 'reg_alpha': 46.61742400090293, 'sub_sample': 0.574407759455137}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:34,183]\u001b[0m Trial 79 finished with value: -872739.3852806506 and parameters: {'colsample_bytree': 0.396281455146019, 'learning_rate': 0.38080327716634077, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 198, 'reg_lambda': 8.349928726412714e-05, 'reg_alpha': 98.00965141642808, 'sub_sample': 0.6621379624413001}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:34,920]\u001b[0m Trial 80 finished with value: -836870.7673010372 and parameters: {'colsample_bytree': 0.3634504466403665, 'learning_rate': 0.15667528699590616, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 225, 'reg_lambda': 0.0016197285930556957, 'reg_alpha': 5.275782643879852, 'sub_sample': 0.7550352432794472}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:35,668]\u001b[0m Trial 81 finished with value: -840325.5040318305 and parameters: {'colsample_bytree': 0.3678686906425734, 'learning_rate': 0.12553162373975765, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 226, 'reg_lambda': 0.0007639457912204907, 'reg_alpha': 4.268579640178395, 'sub_sample': 0.6156520165782347}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:36,464]\u001b[0m Trial 82 finished with value: -843787.0473883192 and parameters: {'colsample_bytree': 0.43487465473329623, 'learning_rate': 0.12528006784567955, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 223, 'reg_lambda': 0.002433905907188659, 'reg_alpha': 4.0786073250136985, 'sub_sample': 0.6189391564426932}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:37,319]\u001b[0m Trial 83 finished with value: -845071.8534384443 and parameters: {'colsample_bytree': 0.4862261122831246, 'learning_rate': 0.1585743972021953, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 238, 'reg_lambda': 0.0012926661698442494, 'reg_alpha': 12.861427071019127, 'sub_sample': 0.7524725630001406}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:38,088]\u001b[0m Trial 84 finished with value: -846084.3951651702 and parameters: {'colsample_bytree': 0.3562314089881858, 'learning_rate': 0.1258727432887996, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 231, 'reg_lambda': 0.0007620854999886365, 'reg_alpha': 5.08255972673019, 'sub_sample': 0.6961783790365859}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:38,863]\u001b[0m Trial 85 finished with value: -847857.157958766 and parameters: {'colsample_bytree': 0.3405266232730697, 'learning_rate': 0.2107353255481477, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 176, 'reg_lambda': 0.00027824493254090775, 'reg_alpha': 2.414964163991971, 'sub_sample': 0.7421643852917159}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:39,572]\u001b[0m Trial 86 finished with value: -837553.375152185 and parameters: {'colsample_bytree': 0.3063237566182409, 'learning_rate': 0.2412520783083662, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 183, 'reg_lambda': 0.004164858362739354, 'reg_alpha': 19.029918065727518, 'sub_sample': 0.7940039806336713}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:40,249]\u001b[0m Trial 87 finished with value: -841787.9468553071 and parameters: {'colsample_bytree': 0.2960664794028056, 'learning_rate': 0.23673721548892926, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 184, 'reg_lambda': 2.688491475426996e-06, 'reg_alpha': 23.676552697557977, 'sub_sample': 0.7968702767005553}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:40,958]\u001b[0m Trial 88 finished with value: -861974.1948039688 and parameters: {'colsample_bytree': 0.2642356776844134, 'learning_rate': 0.1485264780512362, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 201, 'reg_lambda': 0.018766026480470894, 'reg_alpha': 9.372020087531974, 'sub_sample': 0.7142935770563855}. Best is trial 71 with value: -835435.462389064.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:41,823]\u001b[0m Trial 89 finished with value: -835048.0970795677 and parameters: {'colsample_bytree': 0.41729770786409115, 'learning_rate': 0.1732201343588914, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 190, 'reg_lambda': 0.012391878335439522, 'reg_alpha': 16.60003639874413, 'sub_sample': 0.5854985553746755}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:42,477]\u001b[0m Trial 90 finished with value: -907419.4419920794 and parameters: {'colsample_bytree': 0.16616013999499782, 'learning_rate': 0.16951893724465586, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 176, 'reg_lambda': 0.0032866486376368132, 'reg_alpha': 35.24965855673304, 'sub_sample': 0.7716479976591245}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10:50:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:43,326]\u001b[0m Trial 91 finished with value: -849722.2936156829 and parameters: {'colsample_bytree': 0.42839365101985616, 'learning_rate': 0.20438967654712462, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 188, 'reg_lambda': 0.016160643441833242, 'reg_alpha': 0.8496740299060046, 'sub_sample': 0.5874910334576514}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:44,083]\u001b[0m Trial 92 finished with value: -838140.9518063859 and parameters: {'colsample_bytree': 0.39570701791777324, 'learning_rate': 0.15644993794169193, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 212, 'reg_lambda': 0.056224520008442996, 'reg_alpha': 16.887706604966766, 'sub_sample': 0.6873475080079128}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10:50:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:44,811]\u001b[0m Trial 93 finished with value: -845416.0484738682 and parameters: {'colsample_bytree': 0.3146721232003952, 'learning_rate': 0.24629945987267812, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 212, 'reg_lambda': 0.07875532292520213, 'reg_alpha': 8.277344316540107, 'sub_sample': 0.6343339548616503}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:45,613]\u001b[0m Trial 94 finished with value: -837956.662342025 and parameters: {'colsample_bytree': 0.41031316160915066, 'learning_rate': 0.15283658025559155, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 206, 'reg_lambda': 0.00641334971147872, 'reg_alpha': 12.433747179093496, 'sub_sample': 0.807137460217868}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:46,401]\u001b[0m Trial 95 finished with value: -844846.6883273707 and parameters: {'colsample_bytree': 0.4466235978718227, 'learning_rate': 0.15728850172422235, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 217, 'reg_lambda': 0.02646143038911205, 'reg_alpha': 29.980003593447332, 'sub_sample': 0.8582076839002771}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:47,153]\u001b[0m Trial 96 finished with value: -898611.8892037662 and parameters: {'colsample_bytree': 0.40211698860148365, 'learning_rate': 0.5782608738927675, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 208, 'reg_lambda': 0.0077834199115423405, 'reg_alpha': 63.95868591197468, 'sub_sample': 0.8152359337816617}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:48,018]\u001b[0m Trial 97 finished with value: -843174.0142499147 and parameters: {'colsample_bytree': 0.46967465232540806, 'learning_rate': 0.11500316964659688, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 204, 'reg_lambda': 0.10237005576744435, 'reg_alpha': 1.1499345093543288e-08, 'sub_sample': 0.735496876376619}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:48,835]\u001b[0m Trial 98 finished with value: -840919.8181276774 and parameters: {'colsample_bytree': 0.4141249685734597, 'learning_rate': 0.1755525879178592, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 199, 'reg_lambda': 0.012498600569979574, 'reg_alpha': 13.920041554084419, 'sub_sample': 0.7952676776316856}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:50:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 10:50:49,542]\u001b[0m Trial 99 finished with value: -849925.1765110112 and parameters: {'colsample_bytree': 0.4860226098793851, 'learning_rate': 0.15087451072906197, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 220, 'reg_lambda': 0.003836222231361281, 'reg_alpha': 1.90674028754007, 'sub_sample': 0.4894458875342187}. Best is trial 89 with value: -835048.0970795677.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def xgb(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, Z_train, y_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "13b4aa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.41729770786409115,\n",
       " 'learning_rate': 0.1732201343588914,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 190,\n",
       " 'reg_lambda': 0.012391878335439522,\n",
       " 'reg_alpha': 16.60003639874413,\n",
       " 'sub_sample': 0.5854985553746755}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "de89492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:50:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGB = XGBRegressor(**study.best_params)\n",
    "XGB.fit(Z_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1c180011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Model Train Test & Baseline Score\n",
      "\n",
      "Baseline Score RMSE is 2355449\n",
      "\n",
      "Train Score\n",
      "MSE IS 439637625750\n",
      "RSME IS 663051\n",
      "\n",
      "Test\n",
      "MSE IS 706897397538\n",
      "RSME IS 840771\n",
      "\n",
      "Train Test % Difference\n",
      "21.14%\n"
     ]
    }
   ],
   "source": [
    "print_result(model= XGB,\n",
    "            X_train = Z_train,\n",
    "             X_test = Z_test,\n",
    "             y_train = y_train,\n",
    "             y_test = y_test,\n",
    "            title='Comparison of Model Train Test & Baseline Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef9619",
   "metadata": {},
   "source": [
    "### Comparing of train and test RMSE of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fe3dfa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482872684470.4565\n",
      "694890.4118423684\n"
     ]
    }
   ],
   "source": [
    "y_predXGB_train = XGB.predict(Z_train)\n",
    "print(metrics.mean_squared_error(y_train, y_predXGB_train))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_train, y_predXGB_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8f45d558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725582107393.9768\n",
      "851811.074942077\n"
     ]
    }
   ],
   "source": [
    "y_predXGB_test = XGB.predict(Z_test)\n",
    "print(metrics.mean_squared_error(y_test, y_predXGB_test))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_predXGB_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "478570cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.11321483143234"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(863134.2920281967- 689530.2375888029)/863134.2920281967*100\n",
    "\n",
    "# results is still overfitted, we can try randomforestregressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b941e",
   "metadata": {},
   "source": [
    "### Using RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ac3e4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a329396c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 220}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gridseach done multiple times to narrow in the best params\n",
    "rf_params = {\n",
    "    'n_estimators': [180, 200, 210, 220, 250],\n",
    "    'max_depth': [4, 7, 9, 12],\n",
    "}\n",
    "rf = GridSearchCV(rf, param_grid=rf_params, cv=5, n_jobs=-1)\n",
    "rf.fit(Z_train, y_train)\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90dffe",
   "metadata": {},
   "source": [
    "### Comparing of train and test RMSE of RFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b7b97651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Model Train Test & Baseline Score\n",
      "\n",
      "Baseline Score RMSE is 2355449\n",
      "\n",
      "Train Score\n",
      "MSE IS 439994500142\n",
      "RSME IS 663320\n",
      "\n",
      "Test\n",
      "MSE IS 789075923248\n",
      "RSME IS 888299\n",
      "\n",
      "Train Test % Difference\n",
      "25.33%\n"
     ]
    }
   ],
   "source": [
    "print_result(model= rf,\n",
    "            X_train = Z_train,\n",
    "             X_test = Z_test,\n",
    "             y_train = y_train,\n",
    "             y_test = y_test,\n",
    "            title='Comparison of Model Train Test & Baseline Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f68c00f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439913286538.65216\n",
      "663259.5921195955\n"
     ]
    }
   ],
   "source": [
    "y_pred_trainrf = gs.predict(Z_train)\n",
    "print(metrics.mean_squared_error(y_train, y_pred_trainrf))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_train, y_pred_trainrf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee220297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790225740601.689\n",
      "888946.4216710076\n"
     ]
    }
   ],
   "source": [
    "y_pred_testrf = gs.predict(Z_test)\n",
    "print(metrics.mean_squared_error(y_test, y_pred_testrf))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred_testrf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d2cf115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.38812509388076"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(888946.4216710076- 663259.5921195955)/888946.4216710076 *100\n",
    "# Randomforest is overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f005958",
   "metadata": {},
   "source": [
    "### There is overfitting in the 5% reduction of dataset. A new dataset of merged_house_10 is a 10% removal of data, to reduce more existing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf384489",
   "metadata": {},
   "source": [
    "# Using data for merged_house_10(10% removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "330db0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_house_10 = pd.read_csv('./dataset_asof_051121/merged_house_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09a55976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8753, 45)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house_10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095db110",
   "metadata": {},
   "source": [
    "### Linear Regression for this data set (10% removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1850d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X10 = merged_house_10.drop(columns =['price', 'unit price psf', 'index', 'project name', 'street name', 'nett price', 'type of area','floor level','date of sale',])\n",
    "y10 = merged_house_10['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "203057f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X10_train, X10_test, y10_train, y10_test = train_test_split(X10, y10, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8049807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z10_train = sc.fit_transform(X10_train)\n",
    "Z10_test = sc.transform(X10_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6544af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(Z10_train, y10_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca0265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639008548114.2343\n",
      "799380.1024007504\n"
     ]
    }
   ],
   "source": [
    "y10_pred_train = lr.predict(Z10_train)\n",
    "print(metrics.mean_squared_error(y10_train, y10_pred_train))\n",
    "print(np.sqrt(metrics.mean_squared_error(y10_train, y10_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90b77644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745082847995.4116\n",
      "863181.8163025746\n"
     ]
    }
   ],
   "source": [
    "y10_pred_test = lr.predict(Z10_test)\n",
    "print(metrics.mean_squared_error(y10_test, y10_pred_test))\n",
    "print(np.sqrt(metrics.mean_squared_error(y10_test, y10_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc08d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.391457129520848"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(863181.8163025746 - 799380.1024007504)/863181.8163025746* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "948a239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-23 09:32:16,768]\u001b[0m A new study created in memory with name: no-name-f895724b-5fb3-450d-8599-8c6a29d1cfb6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:17,503]\u001b[0m Trial 0 finished with value: -784072.7844767828 and parameters: {'colsample_bytree': 0.4370861069626263, 'learning_rate': 0.9556428757689246, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 131, 'reg_lambda': 3.6303224667798554e-07, 'reg_alpha': 3.809220577048033e-08, 'sub_sample': 0.8795585311974417}. Best is trial 0 with value: -784072.7844767828.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:17,884]\u001b[0m Trial 1 finished with value: -818654.1809696965 and parameters: {'colsample_bytree': 0.6410035105688879, 'learning_rate': 0.737265320016441, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 267, 'reg_lambda': 1.3285903900544182e-06, 'reg_alpha': 6.580360277501306e-07, 'sub_sample': 0.2650640588680905}. Best is trial 0 with value: -784072.7844767828.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:18,464]\u001b[0m Trial 2 finished with value: -728646.0890404525 and parameters: {'colsample_bytree': 0.373818018663584, 'learning_rate': 0.5722807884690141, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 222, 'reg_lambda': 2.4827821051950883e-07, 'reg_alpha': 8.345387083873532e-06, 'sub_sample': 0.4297256589643226}. Best is trial 2 with value: -728646.0890404525.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:18,794]\u001b[0m Trial 3 finished with value: -818397.0546939196 and parameters: {'colsample_bytree': 0.5104629857953323, 'learning_rate': 0.8066583652537123, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 219, 'reg_lambda': 2.9140978279786215e-08, 'reg_alpha': 0.011897302909454906, 'sub_sample': 0.2534717113185624}. Best is trial 2 with value: -728646.0890404525.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:19,321]\u001b[0m Trial 4 finished with value: -758982.9167986339 and parameters: {'colsample_bytree': 0.1585464336867516, 'learning_rate': 0.9539969835279999, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 161, 'reg_lambda': 9.478096804784244e-08, 'reg_alpha': 0.06955530592645753, 'sub_sample': 0.4961372443656412}. Best is trial 2 with value: -728646.0890404525.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:19,608]\u001b[0m Trial 5 finished with value: -840530.1921495466 and parameters: {'colsample_bytree': 0.20983441136030095, 'learning_rate': 0.5456592191001431, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 152, 'reg_lambda': 0.042191293826476094, 'reg_alpha': 1.3095158546031483e-05, 'sub_sample': 0.5680612190600297}. Best is trial 2 with value: -728646.0890404525.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:20,379]\u001b[0m Trial 6 finished with value: -714103.9058199228 and parameters: {'colsample_bytree': 0.5920392514089517, 'learning_rate': 0.26636900997297436, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 288, 'reg_lambda': 8.8771488946556, 'reg_alpha': 0.00952795699161383, 'sub_sample': 0.9296868115208051}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:20,664]\u001b[0m Trial 7 finished with value: -864850.6068314529 and parameters: {'colsample_bytree': 0.17964325184672755, 'learning_rate': 0.27638457617723067, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 178, 'reg_lambda': 5.169997317292732e-06, 'reg_alpha': 1.9380951355796903, 'sub_sample': 0.4210779940242304}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:20,996]\u001b[0m Trial 8 finished with value: -845397.5291248857 and parameters: {'colsample_bytree': 0.3528410587186427, 'learning_rate': 0.5884264748424236, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 114, 'reg_lambda': 73.9382838287635, 'reg_alpha': 0.5277736371601186, 'sub_sample': 0.2788441133807552}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:21,431]\u001b[0m Trial 9 finished with value: -760546.9702906192 and parameters: {'colsample_bytree': 0.10496990541124217, 'learning_rate': 0.8339152856093507, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 255, 'reg_lambda': 5.50106171658889e-08, 'reg_alpha': 3.842884090673403e-05, 'sub_sample': 0.20428215357261675}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:22,359]\u001b[0m Trial 10 finished with value: -719394.0778571428 and parameters: {'colsample_bytree': 0.9497157666716347, 'learning_rate': 0.10539746466023536, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 297, 'reg_lambda': 11.930206277066471, 'reg_alpha': 39.6011191452442, 'sub_sample': 0.9790910709802578}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:23,299]\u001b[0m Trial 11 finished with value: -742933.9267116576 and parameters: {'colsample_bytree': 0.9522656887511342, 'learning_rate': 0.10326321505087403, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 82.82843195255043, 'reg_alpha': 73.24607527580478, 'sub_sample': 0.971643831619738}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:24,183]\u001b[0m Trial 12 finished with value: -722182.1083282076 and parameters: {'colsample_bytree': 0.9925005566564994, 'learning_rate': 0.10376349477481495, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 0.5154377331302434, 'reg_alpha': 90.4650741825025, 'sub_sample': 0.7633847055950665}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:25,010]\u001b[0m Trial 13 finished with value: -719211.2007585218 and parameters: {'colsample_bytree': 0.7310463358543839, 'learning_rate': 0.31176902969578846, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 256, 'reg_lambda': 0.7443377343642432, 'reg_alpha': 0.0006426234450833537, 'sub_sample': 0.7339148735304308}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:25,596]\u001b[0m Trial 14 finished with value: -719441.0092063443 and parameters: {'colsample_bytree': 0.719809179027759, 'learning_rate': 0.34308626701128486, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 258, 'reg_lambda': 0.0008803383553892593, 'reg_alpha': 0.00041797237987258127, 'sub_sample': 0.728070572892402}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:26,301]\u001b[0m Trial 15 finished with value: -724035.3589253131 and parameters: {'colsample_bytree': 0.7701256248171731, 'learning_rate': 0.3315144570723555, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 235, 'reg_lambda': 0.3821520293152025, 'reg_alpha': 0.0009168787473854349, 'sub_sample': 0.707405080891628}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:26,772]\u001b[0m Trial 16 finished with value: -737794.4355421212 and parameters: {'colsample_bytree': 0.7925758018645216, 'learning_rate': 0.42502313336727593, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 271, 'reg_lambda': 0.0021759123045635882, 'reg_alpha': 0.006309200722510088, 'sub_sample': 0.8450085335117865}. Best is trial 6 with value: -714103.9058199228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:27,574]\u001b[0m Trial 17 finished with value: -711020.7983973032 and parameters: {'colsample_bytree': 0.6190761126749975, 'learning_rate': 0.23311013176611864, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 205, 'reg_lambda': 1.477552839171128, 'reg_alpha': 0.0001815350424081093, 'sub_sample': 0.6396767599776616}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:28,429]\u001b[0m Trial 18 finished with value: -716338.43675782 and parameters: {'colsample_bytree': 0.6273714030121061, 'learning_rate': 0.22653262599176494, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 192, 'reg_lambda': 0.0011688601937396826, 'reg_alpha': 0.05913132656838748, 'sub_sample': 0.6137505587072689}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:28,898]\u001b[0m Trial 19 finished with value: -734801.0088470019 and parameters: {'colsample_bytree': 0.5297384252729742, 'learning_rate': 0.4701211237390746, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 213, 'reg_lambda': 0.03158830044300846, 'reg_alpha': 5.439767303997955e-07, 'sub_sample': 0.8341568535785884}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:29,674]\u001b[0m Trial 20 finished with value: -712988.7527226711 and parameters: {'colsample_bytree': 0.610581223456966, 'learning_rate': 0.20077009155680958, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 186, 'reg_lambda': 5.179955919891921, 'reg_alpha': 0.00014535056444722288, 'sub_sample': 0.6314676381988852}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:30,372]\u001b[0m Trial 21 finished with value: -716518.2724142192 and parameters: {'colsample_bytree': 0.5927404078909256, 'learning_rate': 0.1986601281533134, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 187, 'reg_lambda': 7.624214029183208, 'reg_alpha': 0.00011007470807617123, 'sub_sample': 0.6592052721508062}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:31,307]\u001b[0m Trial 22 finished with value: -711957.9218625374 and parameters: {'colsample_bytree': 0.8740052460436492, 'learning_rate': 0.20087195624132467, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 163, 'reg_lambda': 5.849062655809006, 'reg_alpha': 0.005692050240835444, 'sub_sample': 0.10330266943305699}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:32,057]\u001b[0m Trial 23 finished with value: -713046.9478952147 and parameters: {'colsample_bytree': 0.8588985064001662, 'learning_rate': 0.1820552053323891, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 166, 'reg_lambda': 0.048646778682460964, 'reg_alpha': 0.00011562472513934419, 'sub_sample': 0.37669599229273165}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:33,012]\u001b[0m Trial 24 finished with value: -735530.9216957312 and parameters: {'colsample_bytree': 0.8791574386886704, 'learning_rate': 0.3910066877119638, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 140, 'reg_lambda': 1.1702793527708817, 'reg_alpha': 7.769769529988958e-07, 'sub_sample': 0.12099498395039976}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:33,821]\u001b[0m Trial 25 finished with value: -715035.4278267107 and parameters: {'colsample_bytree': 0.6912553024706534, 'learning_rate': 0.1809741429332014, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 204, 'reg_lambda': 3.501482155098672, 'reg_alpha': 4.55100455140347e-06, 'sub_sample': 0.534335728969184}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:34,620]\u001b[0m Trial 26 finished with value: -733187.4160653562 and parameters: {'colsample_bytree': 0.8458833094836274, 'learning_rate': 0.4759689604563459, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 176, 'reg_lambda': 7.92969317124111e-05, 'reg_alpha': 0.0018642191518244502, 'sub_sample': 0.630598672359805}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:35,423]\u001b[0m Trial 27 finished with value: -712025.962069206 and parameters: {'colsample_bytree': 0.4477745343002597, 'learning_rate': 0.2358271687386003, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 101, 'reg_lambda': 0.18446010771419888, 'reg_alpha': 0.09869184596800097, 'sub_sample': 0.48568697608451267}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:36,227]\u001b[0m Trial 28 finished with value: -731191.5286344042 and parameters: {'colsample_bytree': 0.4420432551377398, 'learning_rate': 0.3981212489463488, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 119, 'reg_lambda': 0.011230482845895439, 'reg_alpha': 1.2790731615724549, 'sub_sample': 0.12279573575101221}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:36,891]\u001b[0m Trial 29 finished with value: -743980.3198001765 and parameters: {'colsample_bytree': 0.3008634073330153, 'learning_rate': 0.6522212859070233, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 101, 'reg_lambda': 0.19065749193856238, 'reg_alpha': 0.07783064105923727, 'sub_sample': 0.48161045416561366}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:37,348]\u001b[0m Trial 30 finished with value: -758203.8256537801 and parameters: {'colsample_bytree': 0.4774507860553824, 'learning_rate': 0.25091855453455075, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 137, 'reg_lambda': 29.20246367905952, 'reg_alpha': 2.67578861029397e-08, 'sub_sample': 0.34747822326396505}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:37,984]\u001b[0m Trial 31 finished with value: -711893.1547433914 and parameters: {'colsample_bytree': 0.4081856898095704, 'learning_rate': 0.16603363314745873, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 234, 'reg_lambda': 1.7656510649154649, 'reg_alpha': 0.003958723959610898, 'sub_sample': 0.7962377041534477}. Best is trial 17 with value: -711020.7983973032.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:38,745]\u001b[0m Trial 32 finished with value: -710278.7815178146 and parameters: {'colsample_bytree': 0.28830056813215355, 'learning_rate': 0.16077177612715637, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 233, 'reg_lambda': 1.7809926959736633, 'reg_alpha': 0.3207554064251109, 'sub_sample': 0.7932952419621085}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:39,329]\u001b[0m Trial 33 finished with value: -727730.5330265937 and parameters: {'colsample_bytree': 0.2573455906321774, 'learning_rate': 0.15056284142979426, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 204, 'reg_lambda': 2.0037769476888734, 'reg_alpha': 0.003067838577438478, 'sub_sample': 0.8052453988856189}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:40,050]\u001b[0m Trial 34 finished with value: -725116.9683899591 and parameters: {'colsample_bytree': 0.3828845172667389, 'learning_rate': 0.16400583380783929, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 224, 'reg_lambda': 29.25766925822534, 'reg_alpha': 3.156918549820071, 'sub_sample': 0.7796820338848476}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:40,678]\u001b[0m Trial 35 finished with value: -712667.1351848227 and parameters: {'colsample_bytree': 0.3185347948948244, 'learning_rate': 0.3462908785873216, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 235, 'reg_lambda': 0.1361879606861658, 'reg_alpha': 0.02292007294993543, 'sub_sample': 0.8805946059955337}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:41,232]\u001b[0m Trial 36 finished with value: -721096.7581897865 and parameters: {'colsample_bytree': 0.4048105270490113, 'learning_rate': 0.28954535741249615, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 234, 'reg_lambda': 0.006991561645630534, 'reg_alpha': 10.529593389116911, 'sub_sample': 0.8745468117335569}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:41,909]\u001b[0m Trial 37 finished with value: -761474.3748565828 and parameters: {'colsample_bytree': 0.24982078092755128, 'learning_rate': 0.9939148177478547, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 245, 'reg_lambda': 1.5401834679715658, 'reg_alpha': 0.17782844242895776, 'sub_sample': 0.6805072786303491}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:42,774]\u001b[0m Trial 38 finished with value: -712166.6933232212 and parameters: {'colsample_bytree': 0.5471608950354822, 'learning_rate': 0.13972988002164566, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 213, 'reg_lambda': 1.0633582693547669e-08, 'reg_alpha': 0.29365568712155415, 'sub_sample': 0.9217050955722124}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:43,518]\u001b[0m Trial 39 finished with value: -717264.8184963404 and parameters: {'colsample_bytree': 0.6731638001656512, 'learning_rate': 0.23323318018511813, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 276, 'reg_lambda': 0.0001583704639795528, 'reg_alpha': 0.024783482009809198, 'sub_sample': 0.5748418894773702}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:44,159]\u001b[0m Trial 40 finished with value: -716340.2640121601 and parameters: {'colsample_bytree': 0.31562010498316245, 'learning_rate': 0.27887420264188306, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 149, 'reg_lambda': 21.529083372901844, 'reg_alpha': 0.00348565420787264, 'sub_sample': 0.776571945249531}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:44,985]\u001b[0m Trial 41 finished with value: -715532.9752569103 and parameters: {'colsample_bytree': 0.47741737814024565, 'learning_rate': 0.22411486107419126, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 222, 'reg_lambda': 0.12214254186668466, 'reg_alpha': 0.01874385969237326, 'sub_sample': 0.45787467082424693}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:45,716]\u001b[0m Trial 42 finished with value: -711632.1649100762 and parameters: {'colsample_bytree': 0.42628857972427836, 'learning_rate': 0.14642768583078478, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 126, 'reg_lambda': 2.4734596799522497, 'reg_alpha': 0.6527184173517656, 'sub_sample': 0.20850414521171656}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:46,446]\u001b[0m Trial 43 finished with value: -712008.1899352911 and parameters: {'colsample_bytree': 0.40097213920907737, 'learning_rate': 0.1401579066228484, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 122, 'reg_lambda': 2.64541431410313, 'reg_alpha': 0.5802207276355349, 'sub_sample': 0.17685972828015045}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:47,066]\u001b[0m Trial 44 finished with value: -726174.269448885 and parameters: {'colsample_bytree': 0.2564398643031556, 'learning_rate': 0.14664991952556913, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 158, 'reg_lambda': 6.989562392285278, 'reg_alpha': 7.934152093936075, 'sub_sample': 0.2510970898928867}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:47,730]\u001b[0m Trial 45 finished with value: -731728.5332731148 and parameters: {'colsample_bytree': 0.341470159174463, 'learning_rate': 0.28004521157930773, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 170, 'reg_lambda': 88.16508641581378, 'reg_alpha': 2.200351645604305e-05, 'sub_sample': 0.19352454725800244}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:48,364]\u001b[0m Trial 46 finished with value: -756023.5531254169 and parameters: {'colsample_bytree': 0.4172869695795843, 'learning_rate': 0.8474424692580206, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 197, 'reg_lambda': 0.537740308600411, 'reg_alpha': 0.007739650730430019, 'sub_sample': 0.15350043729585341}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:48,916]\u001b[0m Trial 47 finished with value: -803509.3170699854 and parameters: {'colsample_bytree': 0.16139937688327402, 'learning_rate': 0.1011447803396433, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 244, 'reg_lambda': 1.5026981899247689e-06, 'reg_alpha': 0.0003216514074871045, 'sub_sample': 0.6913288882856652}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:49,549]\u001b[0m Trial 48 finished with value: -736031.8915171021 and parameters: {'colsample_bytree': 0.4921352526473226, 'learning_rate': 0.1967018525887178, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 149, 'reg_lambda': 16.2015512163357, 'reg_alpha': 0.0014530336845093514, 'sub_sample': 0.25814194778999994}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:50,214]\u001b[0m Trial 49 finished with value: -743222.7469512464 and parameters: {'colsample_bytree': 0.3597066071910035, 'learning_rate': 0.6981449776894302, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 214, 'reg_lambda': 1.002121503646251, 'reg_alpha': 0.5113285997404473, 'sub_sample': 0.3573294218998101}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:51,098]\u001b[0m Trial 50 finished with value: -734956.6015730444 and parameters: {'colsample_bytree': 0.557169752540435, 'learning_rate': 0.3020186443591054, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 127, 'reg_lambda': 0.06745115387259501, 'reg_alpha': 18.860936474787938, 'sub_sample': 0.5383734910803986}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:51,821]\u001b[0m Trial 51 finished with value: -712648.675378924 and parameters: {'colsample_bytree': 0.39069417813410023, 'learning_rate': 0.1382904137397614, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 110, 'reg_lambda': 2.903099136236488, 'reg_alpha': 4.036533141730077, 'sub_sample': 0.18561790529318858}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:52,424]\u001b[0m Trial 52 finished with value: -744899.0801503733 and parameters: {'colsample_bytree': 0.20720041827056915, 'learning_rate': 0.14781849791766438, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 126, 'reg_lambda': 2.8940865692388056, 'reg_alpha': 1.7584425827555492, 'sub_sample': 0.16291673869946946}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:52,936]\u001b[0m Trial 53 finished with value: -822532.1636897564 and parameters: {'colsample_bytree': 0.12399104561716204, 'learning_rate': 0.11700009515096312, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 120, 'reg_lambda': 0.4748139093703775, 'reg_alpha': 0.8469679379788646, 'sub_sample': 0.10111112897116153}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:53,636]\u001b[0m Trial 54 finished with value: -726641.5333857501 and parameters: {'colsample_bytree': 0.4434170359348707, 'learning_rate': 0.19502895957351846, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 134, 'reg_lambda': 37.07337972749438, 'reg_alpha': 0.041756768799729185, 'sub_sample': 0.29683375341960877}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:54,198]\u001b[0m Trial 55 finished with value: -721882.1562531985 and parameters: {'colsample_bytree': 0.29610768481884253, 'learning_rate': 0.24551433359561733, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 247, 'reg_lambda': 10.201917058895354, 'reg_alpha': 0.2003254990389207, 'sub_sample': 0.7393371557341321}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:54,987]\u001b[0m Trial 56 finished with value: -711289.5188590011 and parameters: {'colsample_bytree': 0.5242318440181921, 'learning_rate': 0.17146914537927613, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 145, 'reg_lambda': 0.023982849319648444, 'reg_alpha': 0.0002933492585123709, 'sub_sample': 0.2276220741972833}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:55,792]\u001b[0m Trial 57 finished with value: -723199.6675074743 and parameters: {'colsample_bytree': 0.5784134826995199, 'learning_rate': 0.3651293272382842, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 158, 'reg_lambda': 0.016037683825985753, 'reg_alpha': 0.0002329402244802568, 'sub_sample': 0.21819824059561585}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:56,459]\u001b[0m Trial 58 finished with value: -715185.5241862867 and parameters: {'colsample_bytree': 0.5154214107671359, 'learning_rate': 0.21800646829192438, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 143, 'reg_lambda': 0.0036482181034815015, 'reg_alpha': 5.787638227374449e-05, 'sub_sample': 0.2955731155862636}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:57,312]\u001b[0m Trial 59 finished with value: -751079.6705539151 and parameters: {'colsample_bytree': 0.6478090510004564, 'learning_rate': 0.5422583487463049, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 228, 'reg_lambda': 0.24101513778823483, 'reg_alpha': 0.0005944197379983048, 'sub_sample': 0.13985127734480723}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:58,068]\u001b[0m Trial 60 finished with value: -715485.758763465 and parameters: {'colsample_bytree': 0.9031969049911286, 'learning_rate': 0.16599668109891327, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 181, 'reg_lambda': 0.03331772168146676, 'reg_alpha': 4.721915027622617e-06, 'sub_sample': 0.22431104339686994}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:58,918]\u001b[0m Trial 61 finished with value: -710894.0688462231 and parameters: {'colsample_bytree': 0.7907621323949658, 'learning_rate': 0.12375609931623183, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 129, 'reg_lambda': 5.160319456623418, 'reg_alpha': 0.0032976544386394474, 'sub_sample': 0.1690324906580653}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:32:59,768]\u001b[0m Trial 62 finished with value: -714661.388714551 and parameters: {'colsample_bytree': 0.7767353638218173, 'learning_rate': 0.17658697693917752, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 130, 'reg_lambda': 0.9921787890712355, 'reg_alpha': 0.000984724705418742, 'sub_sample': 0.3316588004897256}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:32:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:00,678]\u001b[0m Trial 63 finished with value: -715865.8437494303 and parameters: {'colsample_bytree': 0.9672616810362439, 'learning_rate': 0.11720293249090409, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 144, 'reg_lambda': 8.622531590406528, 'reg_alpha': 0.004409923210146814, 'sub_sample': 0.396309020096899}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:01,532]\u001b[0m Trial 64 finished with value: -718273.3821792447 and parameters: {'colsample_bytree': 0.8323445551889821, 'learning_rate': 0.20903242837720196, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 264, 'reg_lambda': 4.642745255904267, 'reg_alpha': 3.739759870644326e-05, 'sub_sample': 0.10363095288695151}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:02,411]\u001b[0m Trial 65 finished with value: -726720.166859861 and parameters: {'colsample_bytree': 0.9168466376051149, 'learning_rate': 0.2475759829870132, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 167, 'reg_lambda': 0.30245469920135565, 'reg_alpha': 0.001574131997912236, 'sub_sample': 0.224835214767679}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:03,259]\u001b[0m Trial 66 finished with value: -722307.197157252 and parameters: {'colsample_bytree': 0.7961555580803119, 'learning_rate': 0.18241209237219747, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 198, 'reg_lambda': 46.53793034719484, 'reg_alpha': 0.014395894461546746, 'sub_sample': 0.8221468863843937}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:04,129]\u001b[0m Trial 67 finished with value: -730951.3940990095 and parameters: {'colsample_bytree': 0.7231294918697382, 'learning_rate': 0.32426898543714233, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 112, 'reg_lambda': 0.09145309422928909, 'reg_alpha': 0.0001758840352757735, 'sub_sample': 0.5924261667379538}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:04,864]\u001b[0m Trial 68 finished with value: -716957.9971467593 and parameters: {'colsample_bytree': 0.8236404893448414, 'learning_rate': 0.12232719986458929, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 208, 'reg_lambda': 1.3303023893219434, 'reg_alpha': 0.008078721064507846, 'sub_sample': 0.13304967491403097}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:05,714]\u001b[0m Trial 69 finished with value: -711091.1041148421 and parameters: {'colsample_bytree': 0.4618764279755165, 'learning_rate': 0.2612270111157436, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 252, 'reg_lambda': 0.00017687111379339302, 'reg_alpha': 7.478987041065928e-05, 'sub_sample': 0.8705647612349623}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:06,597]\u001b[0m Trial 70 finished with value: -710455.9964160419 and parameters: {'colsample_bytree': 0.471414791495512, 'learning_rate': 0.16750243769710038, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 274, 'reg_lambda': 1.3852820507451462e-05, 'reg_alpha': 9.7156234414659e-06, 'sub_sample': 0.9201546246360102}. Best is trial 32 with value: -710278.7815178146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:07,439]\u001b[0m Trial 71 finished with value: -709138.6190757935 and parameters: {'colsample_bytree': 0.4842664722664387, 'learning_rate': 0.1664336965507271, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 278, 'reg_lambda': 1.32382777432718e-05, 'reg_alpha': 1.0255317001312984e-05, 'sub_sample': 0.9214950236882763}. Best is trial 71 with value: -709138.6190757935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:08,238]\u001b[0m Trial 72 finished with value: -714237.5491173904 and parameters: {'colsample_bytree': 0.4643663879613626, 'learning_rate': 0.2586421526064564, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 281, 'reg_lambda': 6.9377088818336075e-06, 'reg_alpha': 9.026854928595504e-06, 'sub_sample': 0.9942065817942127}. Best is trial 71 with value: -709138.6190757935.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:08,689]\u001b[0m Trial 73 finished with value: -752888.7979183348 and parameters: {'colsample_bytree': 0.5145489292713094, 'learning_rate': 0.16726431051769378, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 288, 'reg_lambda': 4.080025870709035e-05, 'reg_alpha': 1.5474284629339827e-06, 'sub_sample': 0.9489319154551281}. Best is trial 71 with value: -709138.6190757935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:09,520]\u001b[0m Trial 74 finished with value: -712596.319281239 and parameters: {'colsample_bytree': 0.5520875288746477, 'learning_rate': 0.21278123625355358, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 262, 'reg_lambda': 1.580993983374664e-05, 'reg_alpha': 6.388515256860716e-05, 'sub_sample': 0.9049983594962436}. Best is trial 71 with value: -709138.6190757935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:10,400]\u001b[0m Trial 75 finished with value: -710159.5164294562 and parameters: {'colsample_bytree': 0.6165961763692048, 'learning_rate': 0.13015954185904385, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 270, 'reg_lambda': 0.0003960360987639227, 'reg_alpha': 6.131653025194795e-08, 'sub_sample': 0.8565848537418876}. Best is trial 71 with value: -709138.6190757935.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:11,294]\u001b[0m Trial 76 finished with value: -708998.4441135331 and parameters: {'colsample_bytree': 0.6196519308370838, 'learning_rate': 0.10320900158332585, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 269, 'reg_lambda': 0.00034058443493687417, 'reg_alpha': 1.2528454237436795e-07, 'sub_sample': 0.8689529761065578}. Best is trial 76 with value: -708998.4441135331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:11,687]\u001b[0m Trial 77 finished with value: -880746.4226986417 and parameters: {'colsample_bytree': 0.6270915855680166, 'learning_rate': 0.10137945562282381, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 275, 'reg_lambda': 0.0003238373750018413, 'reg_alpha': 6.391842089447684e-08, 'sub_sample': 0.8713172412041454}. Best is trial 76 with value: -708998.4441135331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:12,628]\u001b[0m Trial 78 finished with value: -712235.9865571959 and parameters: {'colsample_bytree': 0.6699000953762817, 'learning_rate': 0.12922458166137477, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 252, 'reg_lambda': 0.0002627562835452231, 'reg_alpha': 1.3360477805788687e-07, 'sub_sample': 0.9588964632508767}. Best is trial 76 with value: -708998.4441135331.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:13,517]\u001b[0m Trial 79 finished with value: -715749.0032100168 and parameters: {'colsample_bytree': 0.5926609960864311, 'learning_rate': 0.26370707789462466, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 288, 'reg_lambda': 0.0008628543424398467, 'reg_alpha': 2.1753620451876834e-07, 'sub_sample': 0.8967256785077016}. Best is trial 76 with value: -708998.4441135331.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:14,515]\u001b[0m Trial 80 finished with value: -715715.7843331925 and parameters: {'colsample_bytree': 0.6979445196616697, 'learning_rate': 0.23104060499589876, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 269, 'reg_lambda': 3.630857004101932e-05, 'reg_alpha': 1.3262508211920672e-08, 'sub_sample': 0.8285097520014324}. Best is trial 76 with value: -708998.4441135331.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:15,374]\u001b[0m Trial 81 finished with value: -710157.0593103447 and parameters: {'colsample_bytree': 0.5679605795481024, 'learning_rate': 0.16656660784431498, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 283, 'reg_lambda': 1.4737191495718712e-06, 'reg_alpha': 2.0122480009098303e-06, 'sub_sample': 0.856672909432677}. Best is trial 76 with value: -708998.4441135331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:16,330]\u001b[0m Trial 82 finished with value: -708772.004233907 and parameters: {'colsample_bytree': 0.5761373746137016, 'learning_rate': 0.12428765974312161, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 300, 'reg_lambda': 7.785511959680964e-07, 'reg_alpha': 6.219656089691891e-07, 'sub_sample': 0.8636262395709218}. Best is trial 82 with value: -708772.004233907.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:17,219]\u001b[0m Trial 83 finished with value: -709932.341416547 and parameters: {'colsample_bytree': 0.609326547535679, 'learning_rate': 0.12959593295007635, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 299, 'reg_lambda': 1.9549124409749646e-07, 'reg_alpha': 1.3063225386112172e-06, 'sub_sample': 0.934483508489671}. Best is trial 82 with value: -708772.004233907.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:18,173]\u001b[0m Trial 84 finished with value: -710350.4796726655 and parameters: {'colsample_bytree': 0.7504869486274072, 'learning_rate': 0.12312672479546913, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 297, 'reg_lambda': 2.393334313723994e-07, 'reg_alpha': 1.62259085807419e-06, 'sub_sample': 0.9295916326582845}. Best is trial 82 with value: -708772.004233907.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:19,064]\u001b[0m Trial 85 finished with value: -708200.8639416614 and parameters: {'colsample_bytree': 0.5728738997537954, 'learning_rate': 0.10283710503304422, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 290, 'reg_lambda': 2.1608041187990282e-07, 'reg_alpha': 1.5557240770526113e-06, 'sub_sample': 0.85153487133629}. Best is trial 85 with value: -708200.8639416614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:20,025]\u001b[0m Trial 86 finished with value: -710394.4071780698 and parameters: {'colsample_bytree': 0.7508705661810189, 'learning_rate': 0.10238618372122843, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 300, 'reg_lambda': 1.6678403871142467e-07, 'reg_alpha': 2.2158389156250983e-06, 'sub_sample': 0.939121833769334}. Best is trial 85 with value: -708200.8639416614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:20,970]\u001b[0m Trial 87 finished with value: -711795.9208477447 and parameters: {'colsample_bytree': 0.6631272779353902, 'learning_rate': 0.13297063857763797, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 293, 'reg_lambda': 7.953519786794937e-07, 'reg_alpha': 4.0513360494008547e-07, 'sub_sample': 0.8488837027059495}. Best is trial 85 with value: -708200.8639416614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:22,043]\u001b[0m Trial 88 finished with value: -710124.3690082222 and parameters: {'colsample_bytree': 0.6098471915386791, 'learning_rate': 0.14849337953729624, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 282, 'reg_lambda': 7.184899482749206e-08, 'reg_alpha': 1.2601103599354708e-06, 'sub_sample': 0.9774585777585539}. Best is trial 85 with value: -708200.8639416614.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:23,025]\u001b[0m Trial 89 finished with value: -710947.6477707352 and parameters: {'colsample_bytree': 0.6105604002302015, 'learning_rate': 0.18727916279871543, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 282, 'reg_lambda': 5.1614777397172076e-08, 'reg_alpha': 7.577927061235798e-07, 'sub_sample': 0.9721240079891629}. Best is trial 85 with value: -708200.8639416614.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:23,935]\u001b[0m Trial 90 finished with value: -792563.6770893119 and parameters: {'colsample_bytree': 0.5741437413536568, 'learning_rate': 0.9088587441762224, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 281, 'reg_lambda': 1.5666726674496964e-06, 'reg_alpha': 5.530185917253016e-08, 'sub_sample': 0.9945414935142949}. Best is trial 85 with value: -708200.8639416614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:24,870]\u001b[0m Trial 91 finished with value: -708176.1656207722 and parameters: {'colsample_bytree': 0.6081482318102632, 'learning_rate': 0.14995701851734167, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 291, 'reg_lambda': 3.9652704245263507e-07, 'reg_alpha': 1.2822823054491217e-06, 'sub_sample': 0.8509083106841969}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:25,738]\u001b[0m Trial 92 finished with value: -709705.2499268915 and parameters: {'colsample_bytree': 0.6431997241066975, 'learning_rate': 0.1468129537157975, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 292, 'reg_lambda': 7.083585081132434e-07, 'reg_alpha': 3.374168857959102e-07, 'sub_sample': 0.8526535311276829}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:26,628]\u001b[0m Trial 93 finished with value: -711958.460043606 and parameters: {'colsample_bytree': 0.6442966112840434, 'learning_rate': 0.1510625203363342, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 291, 'reg_lambda': 2.6116094684418244e-06, 'reg_alpha': 2.5691344993786866e-07, 'sub_sample': 0.8950504013525614}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:27,514]\u001b[0m Trial 94 finished with value: -711380.2502395676 and parameters: {'colsample_bytree': 0.610460658944866, 'learning_rate': 0.1946870701493911, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 286, 'reg_lambda': 3.955395790098293e-07, 'reg_alpha': 5.355795544148412e-06, 'sub_sample': 0.8571425264379499}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:28,380]\u001b[0m Trial 95 finished with value: -712934.5270230606 and parameters: {'colsample_bytree': 0.5415830581488106, 'learning_rate': 0.10200022843956595, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 300, 'reg_lambda': 8.676306927092159e-08, 'reg_alpha': 2.3626814771840424e-06, 'sub_sample': 0.8156439422801162}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:29,282]\u001b[0m Trial 96 finished with value: -709180.5828232719 and parameters: {'colsample_bytree': 0.5753051371767737, 'learning_rate': 0.15638446292791972, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 283, 'reg_lambda': 4.75174666841083e-07, 'reg_alpha': 1.2121704007605986e-07, 'sub_sample': 0.842674132170863}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:30,141]\u001b[0m Trial 97 finished with value: -709655.0390557679 and parameters: {'colsample_bytree': 0.5687299817412965, 'learning_rate': 0.15564516426004346, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 284, 'reg_lambda': 6.054923189995665e-07, 'reg_alpha': 9.501133167796241e-07, 'sub_sample': 0.7486713786452432}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:30,669]\u001b[0m Trial 98 finished with value: -753702.033404493 and parameters: {'colsample_bytree': 0.6921348975687344, 'learning_rate': 0.150092382603583, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 293, 'reg_lambda': 5.292636145221671e-07, 'reg_alpha': 1.190091079185507e-07, 'sub_sample': 0.7552722401047646}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:33:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2022-01-23 09:33:31,511]\u001b[0m Trial 99 finished with value: -710605.3483168307 and parameters: {'colsample_bytree': 0.5007892856939719, 'learning_rate': 0.20296857138021185, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 278, 'reg_lambda': 1.5162846602916995e-08, 'reg_alpha': 4.547010187248247e-07, 'sub_sample': 0.9122505892131235}. Best is trial 91 with value: -708176.1656207722.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def xgb(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, Z10_train, y10_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f4ecd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6081482318102632,\n",
       " 'learning_rate': 0.14995701851734167,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 291,\n",
       " 'reg_lambda': 3.9652704245263507e-07,\n",
       " 'reg_alpha': 1.2822823054491217e-06,\n",
       " 'sub_sample': 0.8509083106841969}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5db6e866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.6081482318102632,\n",
       "             enable_categorical=False, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.14995701851734167,\n",
       "             max_delta_step=0, max_depth=5, min_child_weight=4, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=291, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=1.2822823054491217e-06,\n",
       "             reg_lambda=3.9652704245263507e-07, scale_pos_weight=1,\n",
       "             sub_sample=0.8509083106841969, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB10 = XGBRegressor(colsample_bytree= 0.6081482318102632, learning_rate= 0.14995701851734167, max_depth= 5, min_child_weight= 4, n_estimators= 291,\n",
    "reg_alpha= 1.2822823054491217e-06, reg_lambda=  3.9652704245263507e-07, sub_sample= 0.8509083106841969)\n",
    "XGB10.fit(Z10_train, y10_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a22d52",
   "metadata": {},
   "source": [
    "### Comparing the RMSE of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b60ad5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833398522647.3024\n",
      "912906.634134785\n"
     ]
    }
   ],
   "source": [
    "y10_pred_trainXGB = XGB10.predict(Z10_train)\n",
    "print(metrics.mean_squared_error(y10_train, y10_pred_trainXGB))\n",
    "print(np.sqrt(metrics.mean_squared_error(y10_train, y10_pred_trainXGB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3568e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897259349088.1044\n",
      "947237.7468661732\n"
     ]
    }
   ],
   "source": [
    "y10_pred_testXGB = XGB10.predict(Z10_test)\n",
    "print(metrics.mean_squared_error(y10_test, y10_pred_testXGB))\n",
    "print(np.sqrt(metrics.mean_squared_error(y10_test, y10_pred_testXGB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706536b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(737944.7456683931 -568914.2189612276)/ 737944.7456683931*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f007af",
   "metadata": {},
   "source": [
    "### Using RandomForestRegressor for merged_house_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1c73939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 300}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gridseach done multiple times to narrow in the best params\n",
    "rf_params = {\n",
    "    'n_estimators': [290, 300, 320, 350],\n",
    "    'max_depth': [7, 9, 10, 12],\n",
    "}\n",
    "gs10 = GridSearchCV(rf, param_grid=rf_params, cv=5, n_jobs=-1)\n",
    "gs10.fit(Z10_train, y10_train)\n",
    "gs10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71c5717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361675762476.5393\n",
      "601394.8473977303\n"
     ]
    }
   ],
   "source": [
    "y_pred_trainrf10 = gs10.predict(Z10_train)\n",
    "print(metrics.mean_squared_error(y10_train, y_pred_trainrf10))\n",
    "print(np.sqrt(metrics.mean_squared_error(y10_train, y_pred_trainrf10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9baf8beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580685568332.762\n",
      "762027.2753207473\n"
     ]
    }
   ],
   "source": [
    "y_pred_testrf10 = gs10.predict(Z10_test)\n",
    "print(metrics.mean_squared_error(y10_test, y_pred_testrf10))\n",
    "print(np.sqrt(metrics.mean_squared_error(y10_test, y_pred_testrf10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe7e023c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.079616586611635"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(762027.2753207473 - 601394.8473977303)/ 762027.2753207473 *100\n",
    "# RandomforestRegressor is overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b24b4",
   "metadata": {},
   "source": [
    "## From EDA, it was noticed that the tenure co relates within 99 years and lesser during >99 years. 2 seperate models will be plotted to distinguish both\n",
    "\n",
    "1. Using of the merged_house_10 dataset as more outliers were removed from it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b641353",
   "metadata": {},
   "source": [
    "### Moving house tenure with <=99 years out from the main dataset, naming it as merged_house99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b38fd113",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_house99 = merged_house_10[merged_house_10['tenure'] <=99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f324a7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1119, 45)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house99.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84366efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project name</th>\n",
       "      <th>street name</th>\n",
       "      <th>tenure</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>price</th>\n",
       "      <th>nett price</th>\n",
       "      <th>areasq</th>\n",
       "      <th>type of area</th>\n",
       "      <th>floor level</th>\n",
       "      <th>unit price psf</th>\n",
       "      <th>date of sale</th>\n",
       "      <th>market segment_CCR</th>\n",
       "      <th>market segment_OCR</th>\n",
       "      <th>market segment_RCR</th>\n",
       "      <th>postal district_2.0</th>\n",
       "      <th>postal district_3.0</th>\n",
       "      <th>postal district_4.0</th>\n",
       "      <th>postal district_5.0</th>\n",
       "      <th>postal district_8.0</th>\n",
       "      <th>postal district_9.0</th>\n",
       "      <th>postal district_10.0</th>\n",
       "      <th>postal district_11.0</th>\n",
       "      <th>postal district_12.0</th>\n",
       "      <th>postal district_13.0</th>\n",
       "      <th>postal district_14.0</th>\n",
       "      <th>postal district_15.0</th>\n",
       "      <th>postal district_16.0</th>\n",
       "      <th>postal district_17.0</th>\n",
       "      <th>postal district_18.0</th>\n",
       "      <th>postal district_19.0</th>\n",
       "      <th>postal district_20.0</th>\n",
       "      <th>postal district_21.0</th>\n",
       "      <th>postal district_22.0</th>\n",
       "      <th>postal district_23.0</th>\n",
       "      <th>postal district_25.0</th>\n",
       "      <th>postal district_26.0</th>\n",
       "      <th>postal district_27.0</th>\n",
       "      <th>postal district_28.0</th>\n",
       "      <th>type_Detached</th>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <th>type_Terrace</th>\n",
       "      <th>type of sale_New Sale</th>\n",
       "      <th>type of sale_Resale</th>\n",
       "      <th>type of sale_Sub Sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>PEARL ISLAND</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11288000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>7011.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>Jul-2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PARADISE ISLAND</td>\n",
       "      <td>PARADISE ISLAND</td>\n",
       "      <td>83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11200000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>8633.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>Apr-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>CORAL ISLAND</td>\n",
       "      <td>CORAL ISLAND</td>\n",
       "      <td>83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>9325.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>Mar-2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>PARADISE ISLAND</td>\n",
       "      <td>PARADISE ISLAND</td>\n",
       "      <td>83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10550000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>8170.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>Aug-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>SENTOSA COVE</td>\n",
       "      <td>CORAL ISLAND</td>\n",
       "      <td>83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10300000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>7511.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>May-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                project name      street name  tenure  no. of units  \\\n",
       "0       0  LANDED HOUSING DEVELOPMENT     PEARL ISLAND      86           1.0   \n",
       "3       3             PARADISE ISLAND  PARADISE ISLAND      83           1.0   \n",
       "21     21                CORAL ISLAND     CORAL ISLAND      83           1.0   \n",
       "55     55             PARADISE ISLAND  PARADISE ISLAND      83           1.0   \n",
       "88     88                SENTOSA COVE     CORAL ISLAND      83           1.0   \n",
       "\n",
       "         price nett price  areasq type of area floor level  unit price psf  \\\n",
       "0   11288000.0          -  7011.0         Land           -          1610.0   \n",
       "3   11200000.0          -  8633.0         Land           -          1297.0   \n",
       "21  11000000.0          -  9325.0         Land           -          1180.0   \n",
       "55  10550000.0          -  8170.0         Land           -          1291.0   \n",
       "88  10300000.0          -  7511.0         Land           -          1371.0   \n",
       "\n",
       "   date of sale  market segment_CCR  market segment_OCR  market segment_RCR  \\\n",
       "0      Jul-2017                   1                   0                   0   \n",
       "3      Apr-2018                   1                   0                   0   \n",
       "21     Mar-2017                   1                   0                   0   \n",
       "55     Aug-2020                   1                   0                   0   \n",
       "88     May-2021                   1                   0                   0   \n",
       "\n",
       "    postal district_2.0  postal district_3.0  postal district_4.0  \\\n",
       "0                     0                    0                    1   \n",
       "3                     0                    0                    1   \n",
       "21                    0                    0                    1   \n",
       "55                    0                    0                    1   \n",
       "88                    0                    0                    1   \n",
       "\n",
       "    postal district_5.0  postal district_8.0  postal district_9.0  \\\n",
       "0                     0                    0                    0   \n",
       "3                     0                    0                    0   \n",
       "21                    0                    0                    0   \n",
       "55                    0                    0                    0   \n",
       "88                    0                    0                    0   \n",
       "\n",
       "    postal district_10.0  postal district_11.0  postal district_12.0  \\\n",
       "0                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "21                     0                     0                     0   \n",
       "55                     0                     0                     0   \n",
       "88                     0                     0                     0   \n",
       "\n",
       "    postal district_13.0  postal district_14.0  postal district_15.0  \\\n",
       "0                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "21                     0                     0                     0   \n",
       "55                     0                     0                     0   \n",
       "88                     0                     0                     0   \n",
       "\n",
       "    postal district_16.0  postal district_17.0  postal district_18.0  \\\n",
       "0                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "21                     0                     0                     0   \n",
       "55                     0                     0                     0   \n",
       "88                     0                     0                     0   \n",
       "\n",
       "    postal district_19.0  postal district_20.0  postal district_21.0  \\\n",
       "0                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "21                     0                     0                     0   \n",
       "55                     0                     0                     0   \n",
       "88                     0                     0                     0   \n",
       "\n",
       "    postal district_22.0  postal district_23.0  postal district_25.0  \\\n",
       "0                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "21                     0                     0                     0   \n",
       "55                     0                     0                     0   \n",
       "88                     0                     0                     0   \n",
       "\n",
       "    postal district_26.0  postal district_27.0  postal district_28.0  \\\n",
       "0                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "21                     0                     0                     0   \n",
       "55                     0                     0                     0   \n",
       "88                     0                     0                     0   \n",
       "\n",
       "    type_Detached  type_Semi-detached  type_Terrace  type of sale_New Sale  \\\n",
       "0               1                   0             0                      0   \n",
       "3               1                   0             0                      0   \n",
       "21              1                   0             0                      0   \n",
       "55              1                   0             0                      0   \n",
       "88              1                   0             0                      0   \n",
       "\n",
       "    type of sale_Resale  type of sale_Sub Sale  \n",
       "0                     1                      0  \n",
       "3                     1                      0  \n",
       "21                    1                      0  \n",
       "55                    1                      0  \n",
       "88                    1                      0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house99.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d6ecf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='tenure', ylabel='price'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.scatterplot(y = merged_house99['price'], x = merged_house99['tenure'])\n",
    "#Generally, there is a slight corelation that the prices increases as the tenure is higher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab2ddf",
   "metadata": {},
   "source": [
    "### Moving house tenure with >99 years out from the main dataset, naming it as freehold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6349ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "freehold = merged_house_10[merged_house_10['tenure'] >99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b6b8d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7634, 45)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freehold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9d5d768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='tenure', ylabel='price'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.scatterplot(y = freehold['price'], x = freehold['tenure'])\n",
    "# not much co relation as it is classfied as freehold, technically the freehold is under sales part is classified under freehold as long as it exceeds the normal 99 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc96406",
   "metadata": {},
   "source": [
    "# Modelling for housing equal or lesser than 99 Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7473f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LR, XGB and RF is tried out\n",
    "LR RMSE error:\n",
    "    \n",
    "# Errors is too abnormal, this maybe due to small dataset that doesnt capture the true relationship with the prices, 99 years can be related to the HDB prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "585c9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X99 = merged_house99.drop(columns =['price', 'unit price psf', 'index', 'project name', 'street name', 'nett price', 'type of area','floor level','date of sale',])\n",
    "y99 = merged_house99['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b68a39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X99_train, X99_test, y99_train, y99_test = train_test_split(X99, y99, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d37c2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z99_train = sc.fit_transform(X99_train)\n",
    "Z99_test = sc.transform(X99_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b37e1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr99 =LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cf34198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr99.fit(Z99_train, y99_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7c32f2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Model Train Test & Baseline Score\n",
      "\n",
      "Baseline Score RMSE is 2355449\n",
      "\n",
      "Train Score\n",
      "MSE IS 139514729722\n",
      "RSME IS 373516\n",
      "\n",
      "Test\n",
      "MSE IS 31088788561560048512282832744218624\n",
      "RSME IS 176320130902741920\n",
      "\n",
      "Train Test % Difference\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "print_result(model= lr99,\n",
    "            X_train = Z99_train,\n",
    "             X_test = Z99_test,\n",
    "             y_train = y99_train,\n",
    "             y_test = y99_test,\n",
    "            title='Comparison of Model Train Test & Baseline Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9b600168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Refit selected lasso model\n",
    "y_pred_test_99 = lr99.predict(Z99_test)\n",
    "\n",
    "# Visualizing actual prices vs predicted values\n",
    "plt.scatter(y99_test, y_pred_test_99)\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Actual Cost Price vs Predicted Cost Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8af67ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139514729722.2219\n",
      "373516.7060818323\n"
     ]
    }
   ],
   "source": [
    "y_pred_train99 = lr99.predict(Z99_train)\n",
    "print(metrics.mean_squared_error(y99_train, y_pred_train99))\n",
    "print(np.sqrt(metrics.mean_squared_error(y99_train, y_pred_train99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "deeb822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.108878856156005e+34\n",
      "1.7632013090274192e+17\n"
     ]
    }
   ],
   "source": [
    "y_pred_test99 = lr99.predict(Z99_test)\n",
    "print(metrics.mean_squared_error(y99_test, y_pred_test99))\n",
    "print(np.sqrt(metrics.mean_squared_error(y99_test, y_pred_test99)))\n",
    "# this value is too huge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee48785",
   "metadata": {},
   "source": [
    "### Carrying out XGboost Modelling for merged_house99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a81c9214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-23 09:34:44,184]\u001b[0m A new study created in memory with name: no-name-683afe3d-4e4c-4760-b59d-e4821ab493ee\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:44,448]\u001b[0m Trial 0 finished with value: -590541.836853709 and parameters: {'colsample_bytree': 0.4370861069626263, 'learning_rate': 0.9556428757689246, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 131, 'reg_lambda': 3.6303224667798554e-07, 'reg_alpha': 3.809220577048033e-08, 'sub_sample': 0.8795585311974417}. Best is trial 0 with value: -590541.836853709.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:44,602]\u001b[0m Trial 1 finished with value: -475090.8945116042 and parameters: {'colsample_bytree': 0.6410035105688879, 'learning_rate': 0.737265320016441, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 267, 'reg_lambda': 1.3285903900544182e-06, 'reg_alpha': 6.580360277501306e-07, 'sub_sample': 0.2650640588680905}. Best is trial 1 with value: -475090.8945116042.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:44,818]\u001b[0m Trial 2 finished with value: -493007.7743243029 and parameters: {'colsample_bytree': 0.373818018663584, 'learning_rate': 0.5722807884690141, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 222, 'reg_lambda': 2.4827821051950883e-07, 'reg_alpha': 8.345387083873532e-06, 'sub_sample': 0.4297256589643226}. Best is trial 1 with value: -475090.8945116042.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:45,006]\u001b[0m Trial 3 finished with value: -520912.875331269 and parameters: {'colsample_bytree': 0.5104629857953323, 'learning_rate': 0.8066583652537123, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 219, 'reg_lambda': 2.9140978279786215e-08, 'reg_alpha': 0.011897302909454906, 'sub_sample': 0.2534717113185624}. Best is trial 1 with value: -475090.8945116042.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:45,225]\u001b[0m Trial 4 finished with value: -433215.2973839771 and parameters: {'colsample_bytree': 0.1585464336867516, 'learning_rate': 0.9539969835279999, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 161, 'reg_lambda': 9.478096804784244e-08, 'reg_alpha': 0.06955530592645753, 'sub_sample': 0.4961372443656412}. Best is trial 4 with value: -433215.2973839771.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:45,379]\u001b[0m Trial 5 finished with value: -475429.1202375773 and parameters: {'colsample_bytree': 0.20983441136030095, 'learning_rate': 0.5456592191001431, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 152, 'reg_lambda': 0.042191293826476094, 'reg_alpha': 1.3095158546031483e-05, 'sub_sample': 0.5680612190600297}. Best is trial 4 with value: -433215.2973839771.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:45,660]\u001b[0m Trial 6 finished with value: -407131.8292053398 and parameters: {'colsample_bytree': 0.5920392514089517, 'learning_rate': 0.26636900997297436, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 288, 'reg_lambda': 8.8771488946556, 'reg_alpha': 0.00952795699161383, 'sub_sample': 0.9296868115208051}. Best is trial 6 with value: -407131.8292053398.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:45,809]\u001b[0m Trial 7 finished with value: -491369.5837191139 and parameters: {'colsample_bytree': 0.17964325184672755, 'learning_rate': 0.27638457617723067, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 178, 'reg_lambda': 5.169997317292732e-06, 'reg_alpha': 1.9380951355796903, 'sub_sample': 0.4210779940242304}. Best is trial 6 with value: -407131.8292053398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:45,976]\u001b[0m Trial 8 finished with value: -470412.07167798677 and parameters: {'colsample_bytree': 0.3528410587186427, 'learning_rate': 0.5884264748424236, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 114, 'reg_lambda': 73.9382838287635, 'reg_alpha': 0.5277736371601186, 'sub_sample': 0.2788441133807552}. Best is trial 6 with value: -407131.8292053398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:46,166]\u001b[0m Trial 9 finished with value: -487206.75156991597 and parameters: {'colsample_bytree': 0.10496990541124217, 'learning_rate': 0.8339152856093507, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 255, 'reg_lambda': 5.50106171658889e-08, 'reg_alpha': 3.842884090673403e-05, 'sub_sample': 0.20428215357261675}. Best is trial 6 with value: -407131.8292053398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:46,520]\u001b[0m Trial 10 finished with value: -411561.14555680356 and parameters: {'colsample_bytree': 0.9497157666716347, 'learning_rate': 0.10539746466023536, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 297, 'reg_lambda': 11.930206277066471, 'reg_alpha': 39.6011191452442, 'sub_sample': 0.9790910709802578}. Best is trial 6 with value: -407131.8292053398.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:46,861]\u001b[0m Trial 11 finished with value: -509086.7731010109 and parameters: {'colsample_bytree': 0.9522656887511342, 'learning_rate': 0.10326321505087403, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 82.82843195255043, 'reg_alpha': 73.24607527580478, 'sub_sample': 0.971643831619738}. Best is trial 6 with value: -407131.8292053398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:47,158]\u001b[0m Trial 12 finished with value: -384672.2991611479 and parameters: {'colsample_bytree': 0.9925005566564994, 'learning_rate': 0.10376349477481495, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 0.5154377331302434, 'reg_alpha': 90.4650741825025, 'sub_sample': 0.7633847055950665}. Best is trial 12 with value: -384672.2991611479.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:47,396]\u001b[0m Trial 13 finished with value: -402458.9448426664 and parameters: {'colsample_bytree': 0.7310463358543839, 'learning_rate': 0.31176902969578846, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 260, 'reg_lambda': 0.09378349935519929, 'reg_alpha': 0.000507984588639035, 'sub_sample': 0.7413072416315158}. Best is trial 12 with value: -384672.2991611479.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:47,634]\u001b[0m Trial 14 finished with value: -419322.2542948559 and parameters: {'colsample_bytree': 0.7763828347908058, 'learning_rate': 0.31724512451354203, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 247, 'reg_lambda': 0.03157769150610153, 'reg_alpha': 0.00041797237987258127, 'sub_sample': 0.7333267572758785}. Best is trial 12 with value: -384672.2991611479.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:47,842]\u001b[0m Trial 15 finished with value: -417815.6157012974 and parameters: {'colsample_bytree': 0.792506676036915, 'learning_rate': 0.4244848899387733, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 229, 'reg_lambda': 0.08618448663084818, 'reg_alpha': 0.0007484047769293601, 'sub_sample': 0.742100313526229}. Best is trial 12 with value: -384672.2991611479.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:48,125]\u001b[0m Trial 16 finished with value: -422586.42427979887 and parameters: {'colsample_bytree': 0.7870676919157016, 'learning_rate': 0.20191401253569222, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 271, 'reg_lambda': 0.0007776501992923246, 'reg_alpha': 1.5592816968307144, 'sub_sample': 0.714381607045601}. Best is trial 12 with value: -384672.2991611479.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:48,342]\u001b[0m Trial 17 finished with value: -425433.55528260313 and parameters: {'colsample_bytree': 0.8780168110310309, 'learning_rate': 0.39102924150979707, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 204, 'reg_lambda': 0.00022228472102829976, 'reg_alpha': 0.0001485014033557873, 'sub_sample': 0.6396767599776616}. Best is trial 12 with value: -384672.2991611479.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:48,593]\u001b[0m Trial 18 finished with value: -379283.625257604 and parameters: {'colsample_bytree': 0.6904927085511056, 'learning_rate': 0.17815579496548767, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 248, 'reg_lambda': 0.44643529118791236, 'reg_alpha': 0.005942699298101809, 'sub_sample': 0.8267024934971574}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:48,898]\u001b[0m Trial 19 finished with value: -401392.56704744085 and parameters: {'colsample_bytree': 0.9971082603016066, 'learning_rate': 0.1828364527620594, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 246, 'reg_lambda': 1.856406625137426, 'reg_alpha': 9.05061704425252, 'sub_sample': 0.8454543283953284}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:49,108]\u001b[0m Trial 20 finished with value: -425566.09879857866 and parameters: {'colsample_bytree': 0.6777451414622361, 'learning_rate': 0.4547805054375665, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 278, 'reg_lambda': 0.9630872641589057, 'reg_alpha': 0.02852349035963383, 'sub_sample': 0.8309944237896358}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:49,415]\u001b[0m Trial 21 finished with value: -410006.18142860517 and parameters: {'colsample_bytree': 0.9976416318735601, 'learning_rate': 0.21628617031454217, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 245, 'reg_lambda': 0.7637261734984732, 'reg_alpha': 11.015815653846357, 'sub_sample': 0.843183898158492}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:49,691]\u001b[0m Trial 22 finished with value: -391847.9982860677 and parameters: {'colsample_bytree': 0.8729265376206938, 'learning_rate': 0.170490875739308, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 194, 'reg_lambda': 0.007393359563913052, 'reg_alpha': 0.23063800877143195, 'sub_sample': 0.8197087866921303}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:49,939]\u001b[0m Trial 23 finished with value: -382686.52535893343 and parameters: {'colsample_bytree': 0.8655554193771716, 'learning_rate': 0.1549506151484801, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 189, 'reg_lambda': 0.0025936465996646793, 'reg_alpha': 0.1476468626151311, 'sub_sample': 0.6280667738381644}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:50,199]\u001b[0m Trial 24 finished with value: -379445.72575830045 and parameters: {'colsample_bytree': 0.858967002746504, 'learning_rate': 0.11561384166892183, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 200, 'reg_lambda': 3.9296834332460146e-05, 'reg_alpha': 0.0027489562444532973, 'sub_sample': 0.6248271893160751}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:50,439]\u001b[0m Trial 25 finished with value: -407560.36033942224 and parameters: {'colsample_bytree': 0.8323738791721113, 'learning_rate': 0.34801704242923104, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 188, 'reg_lambda': 6.279282512722431e-05, 'reg_alpha': 0.004518332230347583, 'sub_sample': 0.626108221451959}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:50,648]\u001b[0m Trial 26 finished with value: -384324.5415231161 and parameters: {'colsample_bytree': 0.7075761921535304, 'learning_rate': 0.24484812522004112, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 169, 'reg_lambda': 2.366690808028781e-05, 'reg_alpha': 0.004051194524636848, 'sub_sample': 0.6382220098287112}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:50,887]\u001b[0m Trial 27 finished with value: -391999.0478809335 and parameters: {'colsample_bytree': 0.8832559695348894, 'learning_rate': 0.16069052953466414, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 148, 'reg_lambda': 0.003352208090184161, 'reg_alpha': 0.025355246824053327, 'sub_sample': 0.5353708710577317}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:51,102]\u001b[0m Trial 28 finished with value: -465887.01176233933 and parameters: {'colsample_bytree': 0.5946133918309239, 'learning_rate': 0.4890058214134105, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 201, 'reg_lambda': 0.0007611044960329382, 'reg_alpha': 0.15871160587848407, 'sub_sample': 0.38057900916517184}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:51,342]\u001b[0m Trial 29 finished with value: -516492.7644612178 and parameters: {'colsample_bytree': 0.5267332464918302, 'learning_rate': 0.6401427485130929, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 214, 'reg_lambda': 1.4788604593317367e-05, 'reg_alpha': 4.448996188984284e-07, 'sub_sample': 0.675385004298121}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:51,589]\u001b[0m Trial 30 finished with value: -412069.97999928717 and parameters: {'colsample_bytree': 0.7624043440424074, 'learning_rate': 0.3772518693272594, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 127, 'reg_lambda': 0.00012676897262150284, 'reg_alpha': 2.67578861029397e-08, 'sub_sample': 0.5751692250028689}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:51,804]\u001b[0m Trial 31 finished with value: -392075.29567109485 and parameters: {'colsample_bytree': 0.6849196747011596, 'learning_rate': 0.24601147508473134, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 175, 'reg_lambda': 2.2144233917783736e-05, 'reg_alpha': 0.00245870670085372, 'sub_sample': 0.6419636852451244}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:52,012]\u001b[0m Trial 32 finished with value: -387517.38077977893 and parameters: {'colsample_bytree': 0.7085928994770061, 'learning_rate': 0.14430203258220933, 'max_depth': 2, 'min_child_weight': 5, 'n_estimators': 170, 'reg_lambda': 2.3699986968169333e-06, 'reg_alpha': 0.0022065599340476607, 'sub_sample': 0.4996523147411789}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:52,251]\u001b[0m Trial 33 finished with value: -415787.465760097 and parameters: {'colsample_bytree': 0.6385164920390681, 'learning_rate': 0.23505181799896707, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 186, 'reg_lambda': 0.003957986190517428, 'reg_alpha': 0.00012815441646353752, 'sub_sample': 0.6059232514070175}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:52,496]\u001b[0m Trial 34 finished with value: -416897.4309934514 and parameters: {'colsample_bytree': 0.8218681688170645, 'learning_rate': 0.28702377028028025, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 139, 'reg_lambda': 1.5321024202985476e-06, 'reg_alpha': 0.07017731351989422, 'sub_sample': 0.9046068930059444}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:52,697]\u001b[0m Trial 35 finished with value: -393067.86021965166 and parameters: {'colsample_bytree': 0.45302510720752825, 'learning_rate': 0.13983711232320636, 'max_depth': 2, 'min_child_weight': 5, 'n_estimators': 230, 'reg_lambda': 1.1339287163042353e-08, 'reg_alpha': 0.007860541351119934, 'sub_sample': 0.6799507852247828}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:52,964]\u001b[0m Trial 36 finished with value: -384751.17537541216 and parameters: {'colsample_bytree': 0.9076002723795503, 'learning_rate': 0.2285863921811879, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 211, 'reg_lambda': 5.059438740249463e-07, 'reg_alpha': 2.7236139178611496e-06, 'sub_sample': 0.7924019236991937}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:53,179]\u001b[0m Trial 37 finished with value: -480791.42498539353 and parameters: {'colsample_bytree': 0.6283561460274122, 'learning_rate': 0.9939148177478547, 'max_depth': 2, 'min_child_weight': 5, 'n_estimators': 165, 'reg_lambda': 1.37146712664841e-05, 'reg_alpha': 0.028715344940451942, 'sub_sample': 0.48164289512644287}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:53,418]\u001b[0m Trial 38 finished with value: -415866.6487846983 and parameters: {'colsample_bytree': 0.5785788743675566, 'learning_rate': 0.20120677166271841, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 228, 'reg_lambda': 0.012095705258852157, 'reg_alpha': 0.0016380381411662684, 'sub_sample': 0.3436631547215141}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:53,605]\u001b[0m Trial 39 finished with value: -463577.0851329153 and parameters: {'colsample_bytree': 0.7336049792592351, 'learning_rate': 0.3470654252517139, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 156, 'reg_lambda': 0.0003694895646718206, 'reg_alpha': 0.5966847404047354, 'sub_sample': 0.5401257166910759}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:53,844]\u001b[0m Trial 40 finished with value: -456863.24231246195 and parameters: {'colsample_bytree': 0.8333438654274217, 'learning_rate': 0.7773487177003318, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 182, 'reg_lambda': 5.446197885913463e-05, 'reg_alpha': 7.341427871689331e-05, 'sub_sample': 0.1041335154321904}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:54,158]\u001b[0m Trial 41 finished with value: -411034.0411325195 and parameters: {'colsample_bytree': 0.9015244962619338, 'learning_rate': 0.10130745072105976, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 196, 'reg_lambda': 0.207126580365644, 'reg_alpha': 8.328526300049079, 'sub_sample': 0.7928315649982736}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:54,446]\u001b[0m Trial 42 finished with value: -419184.13280401385 and parameters: {'colsample_bytree': 0.9321536018646652, 'learning_rate': 0.13983130426675267, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 280, 'reg_lambda': 12.39627262066308, 'reg_alpha': 0.010484256957273364, 'sub_sample': 0.6889546583300357}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:54,730]\u001b[0m Trial 43 finished with value: -388479.788175444 and parameters: {'colsample_bytree': 0.8555697819877546, 'learning_rate': 0.2648437922820901, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 235, 'reg_lambda': 0.343687428810037, 'reg_alpha': 2.2263728505801172e-05, 'sub_sample': 0.7637984555550107}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:55,028]\u001b[0m Trial 44 finished with value: -416491.54104814504 and parameters: {'colsample_bytree': 0.2879359304281217, 'learning_rate': 0.10100442799699402, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 6.375157360065057e-06, 'reg_alpha': 0.08569514208179518, 'sub_sample': 0.8895919717364356}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:55,281]\u001b[0m Trial 45 finished with value: -403584.97601282067 and parameters: {'colsample_bytree': 0.9476110213018666, 'learning_rate': 0.17977448073308427, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 208, 'reg_lambda': 4.315567975842778, 'reg_alpha': 0.0002993696572224253, 'sub_sample': 0.5938927233824932}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:55,559]\u001b[0m Trial 46 finished with value: -522022.4844542519 and parameters: {'colsample_bytree': 0.4845710215700522, 'learning_rate': 0.6689636791436582, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 222, 'reg_lambda': 0.002456416076461355, 'reg_alpha': 0.9259990866984308, 'sub_sample': 0.6694194922260203}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:55,810]\u001b[0m Trial 47 finished with value: -408811.48551889067 and parameters: {'colsample_bytree': 0.9707437311118278, 'learning_rate': 0.14050518148787508, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 300, 'reg_lambda': 4.980700912630433e-07, 'reg_alpha': 3.7290845945449633, 'sub_sample': 0.711502204451965}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:56,055]\u001b[0m Trial 48 finished with value: -438049.600065226 and parameters: {'colsample_bytree': 0.8035188672965047, 'learning_rate': 0.8789897792548713, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 267, 'reg_lambda': 0.02574832878730461, 'reg_alpha': 46.958870437524865, 'sub_sample': 0.4534015807900504}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:56,235]\u001b[0m Trial 49 finished with value: -467660.55668510596 and parameters: {'colsample_bytree': 0.7512066133037383, 'learning_rate': 0.2648342219134515, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 286, 'reg_lambda': 0.12839108103791694, 'reg_alpha': 0.24126494485642427, 'sub_sample': 0.7801631937694274}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:56,541]\u001b[0m Trial 50 finished with value: -420633.26014209643 and parameters: {'colsample_bytree': 0.9164362552354796, 'learning_rate': 0.2930733408783438, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 176, 'reg_lambda': 22.33168444109487, 'reg_alpha': 0.0007553767968132281, 'sub_sample': 0.9546617344334454}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:56,785]\u001b[0m Trial 51 finished with value: -384003.57092835096 and parameters: {'colsample_bytree': 0.9116667712635917, 'learning_rate': 0.22620741074092082, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 212, 'reg_lambda': 4.378823167763279e-07, 'reg_alpha': 4.287770007457961e-06, 'sub_sample': 0.7866737624142567}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:57,062]\u001b[0m Trial 52 finished with value: -391175.4319222315 and parameters: {'colsample_bytree': 0.8387046526986363, 'learning_rate': 0.20590340632126675, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 190, 'reg_lambda': 4.1091066243765795e-06, 'reg_alpha': 1.4916074035686872e-07, 'sub_sample': 0.7533929737100159}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:57,373]\u001b[0m Trial 53 finished with value: -385451.6460378403 and parameters: {'colsample_bytree': 0.9647913047248675, 'learning_rate': 0.1419532225529307, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 240, 'reg_lambda': 1.952305126196387e-07, 'reg_alpha': 0.0053442215445635615, 'sub_sample': 0.8637168967309911}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:57,648]\u001b[0m Trial 54 finished with value: -385154.8274781576 and parameters: {'colsample_bytree': 0.6851797202517521, 'learning_rate': 0.18156004586257732, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 259, 'reg_lambda': 5.951303587285836e-05, 'reg_alpha': 2.612056155150916e-06, 'sub_sample': 0.722529199976037}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:57,877]\u001b[0m Trial 55 finished with value: -414224.9923713777 and parameters: {'colsample_bytree': 0.8719624100591262, 'learning_rate': 0.3299623338227901, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 215, 'reg_lambda': 1.3870587678843288e-07, 'reg_alpha': 6.8928029812388735e-06, 'sub_sample': 0.8117314720853577}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:58,203]\u001b[0m Trial 56 finished with value: -394614.61805406096 and parameters: {'colsample_bytree': 0.991911788609755, 'learning_rate': 0.12563324646149981, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 202, 'reg_lambda': 2.9035845595978014, 'reg_alpha': 0.02588631018368281, 'sub_sample': 0.6380783884885907}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:58,491]\u001b[0m Trial 57 finished with value: -409343.9466371579 and parameters: {'colsample_bytree': 0.7805117402923, 'learning_rate': 0.23103413224237992, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 163, 'reg_lambda': 0.5110863332013743, 'reg_alpha': 1.2971994930201008e-08, 'sub_sample': 0.9267005675242314}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:58,768]\u001b[0m Trial 58 finished with value: -413225.49193208676 and parameters: {'colsample_bytree': 0.9211509296756225, 'learning_rate': 0.17667071406577717, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 253, 'reg_lambda': 5.6649971774706665e-08, 'reg_alpha': 0.00021723899714057117, 'sub_sample': 0.5500907150818339}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:59,066]\u001b[0m Trial 59 finished with value: -426655.2015872305 and parameters: {'colsample_bytree': 0.7209139321271754, 'learning_rate': 0.5301017371850506, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 148, 'reg_lambda': 0.05312676322707769, 'reg_alpha': 0.0009961333727417797, 'sub_sample': 0.998877043796576}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:59,289]\u001b[0m Trial 60 finished with value: -400947.26960456005 and parameters: {'colsample_bytree': 0.804434602125679, 'learning_rate': 0.20376151291220415, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 196, 'reg_lambda': 0.0012271165338404793, 'reg_alpha': 22.003261741690917, 'sub_sample': 0.7040444262468591}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:59,551]\u001b[0m Trial 61 finished with value: -407590.2319031289 and parameters: {'colsample_bytree': 0.9055740615079161, 'learning_rate': 0.2528281398415358, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 211, 'reg_lambda': 7.220076363246673e-07, 'reg_alpha': 2.0828696948979726e-06, 'sub_sample': 0.7954583392113428}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:34:59,800]\u001b[0m Trial 62 finished with value: -410004.2371062288 and parameters: {'colsample_bytree': 0.8835824845556413, 'learning_rate': 0.22283079794740882, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 222, 'reg_lambda': 6.515643405720504e-07, 'reg_alpha': 1.488163193902975e-07, 'sub_sample': 0.8583324184756226}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:34:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:00,040]\u001b[0m Trial 63 finished with value: -392835.35532290494 and parameters: {'colsample_bytree': 0.3835000083152824, 'learning_rate': 0.16650358869636447, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 206, 'reg_lambda': 2.825836252717014e-07, 'reg_alpha': 1.5548877256733327e-06, 'sub_sample': 0.7625371838308537}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:00,296]\u001b[0m Trial 64 finished with value: -380957.0772889936 and parameters: {'colsample_bytree': 0.8570140804695525, 'learning_rate': 0.1179655059423341, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 218, 'reg_lambda': 2.7399263322860684e-08, 'reg_alpha': 4.233387870275928e-05, 'sub_sample': 0.6613628461032292}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:00,555]\u001b[0m Trial 65 finished with value: -387368.2266175943 and parameters: {'colsample_bytree': 0.8465787661101589, 'learning_rate': 0.1217406312568278, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 185, 'reg_lambda': 2.0168979947447555e-08, 'reg_alpha': 4.18191035470305e-05, 'sub_sample': 0.6500364716542832}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:00,801]\u001b[0m Trial 66 finished with value: -384821.82520704693 and parameters: {'colsample_bytree': 0.9441181951650787, 'learning_rate': 0.11791322964197433, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 172, 'reg_lambda': 4.994279178417203e-08, 'reg_alpha': 0.003190906870566479, 'sub_sample': 0.6204637632111497}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:01,022]\u001b[0m Trial 67 finished with value: -385991.3264053332 and parameters: {'colsample_bytree': 0.9741696256603042, 'learning_rate': 0.1578556346412761, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 270, 'reg_lambda': 0.00019272052407129, 'reg_alpha': 6.8079502391279734e-06, 'sub_sample': 0.6673097335609582}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:01,268]\u001b[0m Trial 68 finished with value: -452497.66499517823 and parameters: {'colsample_bytree': 0.6586956408014188, 'learning_rate': 0.40514468131401127, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 192, 'reg_lambda': 2.618083658954406e-05, 'reg_alpha': 96.85641246992384, 'sub_sample': 0.5897586342233945}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:01,608]\u001b[0m Trial 69 finished with value: -444124.76598571835 and parameters: {'colsample_bytree': 0.7581696067282273, 'learning_rate': 0.19341911182368332, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 180, 'reg_lambda': 1.1447456414707289, 'reg_alpha': 0.017204933526238517, 'sub_sample': 0.5196332809643409}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:01,891]\u001b[0m Trial 70 finished with value: -399555.1416215578 and parameters: {'colsample_bytree': 0.6131442538259, 'learning_rate': 0.16489120451641728, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 227, 'reg_lambda': 6.9695209466270436e-06, 'reg_alpha': 9.674022013450486e-05, 'sub_sample': 0.5645839857765357}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:02,143]\u001b[0m Trial 71 finished with value: -419232.14038584044 and parameters: {'colsample_bytree': 0.8821413402451089, 'learning_rate': 0.3043303377771406, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 215, 'reg_lambda': 2.6964314742428627e-06, 'reg_alpha': 3.4233877232069803e-07, 'sub_sample': 0.7408411135965572}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:02,407]\u001b[0m Trial 72 finished with value: -394631.5061257157 and parameters: {'colsample_bytree': 0.814166472338707, 'learning_rate': 0.25184473535854446, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 236, 'reg_lambda': 1.2226088923762906e-06, 'reg_alpha': 1.2779484984017221e-05, 'sub_sample': 0.8219630834784692}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:02,648]\u001b[0m Trial 73 finished with value: -409823.0588470744 and parameters: {'colsample_bytree': 0.5517377334462243, 'learning_rate': 0.22330439764785895, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 200, 'reg_lambda': 4.825302923202999e-08, 'reg_alpha': 0.001419701968908963, 'sub_sample': 0.7796243332946542}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:02,908]\u001b[0m Trial 74 finished with value: -382349.71305668587 and parameters: {'colsample_bytree': 0.8620487037834575, 'learning_rate': 0.11820515250108919, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 217, 'reg_lambda': 1.045324884731586e-08, 'reg_alpha': 4.04669822808931e-06, 'sub_sample': 0.7002777131096202}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:03,130]\u001b[0m Trial 75 finished with value: -382011.20435557363 and parameters: {'colsample_bytree': 0.865683700395969, 'learning_rate': 0.10235739382809635, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 220, 'reg_lambda': 1.759642898925278e-08, 'reg_alpha': 1.1384497585120776e-06, 'sub_sample': 0.6971622190034602}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:03,351]\u001b[0m Trial 76 finished with value: -389005.8344534745 and parameters: {'colsample_bytree': 0.8546000819309857, 'learning_rate': 0.12484569783076194, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 218, 'reg_lambda': 1.373420184082014e-08, 'reg_alpha': 4.032503196748415e-06, 'sub_sample': 0.6994847058156263}. Best is trial 18 with value: -379283.625257604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:03,568]\u001b[0m Trial 77 finished with value: -374782.0443093943 and parameters: {'colsample_bytree': 0.7783854310513393, 'learning_rate': 0.10136903379517707, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 225, 'reg_lambda': 8.142000463106808e-08, 'reg_alpha': 9.339643332907624e-07, 'sub_sample': 0.6570799049708295}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:03,757]\u001b[0m Trial 78 finished with value: -473677.8554737834 and parameters: {'colsample_bytree': 0.785016670709755, 'learning_rate': 0.15423800808516167, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 235, 'reg_lambda': 9.245937739932602e-08, 'reg_alpha': 9.97569681128687e-07, 'sub_sample': 0.615158369618919}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:04,000]\u001b[0m Trial 79 finished with value: -392419.0461608747 and parameters: {'colsample_bytree': 0.8179889396358958, 'learning_rate': 0.1115152154345409, 'max_depth': 2, 'min_child_weight': 5, 'n_estimators': 250, 'reg_lambda': 2.8211775739152858e-08, 'reg_alpha': 2.1753620451876834e-07, 'sub_sample': 0.6627509679713397}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:04,222]\u001b[0m Trial 80 finished with value: -381601.1049668147 and parameters: {'colsample_bytree': 0.8628696899937633, 'learning_rate': 0.1277059712854619, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 241, 'reg_lambda': 9.354028540374882e-08, 'reg_alpha': 7.189385740072109e-08, 'sub_sample': 0.7215500847211685}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:04,449]\u001b[0m Trial 81 finished with value: -380029.1673644279 and parameters: {'colsample_bytree': 0.85980662987156, 'learning_rate': 0.13404197864771003, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 242, 'reg_lambda': 9.675465411155254e-08, 'reg_alpha': 6.117384671707984e-07, 'sub_sample': 0.7139515369555087}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:04,663]\u001b[0m Trial 82 finished with value: -380129.16729354515 and parameters: {'colsample_bytree': 0.8719698713234834, 'learning_rate': 0.101900966039534, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 242, 'reg_lambda': 2.1327952145056128e-08, 'reg_alpha': 5.099113277551334e-08, 'sub_sample': 0.7294376910197589}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:04,877]\u001b[0m Trial 83 finished with value: -382212.6576749757 and parameters: {'colsample_bytree': 0.8551742166240357, 'learning_rate': 0.10081380533790116, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 241, 'reg_lambda': 1.0923193015886126e-08, 'reg_alpha': 5.405618902412842e-08, 'sub_sample': 0.7327511669105543}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:05,089]\u001b[0m Trial 84 finished with value: -387250.99729208375 and parameters: {'colsample_bytree': 0.8359270182603822, 'learning_rate': 0.13144838508874793, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 243, 'reg_lambda': 1.0540712947441066e-07, 'reg_alpha': 6.048763983772458e-08, 'sub_sample': 0.7248989933712636}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:05,329]\u001b[0m Trial 85 finished with value: -384751.3572044481 and parameters: {'colsample_bytree': 0.7466143442722494, 'learning_rate': 0.10746944012215237, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 241, 'reg_lambda': 2.5287564159742233e-08, 'reg_alpha': 5.6457096430815295e-08, 'sub_sample': 0.7328281388516267}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:05,551]\u001b[0m Trial 86 finished with value: -380893.3365861265 and parameters: {'colsample_bytree': 0.8866675480248044, 'learning_rate': 0.10288579762070434, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 257, 'reg_lambda': 6.031609015404357e-08, 'reg_alpha': 2.327696250178885e-08, 'sub_sample': 0.6828058368711629}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:05,745]\u001b[0m Trial 87 finished with value: -473535.82684430294 and parameters: {'colsample_bytree': 0.886312376016239, 'learning_rate': 0.14991237320960332, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 260, 'reg_lambda': 7.331487533254004e-08, 'reg_alpha': 1.6759840990305888e-08, 'sub_sample': 0.6762515754105425}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:05,960]\u001b[0m Trial 88 finished with value: -390733.47151415003 and parameters: {'colsample_bytree': 0.7747109644130526, 'learning_rate': 0.17490622529714311, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 250, 'reg_lambda': 3.419642530462204e-08, 'reg_alpha': 7.669968228268627e-07, 'sub_sample': 0.6534820110769525}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:06,182]\u001b[0m Trial 89 finished with value: -396306.09643110307 and parameters: {'colsample_bytree': 0.9341988711603291, 'learning_rate': 0.18978243379632803, 'max_depth': 2, 'min_child_weight': 5, 'n_estimators': 231, 'reg_lambda': 2.022993073849581e-07, 'reg_alpha': 1.0002414858964922e-07, 'sub_sample': 0.5864729704681618}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:06,405]\u001b[0m Trial 90 finished with value: -383573.0639293894 and parameters: {'colsample_bytree': 0.7969025337449216, 'learning_rate': 0.13675390691184172, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 259, 'reg_lambda': 2.095739607895233e-08, 'reg_alpha': 3.4041061033243856e-08, 'sub_sample': 0.6888162074857007}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:06,626]\u001b[0m Trial 91 finished with value: -380935.32868500415 and parameters: {'colsample_bytree': 0.8967917003392426, 'learning_rate': 0.10090447708863487, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 224, 'reg_lambda': 1.6078966300185482e-08, 'reg_alpha': 3.460218915685083e-07, 'sub_sample': 0.7168129491198163}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:06,846]\u001b[0m Trial 92 finished with value: -382579.46444078034 and parameters: {'colsample_bytree': 0.8945754168589253, 'learning_rate': 0.15164136903080325, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 223, 'reg_lambda': 1.0902286458390763e-07, 'reg_alpha': 3.452252662168417e-07, 'sub_sample': 0.7529543001387762}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:07,068]\u001b[0m Trial 93 finished with value: -384395.71793414163 and parameters: {'colsample_bytree': 0.8227483485582661, 'learning_rate': 0.1349226845076626, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 226, 'reg_lambda': 3.6617669492758076e-08, 'reg_alpha': 2.5304300105120212e-08, 'sub_sample': 0.7063069062803388}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:07,284]\u001b[0m Trial 94 finished with value: -381139.38058740494 and parameters: {'colsample_bytree': 0.9301321116190692, 'learning_rate': 0.12060932950243296, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 234, 'reg_lambda': 1.6364593300762439e-07, 'reg_alpha': 5.275585801592239e-07, 'sub_sample': 0.6085317261378345}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:07,501]\u001b[0m Trial 95 finished with value: -383538.71189653105 and parameters: {'colsample_bytree': 0.927951065644639, 'learning_rate': 0.1675259777143369, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 248, 'reg_lambda': 1.785293655781293e-07, 'reg_alpha': 5.393118722388641e-07, 'sub_sample': 0.6103338011723533}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:07,715]\u001b[0m Trial 96 finished with value: -384603.1403495763 and parameters: {'colsample_bytree': 0.9028107613700378, 'learning_rate': 0.12419342424925645, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 255, 'reg_lambda': 1.1177851982557315e-06, 'reg_alpha': 1.2061093148943314e-07, 'sub_sample': 0.6373742586007972}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:07,900]\u001b[0m Trial 97 finished with value: -465885.5250755844 and parameters: {'colsample_bytree': 0.9607795096729332, 'learning_rate': 0.19260783964355332, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 235, 'reg_lambda': 3.144886733006685e-07, 'reg_alpha': 1.0002608605184503e-08, 'sub_sample': 0.6578950059963944}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:08,131]\u001b[0m Trial 98 finished with value: -408931.9556023343 and parameters: {'colsample_bytree': 0.8400108989716151, 'learning_rate': 0.20627551255898102, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 244, 'reg_lambda': 5.52488673634511e-08, 'reg_alpha': 2.3356787301191638e-07, 'sub_sample': 0.6015430678596696}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2022-01-23 09:35:08,328]\u001b[0m Trial 99 finished with value: -474866.36739757354 and parameters: {'colsample_bytree': 0.12621244041302543, 'learning_rate': 0.1503203270086214, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 232, 'reg_lambda': 1.3059892006465084e-07, 'reg_alpha': 9.567454299320424e-08, 'sub_sample': 0.554462174468599}. Best is trial 77 with value: -374782.0443093943.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def xgb(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, Z99_train, y99_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fa38da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7783854310513393,\n",
       " 'learning_rate': 0.10136903379517707,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 225,\n",
       " 'reg_lambda': 8.142000463106808e-08,\n",
       " 'reg_alpha': 9.339643332907624e-07,\n",
       " 'sub_sample': 0.6570799049708295}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "13d86408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:35:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7783854310513393,\n",
       "             enable_categorical=False, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.10136903379517707,\n",
       "             max_delta_step=0, max_depth=2, min_child_weight=4, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=225, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=9.339643332907624e-07, reg_lambda=8.142000463106808e-08,\n",
       "             scale_pos_weight=1, sub_sample=0.6570799049708295, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99 = XGBRegressor(colsample_bytree= 0.7783854310513393, learning_rate= 0.10136903379517707, max_depth= 2, min_child_weight= 4, n_estimators= 225,\n",
    "reg_alpha= 9.339643332907624e-07, reg_lambda=  8.142000463106808e-08, sub_sample= 0.6570799049708295)\n",
    "XGB99.fit(Z99_train, y99_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cef4c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60667498622.44095\n",
      "246307.73155230217\n"
     ]
    }
   ],
   "source": [
    "y_pred_trainXGB99 = XGB99.predict(Z99_train)\n",
    "print(metrics.mean_squared_error(y99_train, y_pred_trainXGB99))\n",
    "print(np.sqrt(metrics.mean_squared_error(y99_train, y_pred_trainXGB99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7da9562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85371547246.47522\n",
      "292184.09820945974\n"
     ]
    }
   ],
   "source": [
    "y_pred_testXGB99 = XGB99.predict(Z99_test)\n",
    "print(metrics.mean_squared_error(y99_test, y_pred_testXGB99))\n",
    "print(np.sqrt(metrics.mean_squared_error(y99_test, y_pred_testXGB99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb90d7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.7011852932085"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(292184.09820945974 - 246307.73155230217)/292184.09820945974*100\n",
    "#XGBoost has an overfit of 15.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84aa7e",
   "metadata": {},
   "source": [
    "### Carrying out RFRegressor for merged_house99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9dc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridseach done multiple times to narrow in the best params\n",
    "rf_params = {\n",
    "    'n_estimators': [40, 41, 42, 43, 44, 45, 46],\n",
    "    'max_depth': [7, 8, 9],\n",
    "}\n",
    "gs99 = GridSearchCV(rf, param_grid=rf_params, cv=5, n_jobs=-1)\n",
    "gs99.fit(Z99_train, y99_train)\n",
    "gs99.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_trainrf99 = gs99.predict(Z99_train)\n",
    "print(metrics.mean_squared_error(y99_train, y_pred_trainrf99))\n",
    "print(np.sqrt(metrics.mean_squared_error(y99_train, y_pred_trainrf99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f532b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_testrf99 = gs99.predict(Z99_test)\n",
    "print(metrics.mean_squared_error(y99_test, y_pred_testrf99))\n",
    "print(np.sqrt(metrics.mean_squared_error(y99_test, y_pred_testrf99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(294383.8916875554 - 205570.62004539958)/ 294383.8916875554 *100\n",
    "#randomforestregressor has an overfit of 30.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8952e",
   "metadata": {},
   "source": [
    "### Carrying out linear regression modelling for freehold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "22b8f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "XFH = freehold.drop(columns =['price', 'unit price psf', 'index', 'project name', 'street name', 'nett price', 'type of area','floor level','date of sale',])\n",
    "yFH = freehold['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bfa68550",
   "metadata": {},
   "outputs": [],
   "source": [
    "XFH_train, XFH_test, yFH_train, yFH_test = train_test_split(XFH, yFH, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1163452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZFH_train = sc.fit_transform(XFH_train)\n",
    "ZFH_test = sc.transform(XFH_test)\n",
    "lr.fit(ZFH_train, yFH_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "eae0ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625210253388.7909\n",
      "790702.3797793902\n"
     ]
    }
   ],
   "source": [
    "y_pred_trainFH = lr.predict(ZFH_train)\n",
    "print(metrics.mean_squared_error(yFH_train, y_pred_trainFH))\n",
    "print(np.sqrt(metrics.mean_squared_error(yFH_train, y_pred_trainFH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a00575fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646643528876.3461\n",
      "804141.4856083139\n"
     ]
    }
   ],
   "source": [
    "y_pred_testFH = lr.predict(ZFH_test)\n",
    "print(metrics.mean_squared_error(yFH_test, y_pred_testFH))\n",
    "print(np.sqrt(metrics.mean_squared_error(yFH_test, y_pred_testFH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d2c5202c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6712364763468694"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(804141.4856083139 - 790702.3797793902)/804141.4856083139 *100\n",
    "# 1.67% overfitting for linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2650ba8",
   "metadata": {},
   "source": [
    "### A check on XGboost for Freehold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da55da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, ZFH_train, yFH_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fcf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBFH = XGBRegressor(colsample_bytree= 0.7201850925222163, learning_rate= 0.17608220702170052, max_depth= 5, min_child_weight= 3, n_estimators= 207,\n",
    "reg_alpha= 1.9607720235176794e-05, reg_lambda=  0.004880134787889033, sub_sample= 0.5508939665995031)\n",
    "XGBFH.fit(ZFH_train, yFH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_trainXGBFH = XGBFH.predict(ZFH_train)\n",
    "print(metrics.mean_squared_error(yFH_train, y_pred_trainXGBFH))\n",
    "print(np.sqrt(metrics.mean_squared_error(yFH_train, y_pred_trainXGBFH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bce79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_testXGBFH = XGBFH.predict(ZFH_test)\n",
    "print(metrics.mean_squared_error(yFH_test, y_pred_testXGBFH))\n",
    "print(np.sqrt(metrics.mean_squared_error(yFH_test, y_pred_testXGBFH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "(757237.371209825 -581159.1893095195)/757237.371209825 *100\n",
    "# XGboost is overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65924601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
