{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16dc9539",
   "metadata": {},
   "source": [
    "## Using price to predict the house price instead of psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405c9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import re\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn import metrics,linear_model\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression,Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60604950",
   "metadata": {},
   "source": [
    "## Using previous data for merged_house1Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f50dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_house1 = pd.read_csv('./dataset_asof_051121/merged_house1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f313e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d80bf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9726, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d9b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project name</th>\n",
       "      <th>street name</th>\n",
       "      <th>tenure</th>\n",
       "      <th>type of sale</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>price</th>\n",
       "      <th>nett price</th>\n",
       "      <th>areasq</th>\n",
       "      <th>type of area</th>\n",
       "      <th>floor level</th>\n",
       "      <th>unit price psf</th>\n",
       "      <th>date of sale</th>\n",
       "      <th>market segment_CCR</th>\n",
       "      <th>market segment_OCR</th>\n",
       "      <th>market segment_RCR</th>\n",
       "      <th>postal district_2.0</th>\n",
       "      <th>postal district_3.0</th>\n",
       "      <th>postal district_4.0</th>\n",
       "      <th>postal district_5.0</th>\n",
       "      <th>postal district_8.0</th>\n",
       "      <th>postal district_9.0</th>\n",
       "      <th>postal district_10.0</th>\n",
       "      <th>postal district_11.0</th>\n",
       "      <th>postal district_12.0</th>\n",
       "      <th>postal district_13.0</th>\n",
       "      <th>postal district_14.0</th>\n",
       "      <th>postal district_15.0</th>\n",
       "      <th>postal district_16.0</th>\n",
       "      <th>postal district_17.0</th>\n",
       "      <th>postal district_18.0</th>\n",
       "      <th>postal district_19.0</th>\n",
       "      <th>postal district_20.0</th>\n",
       "      <th>postal district_21.0</th>\n",
       "      <th>postal district_22.0</th>\n",
       "      <th>postal district_23.0</th>\n",
       "      <th>postal district_25.0</th>\n",
       "      <th>postal district_26.0</th>\n",
       "      <th>postal district_27.0</th>\n",
       "      <th>postal district_28.0</th>\n",
       "      <th>type_Detached</th>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <th>type_Terrace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>PASIR PANJANG DRIVE</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3660000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>Oct-2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OCEAN 8</td>\n",
       "      <td>OCEAN DRIVE</td>\n",
       "      <td>83</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6920000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>3852.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>Oct-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>OCEAN DRIVE</td>\n",
       "      <td>83</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17888000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>8746.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>Oct-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WEST COAST GARDENS</td>\n",
       "      <td>WEST COAST PARK</td>\n",
       "      <td>863</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5400000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>4806.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>Oct-2021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>JALAN MAS KUNING</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2660000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>Oct-2021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                project name          street name  tenure  \\\n",
       "0      0  LANDED HOUSING DEVELOPMENT  PASIR PANJANG DRIVE     999   \n",
       "1      1                     OCEAN 8          OCEAN DRIVE      83   \n",
       "2      2  LANDED HOUSING DEVELOPMENT          OCEAN DRIVE      83   \n",
       "3      3          WEST COAST GARDENS      WEST COAST PARK     863   \n",
       "4      4  LANDED HOUSING DEVELOPMENT     JALAN MAS KUNING     999   \n",
       "\n",
       "  type of sale  no. of units       price nett price  areasq type of area  \\\n",
       "0       Resale           1.0   3660000.0          -  2566.0         Land   \n",
       "1       Resale           1.0   6920000.0          -  3852.0         Land   \n",
       "2       Resale           1.0  17888000.0          -  8746.0         Land   \n",
       "3       Resale           1.0   5400000.0          -  4806.0         Land   \n",
       "4       Resale           1.0   2660000.0          -  1640.0         Land   \n",
       "\n",
       "  floor level  unit price psf date of sale  market segment_CCR  \\\n",
       "0           -          1426.0     Oct-2021                   0   \n",
       "1           -          1796.0     Oct-2021                   1   \n",
       "2           -          2045.0     Oct-2021                   1   \n",
       "3           -          1124.0     Oct-2021                   0   \n",
       "4           -          1622.0     Oct-2021                   0   \n",
       "\n",
       "   market segment_OCR  market segment_RCR  postal district_2.0  \\\n",
       "0                   0                   1                    0   \n",
       "1                   0                   0                    0   \n",
       "2                   0                   0                    0   \n",
       "3                   1                   0                    0   \n",
       "4                   1                   0                    0   \n",
       "\n",
       "   postal district_3.0  postal district_4.0  postal district_5.0  \\\n",
       "0                    0                    0                    1   \n",
       "1                    0                    1                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    0                    1   \n",
       "4                    0                    0                    1   \n",
       "\n",
       "   postal district_8.0  postal district_9.0  postal district_10.0  \\\n",
       "0                    0                    0                     0   \n",
       "1                    0                    0                     0   \n",
       "2                    0                    0                     0   \n",
       "3                    0                    0                     0   \n",
       "4                    0                    0                     0   \n",
       "\n",
       "   postal district_11.0  postal district_12.0  postal district_13.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_14.0  postal district_15.0  postal district_16.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_17.0  postal district_18.0  postal district_19.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_20.0  postal district_21.0  postal district_22.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_23.0  postal district_25.0  postal district_26.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_27.0  postal district_28.0  type_Detached  \\\n",
       "0                     0                     0              0   \n",
       "1                     0                     0              0   \n",
       "2                     0                     0              1   \n",
       "3                     0                     0              0   \n",
       "4                     0                     0              0   \n",
       "\n",
       "   type_Semi-detached  type_Terrace  \n",
       "0                   0             1  \n",
       "1                   0             1  \n",
       "2                   0             0  \n",
       "3                   1             0  \n",
       "4                   0             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedfc4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project name</th>\n",
       "      <th>street name</th>\n",
       "      <th>tenure</th>\n",
       "      <th>type of sale</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>price</th>\n",
       "      <th>nett price</th>\n",
       "      <th>areasq</th>\n",
       "      <th>type of area</th>\n",
       "      <th>floor level</th>\n",
       "      <th>unit price psf</th>\n",
       "      <th>date of sale</th>\n",
       "      <th>market segment_CCR</th>\n",
       "      <th>market segment_OCR</th>\n",
       "      <th>market segment_RCR</th>\n",
       "      <th>postal district_2.0</th>\n",
       "      <th>postal district_3.0</th>\n",
       "      <th>postal district_4.0</th>\n",
       "      <th>postal district_5.0</th>\n",
       "      <th>postal district_8.0</th>\n",
       "      <th>postal district_9.0</th>\n",
       "      <th>postal district_10.0</th>\n",
       "      <th>postal district_11.0</th>\n",
       "      <th>postal district_12.0</th>\n",
       "      <th>postal district_13.0</th>\n",
       "      <th>postal district_14.0</th>\n",
       "      <th>postal district_15.0</th>\n",
       "      <th>postal district_16.0</th>\n",
       "      <th>postal district_17.0</th>\n",
       "      <th>postal district_18.0</th>\n",
       "      <th>postal district_19.0</th>\n",
       "      <th>postal district_20.0</th>\n",
       "      <th>postal district_21.0</th>\n",
       "      <th>postal district_22.0</th>\n",
       "      <th>postal district_23.0</th>\n",
       "      <th>postal district_25.0</th>\n",
       "      <th>postal district_26.0</th>\n",
       "      <th>postal district_27.0</th>\n",
       "      <th>postal district_28.0</th>\n",
       "      <th>type_Detached</th>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <th>type_Terrace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9721</th>\n",
       "      <td>9723</td>\n",
       "      <td>MIMOSA TERRACE</td>\n",
       "      <td>MIMOSA VIEW</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2330000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1616.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>Nov-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9722</th>\n",
       "      <td>9724</td>\n",
       "      <td>SARACA VILLAS</td>\n",
       "      <td>SARACA TERRACE</td>\n",
       "      <td>75</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1675000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>695.0</td>\n",
       "      <td>Nov-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9723</th>\n",
       "      <td>9725</td>\n",
       "      <td>GERALD GARDENS</td>\n",
       "      <td>GERALD CRESCENT</td>\n",
       "      <td>857</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2980000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>4192.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>711.0</td>\n",
       "      <td>Nov-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>9726</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>JALAN SANKAM</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>834.0</td>\n",
       "      <td>Nov-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9725</th>\n",
       "      <td>9727</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>NIM ROAD</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10300000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>9955.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>Nov-2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                project name      street name  tenure type of sale  \\\n",
       "9721   9723              MIMOSA TERRACE      MIMOSA VIEW     999       Resale   \n",
       "9722   9724               SARACA VILLAS   SARACA TERRACE      75       Resale   \n",
       "9723   9725              GERALD GARDENS  GERALD CRESCENT     857       Resale   \n",
       "9724   9726  LANDED HOUSING DEVELOPMENT     JALAN SANKAM     999       Resale   \n",
       "9725   9727  LANDED HOUSING DEVELOPMENT         NIM ROAD     999       Resale   \n",
       "\n",
       "      no. of units       price nett price  areasq type of area floor level  \\\n",
       "9721           1.0   2330000.0          -  1616.0         Land           -   \n",
       "9722           1.0   1675000.0          -  2410.0         Land           -   \n",
       "9723           1.0   2980000.0          -  4192.0         Land           -   \n",
       "9724           1.0   1750000.0          -  2099.0         Land           -   \n",
       "9725           1.0  10300000.0          -  9955.0         Land           -   \n",
       "\n",
       "      unit price psf date of sale  market segment_CCR  market segment_OCR  \\\n",
       "9721          1442.0     Nov-2016                   0                   1   \n",
       "9722           695.0     Nov-2016                   0                   1   \n",
       "9723           711.0     Nov-2016                   0                   1   \n",
       "9724           834.0     Nov-2016                   0                   1   \n",
       "9725          1035.0     Nov-2016                   0                   1   \n",
       "\n",
       "      market segment_RCR  postal district_2.0  postal district_3.0  \\\n",
       "9721                   0                    0                    0   \n",
       "9722                   0                    0                    0   \n",
       "9723                   0                    0                    0   \n",
       "9724                   0                    0                    0   \n",
       "9725                   0                    0                    0   \n",
       "\n",
       "      postal district_4.0  postal district_5.0  postal district_8.0  \\\n",
       "9721                    0                    0                    0   \n",
       "9722                    0                    0                    0   \n",
       "9723                    0                    0                    0   \n",
       "9724                    0                    0                    0   \n",
       "9725                    0                    0                    0   \n",
       "\n",
       "      postal district_9.0  postal district_10.0  postal district_11.0  \\\n",
       "9721                    0                     0                     0   \n",
       "9722                    0                     0                     0   \n",
       "9723                    0                     0                     0   \n",
       "9724                    0                     0                     0   \n",
       "9725                    0                     0                     0   \n",
       "\n",
       "      postal district_12.0  postal district_13.0  postal district_14.0  \\\n",
       "9721                     0                     0                     0   \n",
       "9722                     0                     0                     0   \n",
       "9723                     0                     0                     0   \n",
       "9724                     0                     0                     0   \n",
       "9725                     0                     0                     0   \n",
       "\n",
       "      postal district_15.0  postal district_16.0  postal district_17.0  \\\n",
       "9721                     0                     0                     0   \n",
       "9722                     0                     0                     0   \n",
       "9723                     0                     0                     0   \n",
       "9724                     0                     0                     0   \n",
       "9725                     0                     0                     0   \n",
       "\n",
       "      postal district_18.0  postal district_19.0  postal district_20.0  \\\n",
       "9721                     0                     0                     0   \n",
       "9722                     0                     0                     0   \n",
       "9723                     0                     0                     0   \n",
       "9724                     0                     0                     0   \n",
       "9725                     0                     0                     0   \n",
       "\n",
       "      postal district_21.0  postal district_22.0  postal district_23.0  \\\n",
       "9721                     0                     0                     0   \n",
       "9722                     0                     0                     0   \n",
       "9723                     0                     0                     0   \n",
       "9724                     0                     0                     0   \n",
       "9725                     0                     0                     0   \n",
       "\n",
       "      postal district_25.0  postal district_26.0  postal district_27.0  \\\n",
       "9721                     0                     0                     0   \n",
       "9722                     0                     0                     0   \n",
       "9723                     0                     0                     0   \n",
       "9724                     0                     0                     1   \n",
       "9725                     0                     0                     0   \n",
       "\n",
       "      postal district_28.0  type_Detached  type_Semi-detached  type_Terrace  \n",
       "9721                     1              0                   0             1  \n",
       "9722                     1              0                   0             1  \n",
       "9723                     1              0                   0             1  \n",
       "9724                     0              0                   1             0  \n",
       "9725                     1              1                   0             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe974a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house1['type of area'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882e4103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize =(5,10))\n",
    "sns.heatmap(merged_house1.corr()[['unit price psf']].sort_values('unit price psf', ascending =False), annot=True, vmin = -1, vmax = 1, cmap = 'coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a488b2d7",
   "metadata": {},
   "source": [
    "### Doing Modelling for merged_house1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71e7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_house1.drop(columns = ['price','unit price psf','project name','street name','type of sale','nett price', 'type of area', 'floor level','date of sale', 'index'])\n",
    "y = merged_house1['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d983e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d28b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "lr = LinearRegression()\n",
    "#fit using the training data\n",
    "lr.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ac06de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313279cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit using the training data\n",
    "lr.fit(Z_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e21d58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8090571003491375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "390aaf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8399817227504702"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc4f720",
   "metadata": {},
   "source": [
    "Results is overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f509b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e700663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8090571003491375\n",
      "5864529886207.752\n",
      "2421679.1460075285\n"
     ]
    }
   ],
   "source": [
    "print(metrics.r2_score(y_train, y_pred))\n",
    "print(metrics.mean_squared_error(y_train, y_pred))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3c5f6",
   "metadata": {},
   "source": [
    "## Doing a lasso to see if overfit is reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd661232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State the parameters you want to search for lasso regularisation\n",
    "# we want to go through 1000 different alpha values\n",
    "parameters = {\n",
    "                'alpha': [x/1 for x in range(1000)]\n",
    "             }\n",
    "\n",
    "# Instantiate the model\n",
    "lasso = Lasso()\n",
    "\n",
    "# Instantiate Gridsearch (use previous instantiated parameters and model)\n",
    "lasso_lr = GridSearchCV(lasso, parameters, \n",
    "                     scoring='neg_mean_squared_error', \n",
    "                     cv=5, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18db7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    }
   ],
   "source": [
    "lasso_lr.fit(Z_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6ac69c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 999.0}\n"
     ]
    }
   ],
   "source": [
    "print(lasso_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c8966af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = linear_model.Lasso(alpha = 1, max_iter=10000000, tol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d08668a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1, max_iter=10000000, tol=0.1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ddb05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8088660010559834"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfdf5ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8429568745262974"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c24644a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d34d18e2b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_train, y_pred, s = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfe2c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred, y_train - y_pred, s=5)\n",
    "plt.axhline(0, color ='orange');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf993bb",
   "metadata": {},
   "source": [
    "Line assumption is fine, but there a few outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e498a3",
   "metadata": {},
   "source": [
    "## Using XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31cd1c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBRegressor()\n",
    "XGB.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff43ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-15 01:51:34,137]\u001b[0m A new study created in memory with name: no-name-d0f7e543-d6af-40ba-a8dd-7e0c48336ffb\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:34,694]\u001b[0m Trial 0 finished with value: -3653829.9179255604 and parameters: {'colsample_bytree': 0.4370861069626263, 'learning_rate': 0.9556428757689246, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 131, 'reg_lambda': 3.6303224667798554e-07, 'reg_alpha': 3.809220577048033e-08, 'sub_sample': 0.8795585311974417}. Best is trial 0 with value: -3653829.9179255604.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:35,027]\u001b[0m Trial 1 finished with value: -3638384.5554964487 and parameters: {'colsample_bytree': 0.6410035105688879, 'learning_rate': 0.737265320016441, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 267, 'reg_lambda': 1.3285903900544182e-06, 'reg_alpha': 6.580360277501306e-07, 'sub_sample': 0.2650640588680905}. Best is trial 1 with value: -3638384.5554964487.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:35,492]\u001b[0m Trial 2 finished with value: -3436595.485875581 and parameters: {'colsample_bytree': 0.373818018663584, 'learning_rate': 0.5722807884690141, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 222, 'reg_lambda': 2.4827821051950883e-07, 'reg_alpha': 8.345387083873532e-06, 'sub_sample': 0.4297256589643226}. Best is trial 2 with value: -3436595.485875581.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:35,786]\u001b[0m Trial 3 finished with value: -3421622.87928332 and parameters: {'colsample_bytree': 0.5104629857953323, 'learning_rate': 0.8066583652537123, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 219, 'reg_lambda': 2.9140978279786215e-08, 'reg_alpha': 0.011897302909454906, 'sub_sample': 0.2534717113185624}. Best is trial 3 with value: -3421622.87928332.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:36,277]\u001b[0m Trial 4 finished with value: -3819217.4062938616 and parameters: {'colsample_bytree': 0.1585464336867516, 'learning_rate': 0.9539969835279999, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 161, 'reg_lambda': 9.478096804784244e-08, 'reg_alpha': 0.06955530592645753, 'sub_sample': 0.4961372443656412}. Best is trial 3 with value: -3421622.87928332.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:36,558]\u001b[0m Trial 5 finished with value: -3466709.5011096303 and parameters: {'colsample_bytree': 0.20983441136030095, 'learning_rate': 0.5456592191001431, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 152, 'reg_lambda': 0.042191293826476094, 'reg_alpha': 1.3095158546031483e-05, 'sub_sample': 0.5680612190600297}. Best is trial 3 with value: -3421622.87928332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:37,279]\u001b[0m Trial 6 finished with value: -3392310.237382342 and parameters: {'colsample_bytree': 0.5920392514089517, 'learning_rate': 0.26636900997297436, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 288, 'reg_lambda': 8.8771488946556, 'reg_alpha': 0.00952795699161383, 'sub_sample': 0.9296868115208051}. Best is trial 6 with value: -3392310.237382342.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:37,562]\u001b[0m Trial 7 finished with value: -3578969.6349956864 and parameters: {'colsample_bytree': 0.17964325184672755, 'learning_rate': 0.27638457617723067, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 178, 'reg_lambda': 5.169997317292732e-06, 'reg_alpha': 1.9380951355796903, 'sub_sample': 0.4210779940242304}. Best is trial 6 with value: -3392310.237382342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:37,860]\u001b[0m Trial 8 finished with value: -3579021.7293031877 and parameters: {'colsample_bytree': 0.3528410587186427, 'learning_rate': 0.5884264748424236, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 114, 'reg_lambda': 73.9382838287635, 'reg_alpha': 0.5277736371601186, 'sub_sample': 0.2788441133807552}. Best is trial 6 with value: -3392310.237382342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:38,262]\u001b[0m Trial 9 finished with value: -3584536.171820134 and parameters: {'colsample_bytree': 0.10496990541124217, 'learning_rate': 0.8339152856093507, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 255, 'reg_lambda': 5.50106171658889e-08, 'reg_alpha': 3.842884090673403e-05, 'sub_sample': 0.20428215357261675}. Best is trial 6 with value: -3392310.237382342.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:39,120]\u001b[0m Trial 10 finished with value: -3243361.8712023343 and parameters: {'colsample_bytree': 0.9497157666716347, 'learning_rate': 0.10539746466023536, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 297, 'reg_lambda': 11.930206277066471, 'reg_alpha': 39.6011191452442, 'sub_sample': 0.9790910709802578}. Best is trial 10 with value: -3243361.8712023343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:40,075]\u001b[0m Trial 11 finished with value: -3652101.0481246626 and parameters: {'colsample_bytree': 0.9522656887511342, 'learning_rate': 0.10326321505087403, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 82.82843195255043, 'reg_alpha': 73.24607527580478, 'sub_sample': 0.971643831619738}. Best is trial 10 with value: -3243361.8712023343.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:40,856]\u001b[0m Trial 12 finished with value: -3763672.3550362876 and parameters: {'colsample_bytree': 0.9925005566564994, 'learning_rate': 0.10376349477481495, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 0.5154377331302434, 'reg_alpha': 90.4650741825025, 'sub_sample': 0.7633847055950665}. Best is trial 10 with value: -3243361.8712023343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:41,722]\u001b[0m Trial 13 finished with value: -3593313.0165543063 and parameters: {'colsample_bytree': 0.7310463358543839, 'learning_rate': 0.31176902969578846, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 256, 'reg_lambda': 0.7443377343642432, 'reg_alpha': 0.0006426234450833537, 'sub_sample': 0.7339148735304308}. Best is trial 10 with value: -3243361.8712023343.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:42,342]\u001b[0m Trial 14 finished with value: -3578540.7607633183 and parameters: {'colsample_bytree': 0.8333053471044078, 'learning_rate': 0.26682484317247296, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 275, 'reg_lambda': 0.0014616829044245118, 'reg_alpha': 0.004929458493315183, 'sub_sample': 0.9964152904250921}. Best is trial 10 with value: -3243361.8712023343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:43,128]\u001b[0m Trial 15 finished with value: -3308586.5233633756 and parameters: {'colsample_bytree': 0.8218224088720183, 'learning_rate': 0.37686433229944233, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 232, 'reg_lambda': 2.8786246481953217, 'reg_alpha': 3.0431882979437432, 'sub_sample': 0.7851478927791123}. Best is trial 10 with value: -3243361.8712023343.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:43,838]\u001b[0m Trial 16 finished with value: -3427643.2170599727 and parameters: {'colsample_bytree': 0.8300082366989441, 'learning_rate': 0.4163694923198906, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 234, 'reg_lambda': 0.006296946006763938, 'reg_alpha': 4.789507740537253, 'sub_sample': 0.8056150707789428}. Best is trial 10 with value: -3243361.8712023343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:44,292]\u001b[0m Trial 17 finished with value: -3685118.0003457647 and parameters: {'colsample_bytree': 0.8555853425344547, 'learning_rate': 0.4261430022547306, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 196, 'reg_lambda': 7.721327045288563e-05, 'reg_alpha': 10.049590553539232, 'sub_sample': 0.6396767599776616}. Best is trial 10 with value: -3243361.8712023343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:44,839]\u001b[0m Trial 18 finished with value: -3230336.820273203 and parameters: {'colsample_bytree': 0.7128291728821952, 'learning_rate': 0.1868014632124125, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 238, 'reg_lambda': 0.9018844622615715, 'reg_alpha': 0.2138992180017996, 'sub_sample': 0.8327892453883639}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:45,439]\u001b[0m Trial 19 finished with value: -3646399.799193638 and parameters: {'colsample_bytree': 0.6424637894129267, 'learning_rate': 0.18288821672568478, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 198, 'reg_lambda': 0.03801017743277758, 'reg_alpha': 0.18006514854225758, 'sub_sample': 0.6665832542291555}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:45,873]\u001b[0m Trial 20 finished with value: -3430499.8034853213 and parameters: {'colsample_bytree': 0.710693796171783, 'learning_rate': 0.1902556850703867, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 250, 'reg_lambda': 0.1123125688513539, 'reg_alpha': 0.00029054946794909085, 'sub_sample': 0.8798333007753495}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:46,593]\u001b[0m Trial 21 finished with value: -3325532.580663359 and parameters: {'colsample_bytree': 0.9073312088116371, 'learning_rate': 0.38675229409787415, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 234, 'reg_lambda': 4.260415724804807, 'reg_alpha': 12.373733333251003, 'sub_sample': 0.8469591450394428}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:47,038]\u001b[0m Trial 22 finished with value: -3287945.3970402544 and parameters: {'colsample_bytree': 0.760951959930388, 'learning_rate': 0.18305596599387378, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 216, 'reg_lambda': 5.8917055040809, 'reg_alpha': 0.7990215579927525, 'sub_sample': 0.7302590499248149}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:47,475]\u001b[0m Trial 23 finished with value: -3378695.7210208895 and parameters: {'colsample_bytree': 0.7434296542038467, 'learning_rate': 0.15702256463388123, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 209, 'reg_lambda': 19.818483513846445, 'reg_alpha': 0.1022041594842201, 'sub_sample': 0.703791790951311}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:47,953]\u001b[0m Trial 24 finished with value: -3255754.036539368 and parameters: {'colsample_bytree': 0.7539345172716326, 'learning_rate': 0.19853790114207678, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 177, 'reg_lambda': 0.45409031916286746, 'reg_alpha': 0.6455443038044729, 'sub_sample': 0.9140423075260493}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:48,541]\u001b[0m Trial 25 finished with value: -3393913.984569293 and parameters: {'colsample_bytree': 0.9134501664964756, 'learning_rate': 0.47283716310954826, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 172, 'reg_lambda': 0.4707349227518258, 'reg_alpha': 0.03586606781184472, 'sub_sample': 0.9310937241454367}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:48,974]\u001b[0m Trial 26 finished with value: -3655200.2154896134 and parameters: {'colsample_bytree': 0.6607284138389128, 'learning_rate': 0.3240036637587306, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 186, 'reg_lambda': 0.007459233134914333, 'reg_alpha': 34.56689329496442, 'sub_sample': 0.9996429385893904}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:49,493]\u001b[0m Trial 27 finished with value: -3418546.043363226 and parameters: {'colsample_bytree': 0.5438448132591432, 'learning_rate': 0.2292674928560706, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 148, 'reg_lambda': 0.00010568190775722363, 'reg_alpha': 0.6898198774157775, 'sub_sample': 0.8378839432105791}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:49,943]\u001b[0m Trial 28 finished with value: -3713824.930601521 and parameters: {'colsample_bytree': 0.7784080443040535, 'learning_rate': 0.10023590107424163, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 276, 'reg_lambda': 0.14696084640254822, 'reg_alpha': 0.002638074183387561, 'sub_sample': 0.9099544541051876}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:50,508]\u001b[0m Trial 29 finished with value: -3506313.206500389 and parameters: {'colsample_bytree': 0.8967764362028962, 'learning_rate': 0.49615734886224483, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 124, 'reg_lambda': 1.765914845865597, 'reg_alpha': 15.532055237873978, 'sub_sample': 0.5987931519938687}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:51,022]\u001b[0m Trial 30 finished with value: -3236750.982377795 and parameters: {'colsample_bytree': 0.48592757988059426, 'learning_rate': 0.6485441231867455, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 136, 'reg_lambda': 29.20246367905952, 'reg_alpha': 2.67578861029397e-08, 'sub_sample': 0.8854383553682931}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:51,524]\u001b[0m Trial 31 finished with value: -3278304.1065296456 and parameters: {'colsample_bytree': 0.49879263053368006, 'learning_rate': 0.7344290290006427, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 141, 'reg_lambda': 22.134689119475148, 'reg_alpha': 3.4190464442812367e-08, 'sub_sample': 0.8688458684673117}. Best is trial 18 with value: -3230336.820273203.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:52,033]\u001b[0m Trial 32 finished with value: -3196189.372999428 and parameters: {'colsample_bytree': 0.5969574919026831, 'learning_rate': 0.6880281501298231, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 104, 'reg_lambda': 38.58653463026681, 'reg_alpha': 2.76333640270398e-06, 'sub_sample': 0.9387448522909138}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:52,504]\u001b[0m Trial 33 finished with value: -3328773.9384669308 and parameters: {'colsample_bytree': 0.4307300720969396, 'learning_rate': 0.6810436404458204, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 104, 'reg_lambda': 29.9290684137836, 'reg_alpha': 4.810834339604104e-07, 'sub_sample': 0.8271295237372428}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:52,985]\u001b[0m Trial 34 finished with value: -3338096.2923575738 and parameters: {'colsample_bytree': 0.3249690607750012, 'learning_rate': 0.64492889772695, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 11.599381734144524, 'reg_alpha': 2.1506903324493368e-07, 'sub_sample': 0.9457673422423805}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:53,557]\u001b[0m Trial 35 finished with value: -3266490.1522544073 and parameters: {'colsample_bytree': 0.43987603809703346, 'learning_rate': 0.8308136123818237, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 126, 'reg_lambda': 61.13295357156787, 'reg_alpha': 1.7259666034048018e-08, 'sub_sample': 0.8858412322197391}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:54,089]\u001b[0m Trial 36 finished with value: -3502321.0307609243 and parameters: {'colsample_bytree': 0.592098856598171, 'learning_rate': 0.7473665754414685, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 135, 'reg_lambda': 1.1740123076822984, 'reg_alpha': 2.2425061219121132e-06, 'sub_sample': 0.9599093106406242}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:54,579]\u001b[0m Trial 37 finished with value: -3522630.733932586 and parameters: {'colsample_bytree': 0.46819540862444464, 'learning_rate': 0.9072135162703617, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 119, 'reg_lambda': 7.093936471828321, 'reg_alpha': 2.1280966148576956e-07, 'sub_sample': 0.5054800128652284}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:55,125]\u001b[0m Trial 38 finished with value: -3629892.1356702163 and parameters: {'colsample_bytree': 0.28447391160635205, 'learning_rate': 0.6256037597454669, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 109, 'reg_lambda': 1.0633582693547669e-08, 'reg_alpha': 4.491386534035797e-05, 'sub_sample': 0.771642098624415}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:55,924]\u001b[0m Trial 39 finished with value: -3832131.3585946076 and parameters: {'colsample_bytree': 0.5793390813812216, 'learning_rate': 0.7654250195953115, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 161, 'reg_lambda': 0.12124757727726508, 'reg_alpha': 1.765089769260634e-06, 'sub_sample': 0.41203474324417466}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:56,507]\u001b[0m Trial 40 finished with value: -3252517.070844873 and parameters: {'colsample_bytree': 0.685571913392898, 'learning_rate': 0.541305750911155, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 268, 'reg_lambda': 96.03475349338265, 'reg_alpha': 1.0889132100364863e-08, 'sub_sample': 0.32643334647637634}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:57,061]\u001b[0m Trial 41 finished with value: -3245108.845618172 and parameters: {'colsample_bytree': 0.6734697445863924, 'learning_rate': 0.697092253452637, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 282, 'reg_lambda': 82.37191505087657, 'reg_alpha': 8.795085129482494e-08, 'sub_sample': 0.33085011517269497}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:57,705]\u001b[0m Trial 42 finished with value: -3353800.4256664915 and parameters: {'colsample_bytree': 0.6201867316311669, 'learning_rate': 0.6955352013807151, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 284, 'reg_lambda': 29.984126656862536, 'reg_alpha': 6.739252556995194e-08, 'sub_sample': 0.34962911075200526}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:58,426]\u001b[0m Trial 43 finished with value: -3491850.2753103124 and parameters: {'colsample_bytree': 0.5346333635540002, 'learning_rate': 0.5899808916733155, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 284, 'reg_lambda': 2.7257805388328644, 'reg_alpha': 1.1950026499689013e-07, 'sub_sample': 0.48748617475330003}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:58,978]\u001b[0m Trial 44 finished with value: -3314418.849098258 and parameters: {'colsample_bytree': 0.4022496039480186, 'learning_rate': 0.6482064846016438, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 253, 'reg_lambda': 11.85897034923336, 'reg_alpha': 2.246502312795357e-06, 'sub_sample': 0.9595378364687754}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:51:59,525]\u001b[0m Trial 45 finished with value: -3310712.4996263497 and parameters: {'colsample_bytree': 0.49619062221810917, 'learning_rate': 0.8590543734467478, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 243, 'reg_lambda': 34.9118309511586, 'reg_alpha': 2.200351645604305e-05, 'sub_sample': 0.2126476494779114}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:51:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:00,259]\u001b[0m Trial 46 finished with value: -3517045.38024228 and parameters: {'colsample_bytree': 0.9946965905856978, 'learning_rate': 0.6871451717372487, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 299, 'reg_lambda': 9.256151863141625, 'reg_alpha': 6.949467373243951e-06, 'sub_sample': 0.15892331758788547}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:00,744]\u001b[0m Trial 47 finished with value: -3409765.598267585 and parameters: {'colsample_bytree': 0.6847334472928109, 'learning_rate': 0.7848442186854089, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 270, 'reg_lambda': 1.5026981899247689e-06, 'reg_alpha': 8.211186440378835e-07, 'sub_sample': 0.8939120221781262}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:01,525]\u001b[0m Trial 48 finished with value: -3597465.983705889 and parameters: {'colsample_bytree': 0.5843072092609821, 'learning_rate': 0.5228579688920437, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 288, 'reg_lambda': 1.50750099853838, 'reg_alpha': 0.0002715471192123556, 'sub_sample': 0.8068273416189301}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:02,064]\u001b[0m Trial 49 finished with value: -3269236.1828375272 and parameters: {'colsample_bytree': 0.5559749761699224, 'learning_rate': 0.5949396282197981, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 261, 'reg_lambda': 86.06409813598013, 'reg_alpha': 3.24560880209994e-08, 'sub_sample': 0.5610249545868908}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:02,800]\u001b[0m Trial 50 finished with value: -3641177.1860866537 and parameters: {'colsample_bytree': 0.8013837687473306, 'learning_rate': 0.9889298712426184, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 223, 'reg_lambda': 4.196769592497524, 'reg_alpha': 7.973221529387774e-08, 'sub_sample': 0.9815163763630078}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:03,352]\u001b[0m Trial 51 finished with value: -3722151.2768672532 and parameters: {'colsample_bytree': 0.685552937603717, 'learning_rate': 0.13444064619696822, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 266, 'reg_lambda': 95.29188422257013, 'reg_alpha': 1.262791058442647e-08, 'sub_sample': 0.3140153010247233}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:03,908]\u001b[0m Trial 52 finished with value: -3204960.9077872196 and parameters: {'colsample_bytree': 0.6439617703177369, 'learning_rate': 0.5435976650322426, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 282, 'reg_lambda': 38.867998744319536, 'reg_alpha': 1.1730534818373887e-08, 'sub_sample': 0.32153006666897627}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:04,490]\u001b[0m Trial 53 finished with value: -3213025.074049854 and parameters: {'colsample_bytree': 0.625678624245619, 'learning_rate': 0.7101217420159471, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 292, 'reg_lambda': 16.761787377510927, 'reg_alpha': 2.876131148097432e-07, 'sub_sample': 0.37283644612854583}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:05,036]\u001b[0m Trial 54 finished with value: -3393123.012132382 and parameters: {'colsample_bytree': 0.6197426892988571, 'learning_rate': 0.7326979122583437, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 293, 'reg_lambda': 18.55117841450114, 'reg_alpha': 4.798328835992993e-07, 'sub_sample': 0.3962379403966235}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:05,473]\u001b[0m Trial 55 finished with value: -3288852.057522792 and parameters: {'colsample_bytree': 0.7185584422277606, 'learning_rate': 0.31212391782178606, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 298, 'reg_lambda': 0.3236137356393935, 'reg_alpha': 0.018422358788759256, 'sub_sample': 0.2687462622587645}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:06,034]\u001b[0m Trial 56 finished with value: -3620242.055613286 and parameters: {'colsample_bytree': 0.6377773769319373, 'learning_rate': 0.6231003730015988, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 276, 'reg_lambda': 3.3101054460117125, 'reg_alpha': 5.449746274084839e-06, 'sub_sample': 0.3720291774513262}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:06,664]\u001b[0m Trial 57 finished with value: -3298726.8355765436 and parameters: {'colsample_bytree': 0.5160159507135789, 'learning_rate': 0.2318933414718427, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 244, 'reg_lambda': 36.03980543489998, 'reg_alpha': 3.459357202533867e-08, 'sub_sample': 0.43705580689151546}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:07,189]\u001b[0m Trial 58 finished with value: -3633074.205127289 and parameters: {'colsample_bytree': 0.6090919883246428, 'learning_rate': 0.14969023588412833, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 291, 'reg_lambda': 0.04949968498597206, 'reg_alpha': 1.883478180181288e-07, 'sub_sample': 0.4611975967449941}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:07,940]\u001b[0m Trial 59 finished with value: -3521496.10343137 and parameters: {'colsample_bytree': 0.863930884449012, 'learning_rate': 0.8811688072229024, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 161, 'reg_lambda': 0.7762193466341816, 'reg_alpha': 0.00011292618203703991, 'sub_sample': 0.8557962262542079}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:08,353]\u001b[0m Trial 60 finished with value: -3684203.057573621 and parameters: {'colsample_bytree': 0.5526507432448657, 'learning_rate': 0.8070286773584314, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 114, 'reg_lambda': 0.00019688905254946175, 'reg_alpha': 0.2645980708662362, 'sub_sample': 0.20593634511991282}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:08,894]\u001b[0m Trial 61 finished with value: -3297644.795711174 and parameters: {'colsample_bytree': 0.668815895121308, 'learning_rate': 0.6910379000115403, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 283, 'reg_lambda': 11.406964007378038, 'reg_alpha': 8.56168893402559e-08, 'sub_sample': 0.2890082964018421}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:09,439]\u001b[0m Trial 62 finished with value: -3196779.9633128177 and parameters: {'colsample_bytree': 0.6420999946690482, 'learning_rate': 0.7009606618642474, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 280, 'reg_lambda': 44.30827389897611, 'reg_alpha': 8.824115648836832e-07, 'sub_sample': 0.1327259893739603}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:09,922]\u001b[0m Trial 63 finished with value: -3313266.473871854 and parameters: {'colsample_bytree': 0.4705242164495978, 'learning_rate': 0.562905450581488, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 277, 'reg_lambda': 7.031427109034942, 'reg_alpha': 7.279063063591897e-07, 'sub_sample': 0.12960026735448288}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:10,488]\u001b[0m Trial 64 finished with value: -3356546.8527976153 and parameters: {'colsample_bytree': 0.9405828990131964, 'learning_rate': 0.7189880696737339, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 208, 'reg_lambda': 41.56453178832314, 'reg_alpha': 3.2007249792253996, 'sub_sample': 0.10425162494464739}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:11,072]\u001b[0m Trial 65 finished with value: -3241376.4326302065 and parameters: {'colsample_bytree': 0.7172304191559841, 'learning_rate': 0.6698380295854292, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 300, 'reg_lambda': 15.058906503905787, 'reg_alpha': 0.001557911873409089, 'sub_sample': 0.6008444116898748}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:11,620]\u001b[0m Trial 66 finished with value: -3203252.555729309 and parameters: {'colsample_bytree': 0.6409142894542632, 'learning_rate': 0.6401853907355312, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 300, 'reg_lambda': 21.060509070928642, 'reg_alpha': 0.004789230105787455, 'sub_sample': 0.2406260084827292}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:12,153]\u001b[0m Trial 67 finished with value: -3455510.0438644136 and parameters: {'colsample_bytree': 0.6378419004639481, 'learning_rate': 0.6259503653677188, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 261, 'reg_lambda': 2.1927480465718707, 'reg_alpha': 0.005620439020611813, 'sub_sample': 0.23756274377150052}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:12,672]\u001b[0m Trial 68 finished with value: -3242045.3651441415 and parameters: {'colsample_bytree': 0.5687414337436515, 'learning_rate': 0.7730203968435986, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 190, 'reg_lambda': 42.266870432038914, 'reg_alpha': 2.106135976242943e-08, 'sub_sample': 0.16797615455416406}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:13,118]\u001b[0m Trial 69 finished with value: -3646766.625727215 and parameters: {'colsample_bytree': 0.7854466487433042, 'learning_rate': 0.4772972077221207, 'max_depth': 2, 'min_child_weight': 5, 'n_estimators': 290, 'reg_lambda': 1.684869278669373e-05, 'reg_alpha': 0.06704290652440337, 'sub_sample': 0.17220531750863782}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:13,750]\u001b[0m Trial 70 finished with value: -3353836.4848835394 and parameters: {'colsample_bytree': 0.6500817765249548, 'learning_rate': 0.6609469292503797, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 244, 'reg_lambda': 4.058437094109027, 'reg_alpha': 1.320653507762845e-06, 'sub_sample': 0.2511850016446446}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:14,404]\u001b[0m Trial 71 finished with value: -3228426.6207062155 and parameters: {'colsample_bytree': 0.7226366609855168, 'learning_rate': 0.7177261829357711, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 300, 'reg_lambda': 16.557647769328636, 'reg_alpha': 0.0009095788116278294, 'sub_sample': 0.6111280684011977}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:14,992]\u001b[0m Trial 72 finished with value: -3238033.925790601 and parameters: {'colsample_bytree': 0.6023669517619376, 'learning_rate': 0.7088933979547709, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 272, 'reg_lambda': 21.03747817438312, 'reg_alpha': 3.864218995410259e-06, 'sub_sample': 0.7163899331851121}. Best is trial 32 with value: -3196189.372999428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:15,568]\u001b[0m Trial 73 finished with value: -3193931.6324041765 and parameters: {'colsample_bytree': 0.705708661411666, 'learning_rate': 0.7614196935952637, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 293, 'reg_lambda': 48.04985859689279, 'reg_alpha': 0.0008284234287946551, 'sub_sample': 0.28567474639087426}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:16,154]\u001b[0m Trial 74 finished with value: -3318134.8276006808 and parameters: {'colsample_bytree': 0.7548248175973987, 'learning_rate': 0.6048959962338498, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 294, 'reg_lambda': 6.816563858234169, 'reg_alpha': 0.0008477394035470648, 'sub_sample': 0.3059586111024328}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:16,735]\u001b[0m Trial 75 finished with value: -3321582.0893314225 and parameters: {'colsample_bytree': 0.6966272669030757, 'learning_rate': 0.808892896061461, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 279, 'reg_lambda': 46.33012060718396, 'reg_alpha': 0.0004505780372617205, 'sub_sample': 0.23056245406136344}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:17,288]\u001b[0m Trial 76 finished with value: -3457797.8711052896 and parameters: {'colsample_bytree': 0.7393689071027545, 'learning_rate': 0.7567924905623398, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 287, 'reg_lambda': 0.27245553952103, 'reg_alpha': 7.069027576875411e-05, 'sub_sample': 0.2925800081767375}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:17,883]\u001b[0m Trial 77 finished with value: -3259171.071309178 and parameters: {'colsample_bytree': 0.7153022564571491, 'learning_rate': 0.7230625887608249, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 262, 'reg_lambda': 15.040313261775209, 'reg_alpha': 1.3078934845201014e-05, 'sub_sample': 0.3658792308502829}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:18,301]\u001b[0m Trial 78 finished with value: -3368860.0297844913 and parameters: {'colsample_bytree': 0.6594310643910766, 'learning_rate': 0.7829858722692478, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 295, 'reg_lambda': 1.042767847268068, 'reg_alpha': 0.0169307304920323, 'sub_sample': 0.6745677256115598}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:18,871]\u001b[0m Trial 79 finished with value: -3671283.069812022 and parameters: {'colsample_bytree': 0.632943894495447, 'learning_rate': 0.8427547646023318, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 228, 'reg_lambda': 0.0044893502506090635, 'reg_alpha': 0.0002050615361702232, 'sub_sample': 0.5193238994957917}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:19,451]\u001b[0m Trial 80 finished with value: -3257292.8469843157 and parameters: {'colsample_bytree': 0.7764096026436456, 'learning_rate': 0.34243703371806133, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 300, 'reg_lambda': 6.118941811557579, 'reg_alpha': 0.003021156880961856, 'sub_sample': 0.34533688973616933}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:19,989]\u001b[0m Trial 81 finished with value: -3222440.324414105 and parameters: {'colsample_bytree': 0.6017863810556588, 'learning_rate': 0.6533183711204957, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 289, 'reg_lambda': 20.834243432340084, 'reg_alpha': 1.272328503304595, 'sub_sample': 0.9264452596401991}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:20,567]\u001b[0m Trial 82 finished with value: -3218690.1789936954 and parameters: {'colsample_bytree': 0.6062612118250769, 'learning_rate': 0.7427072173518002, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 280, 'reg_lambda': 54.49682585896059, 'reg_alpha': 0.1637215587289242, 'sub_sample': 0.9322761006384367}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:21,063]\u001b[0m Trial 83 finished with value: -3274179.301694888 and parameters: {'colsample_bytree': 0.5354286637790157, 'learning_rate': 0.7418206589038552, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 288, 'reg_lambda': 55.19902859239272, 'reg_alpha': 0.0015629301968790876, 'sub_sample': 0.18410655202600487}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:21,637]\u001b[0m Trial 84 finished with value: -3225708.8535366016 and parameters: {'colsample_bytree': 0.6164644596148231, 'learning_rate': 0.6718860990688361, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 281, 'reg_lambda': 18.936906181872914, 'reg_alpha': 1.642499049930419, 'sub_sample': 0.9424843623598749}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:22,150]\u001b[0m Trial 85 finished with value: -3248338.6609445326 and parameters: {'colsample_bytree': 0.5890496824559722, 'learning_rate': 0.5609750194312333, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 280, 'reg_lambda': 59.005971140542364, 'reg_alpha': 1.2696179083587698, 'sub_sample': 0.9320509239668909}. Best is trial 73 with value: -3193931.6324041765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:22,716]\u001b[0m Trial 86 finished with value: -3180056.890086433 and parameters: {'colsample_bytree': 0.6205410639922893, 'learning_rate': 0.6673394480906996, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 271, 'reg_lambda': 24.205741768145575, 'reg_alpha': 8.64119849709009, 'sub_sample': 0.9185903193587147}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:23,232]\u001b[0m Trial 87 finished with value: -3233476.1789054708 and parameters: {'colsample_bytree': 0.5666819469244044, 'learning_rate': 0.5300232050375361, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 266, 'reg_lambda': 31.35047034685651, 'reg_alpha': 9.099194700479611, 'sub_sample': 0.9799104136508541}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:23,723]\u001b[0m Trial 88 finished with value: -3254432.7990192357 and parameters: {'colsample_bytree': 0.5137532581549127, 'learning_rate': 0.6346531451992166, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 272, 'reg_lambda': 55.10082288660023, 'reg_alpha': 0.4320339943318346, 'sub_sample': 0.142708557139517}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:24,271]\u001b[0m Trial 89 finished with value: -3450534.6067343485 and parameters: {'colsample_bytree': 0.6491180103401989, 'learning_rate': 0.6087702978672165, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 287, 'reg_lambda': 2.362666329431397, 'reg_alpha': 0.12842377234538804, 'sub_sample': 0.26503331173040545}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:24,631]\u001b[0m Trial 90 finished with value: -3616789.980452087 and parameters: {'colsample_bytree': 0.6014296276210472, 'learning_rate': 0.584499529498688, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 294, 'reg_lambda': 10.540631064178102, 'reg_alpha': 19.914474563054565, 'sub_sample': 0.9072609384891793}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:25,147]\u001b[0m Trial 91 finished with value: -3256580.83832393 and parameters: {'colsample_bytree': 0.605522966088179, 'learning_rate': 0.665052307911657, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 274, 'reg_lambda': 96.20535496596912, 'reg_alpha': 6.135375584121413, 'sub_sample': 0.948938844814539}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:25,679]\u001b[0m Trial 92 finished with value: -3231380.574212881 and parameters: {'colsample_bytree': 0.6270494533049711, 'learning_rate': 0.6691504811694687, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 283, 'reg_lambda': 22.394948916830344, 'reg_alpha': 1.7870033547795845, 'sub_sample': 0.9213793700328471}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:26,222]\u001b[0m Trial 93 finished with value: -3202151.5447150776 and parameters: {'colsample_bytree': 0.6895826985301597, 'learning_rate': 0.7037865696941896, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 257, 'reg_lambda': 25.981624987704613, 'reg_alpha': 52.94535904429212, 'sub_sample': 0.8666791485760086}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:26,804]\u001b[0m Trial 94 finished with value: -3351220.877917558 and parameters: {'colsample_bytree': 0.6661775769280696, 'learning_rate': 0.7059443122766388, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 255, 'reg_lambda': 6.183607436335365, 'reg_alpha': 58.171267899286676, 'sub_sample': 0.965019294660658}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:27,334]\u001b[0m Trial 95 finished with value: -3205755.455311641 and parameters: {'colsample_bytree': 0.693469768001822, 'learning_rate': 0.7597357633373912, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 290, 'reg_lambda': 26.8346887393011, 'reg_alpha': 28.38810402374416, 'sub_sample': 0.8993649747708355}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:27,919]\u001b[0m Trial 96 finished with value: -3227261.409600688 and parameters: {'colsample_bytree': 0.7008306265260139, 'learning_rate': 0.7499581724481479, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 265, 'reg_lambda': 56.43745843123118, 'reg_alpha': 32.22940330169976, 'sub_sample': 0.8634102959119958}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:28,463]\u001b[0m Trial 97 finished with value: -3453056.1129075657 and parameters: {'colsample_bytree': 0.6791442172204768, 'learning_rate': 0.7657467593552245, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 275, 'reg_lambda': 8.49672852070727, 'reg_alpha': 20.509948703225827, 'sub_sample': 0.8112577131571612}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:29,194]\u001b[0m Trial 98 finished with value: -3558758.582928525 and parameters: {'colsample_bytree': 0.697134787385491, 'learning_rate': 0.8205284332579037, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 285, 'reg_lambda': 4.35172976452648e-07, 'reg_alpha': 92.34908753235324, 'sub_sample': 0.8854600058747009}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:29,917]\u001b[0m Trial 99 finished with value: -3210617.305024092 and parameters: {'colsample_bytree': 0.7386774201321635, 'learning_rate': 0.7370634778096032, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 249, 'reg_lambda': 28.673590305621598, 'reg_alpha': 3.127649624756638e-07, 'sub_sample': 0.9981110804445532}. Best is trial 86 with value: -3180056.890086433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def xgb(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, Z_train, y_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c836987f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6205410639922893,\n",
       " 'learning_rate': 0.6673394480906996,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 2,\n",
       " 'n_estimators': 271,\n",
       " 'reg_lambda': 24.205741768145575,\n",
       " 'reg_alpha': 8.64119849709009,\n",
       " 'sub_sample': 0.9185903193587147}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e4e5001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3180056.890086433"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c2d5df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.6205410639922893,\n",
       "             enable_categorical=False, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.6673394480906996,\n",
       "             max_delta_step=0, max_depth=3, min_child_weight=2, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=271, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=8.64119849709009, reg_lambda=24.205741768145575,\n",
       "             scale_pos_weight=1, sub_sample=0.9185903193587147, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBRegressor(colsample_bytree= 0.6205410639922893, learning_rate= 0.6673394480906996, max_depth= 3, min_child_weight= 2, n_estimators= 271,\n",
    "reg_alpha= 8.64119849709009, reg_lambda= 24.205741768145575, sub_sample=  0.9185903193587147)\n",
    "XGB.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c63f73e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606254179440374"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB.score(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ae87b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8872822122512368"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765bea2",
   "metadata": {},
   "source": [
    "Overfitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53c2c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9606254179440374\n",
      "1209332285444.262\n",
      "1099696.4515011685\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = XGB.predict(Z_train)\n",
    "print(metrics.r2_score(y_train, y_pred2))\n",
    "print(metrics.mean_squared_error(y_train, y_pred2))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_train, y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9a0c3",
   "metadata": {},
   "source": [
    "# Using merged_house 2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2884ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_house2 = pd.read_csv('./dataset_asof_051121/merged_house2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d6c4b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9582, 43)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af9dced4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.076e+03, 2.432e+03, 4.960e+02, 2.340e+02, 1.020e+02, 6.200e+01,\n",
       "        3.500e+01, 3.500e+01, 2.600e+01, 1.800e+01, 1.400e+01, 1.700e+01,\n",
       "        1.100e+01, 9.000e+00, 4.000e+00, 4.000e+00, 1.000e+00, 0.000e+00,\n",
       "        2.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([  725000.        ,  3830833.33333333,  6936666.66666667,\n",
       "        10042500.        , 13148333.33333333, 16254166.66666667,\n",
       "        19360000.        , 22465833.33333334, 25571666.66666667,\n",
       "        28677500.        , 31783333.33333334, 34889166.66666667,\n",
       "        37995000.        , 41100833.33333334, 44206666.66666667,\n",
       "        47312500.        , 50418333.33333334, 53524166.66666667,\n",
       "        56630000.        , 59735833.33333334, 62841666.66666667,\n",
       "        65947500.        , 69053333.33333334, 72159166.66666667,\n",
       "        75265000.        , 78370833.33333334, 81476666.66666667,\n",
       "        84582500.        , 87688333.33333334, 90794166.66666667,\n",
       "        93900000.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "price = merged_house2['price']\n",
    "\n",
    "plt.hist(price, bins =30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed948d",
   "metadata": {},
   "source": [
    "Model is skewed to left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66dbdf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_houseP = merged_house2.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8eeb545",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = merged_houseP.drop(columns = ['price','unit price psf','project name','street name','type of sale','nett price', 'type of area', 'floor level','date of sale', 'index'])\n",
    "y1 = merged_houseP['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bde1f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits.\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f65c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z1_train = sc.fit_transform(X1_train)\n",
    "Z1_test = sc.transform(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ec7db",
   "metadata": {},
   "source": [
    "XGboost to be used for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8a2161e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB2 = XGBRegressor()\n",
    "XGB2.fit(Z1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcf444bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-15 01:52:30,944]\u001b[0m A new study created in memory with name: no-name-8bf0aa5a-b1fb-4310-99d7-e57eadc750ac\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:31,551]\u001b[0m Trial 0 finished with value: -1762419.078025642 and parameters: {'colsample_bytree': 0.4370861069626263, 'learning_rate': 0.9556428757689246, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 131, 'reg_lambda': 3.6303224667798554e-07, 'reg_alpha': 3.809220577048033e-08, 'sub_sample': 0.8795585311974417}. Best is trial 0 with value: -1762419.078025642.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:31,885]\u001b[0m Trial 1 finished with value: -1749829.5251241552 and parameters: {'colsample_bytree': 0.6410035105688879, 'learning_rate': 0.737265320016441, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 267, 'reg_lambda': 1.3285903900544182e-06, 'reg_alpha': 6.580360277501306e-07, 'sub_sample': 0.2650640588680905}. Best is trial 1 with value: -1749829.5251241552.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:32,335]\u001b[0m Trial 2 finished with value: -1622957.9276332485 and parameters: {'colsample_bytree': 0.373818018663584, 'learning_rate': 0.5722807884690141, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 222, 'reg_lambda': 2.4827821051950883e-07, 'reg_alpha': 8.345387083873532e-06, 'sub_sample': 0.4297256589643226}. Best is trial 2 with value: -1622957.9276332485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:32,669]\u001b[0m Trial 3 finished with value: -1756458.2901047245 and parameters: {'colsample_bytree': 0.5104629857953323, 'learning_rate': 0.8066583652537123, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 219, 'reg_lambda': 2.9140978279786215e-08, 'reg_alpha': 0.011897302909454906, 'sub_sample': 0.2534717113185624}. Best is trial 2 with value: -1622957.9276332485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:33,170]\u001b[0m Trial 4 finished with value: -1788873.566744912 and parameters: {'colsample_bytree': 0.1585464336867516, 'learning_rate': 0.9539969835279999, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 161, 'reg_lambda': 9.478096804784244e-08, 'reg_alpha': 0.06955530592645753, 'sub_sample': 0.4961372443656412}. Best is trial 2 with value: -1622957.9276332485.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:33,450]\u001b[0m Trial 5 finished with value: -1817398.2944428022 and parameters: {'colsample_bytree': 0.20983441136030095, 'learning_rate': 0.5456592191001431, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 152, 'reg_lambda': 0.042191293826476094, 'reg_alpha': 1.3095158546031483e-05, 'sub_sample': 0.5680612190600297}. Best is trial 2 with value: -1622957.9276332485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:34,171]\u001b[0m Trial 6 finished with value: -1607921.4294803436 and parameters: {'colsample_bytree': 0.5920392514089517, 'learning_rate': 0.26636900997297436, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 288, 'reg_lambda': 8.8771488946556, 'reg_alpha': 0.00952795699161383, 'sub_sample': 0.9296868115208051}. Best is trial 6 with value: -1607921.4294803436.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:34,471]\u001b[0m Trial 7 finished with value: -1836793.3500733352 and parameters: {'colsample_bytree': 0.17964325184672755, 'learning_rate': 0.27638457617723067, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 178, 'reg_lambda': 5.169997317292732e-06, 'reg_alpha': 1.9380951355796903, 'sub_sample': 0.4210779940242304}. Best is trial 6 with value: -1607921.4294803436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:34,769]\u001b[0m Trial 8 finished with value: -1871720.5100247539 and parameters: {'colsample_bytree': 0.3528410587186427, 'learning_rate': 0.5884264748424236, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 114, 'reg_lambda': 73.9382838287635, 'reg_alpha': 0.5277736371601186, 'sub_sample': 0.2788441133807552}. Best is trial 6 with value: -1607921.4294803436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:35,165]\u001b[0m Trial 9 finished with value: -1754816.895471111 and parameters: {'colsample_bytree': 0.10496990541124217, 'learning_rate': 0.8339152856093507, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 255, 'reg_lambda': 5.50106171658889e-08, 'reg_alpha': 3.842884090673403e-05, 'sub_sample': 0.20428215357261675}. Best is trial 6 with value: -1607921.4294803436.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:36,069]\u001b[0m Trial 10 finished with value: -1563316.482841052 and parameters: {'colsample_bytree': 0.9497157666716347, 'learning_rate': 0.10539746466023536, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 297, 'reg_lambda': 11.930206277066471, 'reg_alpha': 39.6011191452442, 'sub_sample': 0.9790910709802578}. Best is trial 10 with value: -1563316.482841052.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:36,961]\u001b[0m Trial 11 finished with value: -1769097.065581664 and parameters: {'colsample_bytree': 0.9522656887511342, 'learning_rate': 0.10326321505087403, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 82.82843195255043, 'reg_alpha': 73.24607527580478, 'sub_sample': 0.971643831619738}. Best is trial 10 with value: -1563316.482841052.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:37,699]\u001b[0m Trial 12 finished with value: -1501807.8170444276 and parameters: {'colsample_bytree': 0.9925005566564994, 'learning_rate': 0.10376349477481495, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 295, 'reg_lambda': 0.5154377331302434, 'reg_alpha': 90.4650741825025, 'sub_sample': 0.7633847055950665}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:38,317]\u001b[0m Trial 13 finished with value: -1541950.131256442 and parameters: {'colsample_bytree': 0.9923243791594821, 'learning_rate': 0.13022729644102515, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 249, 'reg_lambda': 0.09378349935519929, 'reg_alpha': 98.54268387927638, 'sub_sample': 0.7487845791649022}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:38,903]\u001b[0m Trial 14 finished with value: -1508096.0791073253 and parameters: {'colsample_bytree': 0.7877689893471364, 'learning_rate': 0.2761488960754062, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 247, 'reg_lambda': 0.03157769150610153, 'reg_alpha': 4.450521443330538, 'sub_sample': 0.7385666642916615}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:39,371]\u001b[0m Trial 15 finished with value: -1595702.5533690534 and parameters: {'colsample_bytree': 0.7804373430801348, 'learning_rate': 0.3315144570723555, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 229, 'reg_lambda': 0.0005694913915565323, 'reg_alpha': 2.8076655848128182, 'sub_sample': 0.7087791056438787}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:40,104]\u001b[0m Trial 16 finished with value: -1604896.095917423 and parameters: {'colsample_bytree': 0.7914631438360765, 'learning_rate': 0.41073805181498313, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 268, 'reg_lambda': 0.04280043857930639, 'reg_alpha': 6.202398176432575, 'sub_sample': 0.7743029917400299}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:40,584]\u001b[0m Trial 17 finished with value: -1583869.3585549463 and parameters: {'colsample_bytree': 0.7952073910549269, 'learning_rate': 0.2349937566073952, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 204, 'reg_lambda': 0.0021565817651528515, 'reg_alpha': 0.20414884541025957, 'sub_sample': 0.6396767599776616}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:41,168]\u001b[0m Trial 18 finished with value: -1640681.384892795 and parameters: {'colsample_bytree': 0.8491106367117831, 'learning_rate': 0.40706818505653775, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 244, 'reg_lambda': 0.44643529118791236, 'reg_alpha': 0.005456255201362009, 'sub_sample': 0.8267024934971574}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:41,837]\u001b[0m Trial 19 finished with value: -1513047.7678819203 and parameters: {'colsample_bytree': 0.6562799583969415, 'learning_rate': 0.20083679020862924, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 268, 'reg_lambda': 0.0005262907678924009, 'reg_alpha': 0.000621491820785849, 'sub_sample': 0.6430994564294443}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:42,298]\u001b[0m Trial 20 finished with value: -1572900.549233376 and parameters: {'colsample_bytree': 0.8852869949362379, 'learning_rate': 0.4343754916917302, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 186, 'reg_lambda': 0.9828458161918191, 'reg_alpha': 11.67268669140412, 'sub_sample': 0.8309944237896358}. Best is trial 12 with value: -1501807.8170444276.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:42,997]\u001b[0m Trial 21 finished with value: -1497006.2522139938 and parameters: {'colsample_bytree': 0.6873563550228332, 'learning_rate': 0.1863432202662247, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 276, 'reg_lambda': 0.00017019287080119824, 'reg_alpha': 0.00011007470807617123, 'sub_sample': 0.6169332984780489}. Best is trial 21 with value: -1497006.2522139938.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:43,719]\u001b[0m Trial 22 finished with value: -1495445.272666127 and parameters: {'colsample_bytree': 0.7282869760048614, 'learning_rate': 0.1876002177475279, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 280, 'reg_lambda': 3.817693638425311e-05, 'reg_alpha': 0.00018520514764359673, 'sub_sample': 0.6583848667072101}. Best is trial 22 with value: -1495445.272666127.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:44,415]\u001b[0m Trial 23 finished with value: -1481475.2284323587 and parameters: {'colsample_bytree': 0.690113618486667, 'learning_rate': 0.1772377393880452, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 273, 'reg_lambda': 3.0197933072502674e-05, 'reg_alpha': 0.00022642092841446409, 'sub_sample': 0.6283965168034602}. Best is trial 23 with value: -1481475.2284323587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:45,110]\u001b[0m Trial 24 finished with value: -1558234.8506298913 and parameters: {'colsample_bytree': 0.6918934238264043, 'learning_rate': 0.19635720208873017, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 278, 'reg_lambda': 3.270582400338106e-05, 'reg_alpha': 0.00013458649096494566, 'sub_sample': 0.5933024257486624}. Best is trial 23 with value: -1481475.2284323587.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:45,868]\u001b[0m Trial 25 finished with value: -1546444.4269362781 and parameters: {'colsample_bytree': 0.540441221671801, 'learning_rate': 0.3448908089908024, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 276, 'reg_lambda': 3.534734709606639e-05, 'reg_alpha': 1.3467769484715348e-06, 'sub_sample': 0.4725875875624316}. Best is trial 23 with value: -1481475.2284323587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:46,833]\u001b[0m Trial 26 finished with value: -1680217.6630912947 and parameters: {'colsample_bytree': 0.7048438629228968, 'learning_rate': 0.47221384206742434, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 235, 'reg_lambda': 5.376381249304065e-05, 'reg_alpha': 0.0006841248716434265, 'sub_sample': 0.34782813656489764}. Best is trial 23 with value: -1481475.2284323587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:47,532]\u001b[0m Trial 27 finished with value: -1476749.7631875838 and parameters: {'colsample_bytree': 0.7212199673780071, 'learning_rate': 0.17970770728660687, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 209, 'reg_lambda': 0.0020509481381074716, 'reg_alpha': 0.0001568894897579758, 'sub_sample': 0.656462339879924}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:48,115]\u001b[0m Trial 28 finished with value: -1625923.6409126152 and parameters: {'colsample_bytree': 0.6073327943196228, 'learning_rate': 0.17464672896386182, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 204, 'reg_lambda': 0.003759901916242067, 'reg_alpha': 0.0020256146701417388, 'sub_sample': 0.6791649710273856}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:48,620]\u001b[0m Trial 29 finished with value: -1552144.4902040854 and parameters: {'colsample_bytree': 0.4539961030801218, 'learning_rate': 0.32502099040884047, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 124, 'reg_lambda': 0.005011487489662494, 'reg_alpha': 4.448996188984284e-07, 'sub_sample': 0.5198398438280527}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:49,349]\u001b[0m Trial 30 finished with value: -1725897.702400699 and parameters: {'colsample_bytree': 0.7305444865278783, 'learning_rate': 0.6485441231867455, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 145, 'reg_lambda': 6.641144786329923e-06, 'reg_alpha': 2.67578861029397e-08, 'sub_sample': 0.8412835324178308}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:50,053]\u001b[0m Trial 31 finished with value: -1490296.556818516 and parameters: {'colsample_bytree': 0.7227151573412186, 'learning_rate': 0.17257877985612602, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 281, 'reg_lambda': 0.00013023946008478948, 'reg_alpha': 0.0001052290535822713, 'sub_sample': 0.5844068437520248}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:50,832]\u001b[0m Trial 32 finished with value: -1522865.561510519 and parameters: {'colsample_bytree': 0.8750519913073874, 'learning_rate': 0.22752567119598627, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 255, 'reg_lambda': 1.7541916126377878e-06, 'reg_alpha': 0.000236725411460455, 'sub_sample': 0.5502430771307915}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:51,666]\u001b[0m Trial 33 finished with value: -1512537.2760357563 and parameters: {'colsample_bytree': 0.6142341095029751, 'learning_rate': 0.14491276177352425, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 285, 'reg_lambda': 0.00024182300980244489, 'reg_alpha': 4.47838630777421e-06, 'sub_sample': 0.6825948117223162}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:52,349]\u001b[0m Trial 34 finished with value: -1563541.5149962208 and parameters: {'colsample_bytree': 0.7242164366322532, 'learning_rate': 0.340400800753183, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 9.60399430035537e-06, 'reg_alpha': 1.6716843327795758e-07, 'sub_sample': 0.42545253549875106}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:53,009]\u001b[0m Trial 35 finished with value: -1578075.6821560252 and parameters: {'colsample_bytree': 0.4962159427434817, 'learning_rate': 0.2591540754293079, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 263, 'reg_lambda': 9.27767304354096e-05, 'reg_alpha': 3.2513282902643205e-05, 'sub_sample': 0.6027708970724733}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:53,600]\u001b[0m Trial 36 finished with value: -1511349.9166650241 and parameters: {'colsample_bytree': 0.8582751807005333, 'learning_rate': 0.1759984820694682, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 213, 'reg_lambda': 8.090578895540372e-07, 'reg_alpha': 0.030667028549099817, 'sub_sample': 0.5328859770519864}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:54,367]\u001b[0m Trial 37 finished with value: -1840366.5140359045 and parameters: {'colsample_bytree': 0.5660796574960537, 'learning_rate': 0.9939148177478547, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 182, 'reg_lambda': 0.0015410920443967224, 'reg_alpha': 0.0019142919280802652, 'sub_sample': 0.48196766773211097}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:54,895]\u001b[0m Trial 38 finished with value: -1524423.4696044042 and parameters: {'colsample_bytree': 0.6566828895588024, 'learning_rate': 0.2977968479528372, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 234, 'reg_lambda': 1.0633582693547669e-08, 'reg_alpha': 6.484711340874862e-06, 'sub_sample': 0.3747029694765541}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:55,629]\u001b[0m Trial 39 finished with value: -1655156.4125955969 and parameters: {'colsample_bytree': 0.747266034683909, 'learning_rate': 0.49826417252379696, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 284, 'reg_lambda': 0.012974209650522756, 'reg_alpha': 2.369727781563506e-05, 'sub_sample': 0.6756491511197298}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:56,532]\u001b[0m Trial 40 finished with value: -1626385.0279402016 and parameters: {'colsample_bytree': 0.820399076068969, 'learning_rate': 0.3796310008073413, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 167, 'reg_lambda': 2.493851256742818e-07, 'reg_alpha': 0.00029663157556424996, 'sub_sample': 0.10977419983755343}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:57,198]\u001b[0m Trial 41 finished with value: -1496815.2685179154 and parameters: {'colsample_bytree': 0.6355925925512985, 'learning_rate': 0.17736029095731845, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 277, 'reg_lambda': 0.00014526046570516885, 'reg_alpha': 9.414202717670814e-05, 'sub_sample': 0.6197791372632058}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:57,901]\u001b[0m Trial 42 finished with value: -1510772.3658860214 and parameters: {'colsample_bytree': 0.6639706922885191, 'learning_rate': 0.22651960522814188, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 262, 'reg_lambda': 1.580482256223588e-05, 'reg_alpha': 7.343948367884096e-05, 'sub_sample': 0.568866557098002}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:58,562]\u001b[0m Trial 43 finished with value: -1480487.0996362632 and parameters: {'colsample_bytree': 0.5717685645756765, 'learning_rate': 0.15419937473962558, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 299, 'reg_lambda': 1.7322663395375708e-06, 'reg_alpha': 4.097666938042721e-06, 'sub_sample': 0.6422329181025521}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:59,112]\u001b[0m Trial 44 finished with value: -1553939.4229933338 and parameters: {'colsample_bytree': 0.34989733275650337, 'learning_rate': 0.1501424231328925, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 296, 'reg_lambda': 6.218595992110188e-07, 'reg_alpha': 2.0334509760773038e-06, 'sub_sample': 0.7164299768563718}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:52:59,876]\u001b[0m Trial 45 finished with value: -1529122.363401433 and parameters: {'colsample_bytree': 0.5624500072280223, 'learning_rate': 0.23712318454472603, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 289, 'reg_lambda': 2.584722211981419e-06, 'reg_alpha': 1.2864509714123134e-05, 'sub_sample': 0.6569625987616583}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:52:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:52:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:00,413]\u001b[0m Trial 46 finished with value: -1707144.4624463255 and parameters: {'colsample_bytree': 0.5032612187377538, 'learning_rate': 0.8474424692580206, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 300, 'reg_lambda': 3.4550166780946768e-06, 'reg_alpha': 1.7694211606223362e-07, 'sub_sample': 0.7961827852147171}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:00,941]\u001b[0m Trial 47 finished with value: -1637609.8430130293 and parameters: {'colsample_bytree': 0.29157971698914037, 'learning_rate': 0.14026089211899262, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 284, 'reg_lambda': 1.2259974303339088e-07, 'reg_alpha': 0.004088414536284876, 'sub_sample': 0.9144597819434408}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:01,924]\u001b[0m Trial 48 finished with value: -1596166.2274283888 and parameters: {'colsample_bytree': 0.7516519216028035, 'learning_rate': 0.2950526061678947, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 219, 'reg_lambda': 0.00031498334871893666, 'reg_alpha': 0.01930410934831645, 'sub_sample': 0.5018780315679605}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:02,608]\u001b[0m Trial 49 finished with value: -1704708.9102298305 and parameters: {'colsample_bytree': 0.4498292861281771, 'learning_rate': 0.6981449776894302, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 258, 'reg_lambda': 2.5090037487233328e-05, 'reg_alpha': 0.00045180195087985705, 'sub_sample': 0.5785520830467641}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:03,330]\u001b[0m Trial 50 finished with value: -1494559.770897654 and parameters: {'colsample_bytree': 0.5792254824417946, 'learning_rate': 0.10531043408444564, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 241, 'reg_lambda': 0.0005989559894394641, 'reg_alpha': 3.254629851822782e-06, 'sub_sample': 0.7136617943417618}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:04,024]\u001b[0m Trial 51 finished with value: -1502057.3343153868 and parameters: {'colsample_bytree': 0.5814632820142176, 'learning_rate': 0.11664599065891074, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 241, 'reg_lambda': 0.0008508859447849774, 'reg_alpha': 2.896687855440506e-06, 'sub_sample': 0.7086961812966287}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:04,696]\u001b[0m Trial 52 finished with value: -1496277.3931980631 and parameters: {'colsample_bytree': 0.5294665688746667, 'learning_rate': 0.15187623074075, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 190, 'reg_lambda': 7.878156395535198e-05, 'reg_alpha': 1.9440005896436602e-05, 'sub_sample': 0.7197555621327067}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:05,375]\u001b[0m Trial 53 finished with value: -1524984.6352010027 and parameters: {'colsample_bytree': 0.6137516340675805, 'learning_rate': 0.22144269772173608, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 271, 'reg_lambda': 0.007078654615753609, 'reg_alpha': 6.5757367229452655e-06, 'sub_sample': 0.7859409487926867}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:05,963]\u001b[0m Trial 54 finished with value: -1502592.1726668966 and parameters: {'colsample_bytree': 0.7548936081212573, 'learning_rate': 0.10110430114015265, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 289, 'reg_lambda': 0.0011454482501779483, 'reg_alpha': 8.618832928288896e-07, 'sub_sample': 0.6428388980515717}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:06,668]\u001b[0m Trial 55 finished with value: -1522018.0454312845 and parameters: {'colsample_bytree': 0.6893125190055999, 'learning_rate': 0.2521618845795574, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 250, 'reg_lambda': 9.631057660008937e-06, 'reg_alpha': 5.1170770326670344e-05, 'sub_sample': 0.7412973251819769}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:07,492]\u001b[0m Trial 56 finished with value: -1622064.0706624126 and parameters: {'colsample_bytree': 0.8191393525107621, 'learning_rate': 0.19920932743107625, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 225, 'reg_lambda': 0.0003789701805827161, 'reg_alpha': 0.0014222437821981115, 'sub_sample': 0.5535626128219706}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:08,109]\u001b[0m Trial 57 finished with value: -1490014.6101380892 and parameters: {'colsample_bytree': 0.40091035798143015, 'learning_rate': 0.15389823299273858, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 213, 'reg_lambda': 2.097591530765648e-05, 'reg_alpha': 0.00023764290098397283, 'sub_sample': 0.6119291646305758}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:08,567]\u001b[0m Trial 58 finished with value: -1530421.8090999294 and parameters: {'colsample_bytree': 0.3935480089172352, 'learning_rate': 0.14432324408556627, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 193, 'reg_lambda': 1.5639607491510777e-05, 'reg_alpha': 1.1032056718011091e-08, 'sub_sample': 0.45787694705452975}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:09,091]\u001b[0m Trial 59 finished with value: -1552791.0853553596 and parameters: {'colsample_bytree': 0.23159090641002256, 'learning_rate': 0.2831299474322832, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 214, 'reg_lambda': 0.014397007847447532, 'reg_alpha': 1.0847688834819806e-05, 'sub_sample': 0.5914216372572035}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:09,811]\u001b[0m Trial 60 finished with value: -1532690.3204017924 and parameters: {'colsample_bytree': 0.4855523052738208, 'learning_rate': 0.124349698422207, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 213, 'reg_lambda': 1.1178017590897777e-06, 'reg_alpha': 0.004430445053594028, 'sub_sample': 0.6255359495158439}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:10,506]\u001b[0m Trial 61 finished with value: -1506159.4322965704 and parameters: {'colsample_bytree': 0.6292845325758875, 'learning_rate': 0.20537780472539874, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 237, 'reg_lambda': 8.37387148639224e-05, 'reg_alpha': 0.00016976476699472615, 'sub_sample': 0.6656148052938511}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:11,070]\u001b[0m Trial 62 finished with value: -1509781.2438923204 and parameters: {'colsample_bytree': 0.4041129571293718, 'learning_rate': 0.16958278265366616, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 270, 'reg_lambda': 4.948303256588004e-06, 'reg_alpha': 0.0006587250670193191, 'sub_sample': 0.6136429115431545}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:11,767]\u001b[0m Trial 63 finished with value: -1480302.7388691376 and parameters: {'colsample_bytree': 0.6686303249901988, 'learning_rate': 0.10184184997319502, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 199, 'reg_lambda': 0.002264736883428961, 'reg_alpha': 4.815795348898932e-05, 'sub_sample': 0.526398558919703}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:12,428]\u001b[0m Trial 64 finished with value: -1500179.7949747401 and parameters: {'colsample_bytree': 0.5947255736425425, 'learning_rate': 0.10149374674082601, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 175, 'reg_lambda': 0.003154480764402946, 'reg_alpha': 4.737381924887946e-05, 'sub_sample': 0.5530802399584986}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:13,083]\u001b[0m Trial 65 finished with value: -1483610.238397337 and parameters: {'colsample_bytree': 0.5381257047725869, 'learning_rate': 0.15535285561716738, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 197, 'reg_lambda': 0.0008362749294432025, 'reg_alpha': 0.00031645210734272515, 'sub_sample': 0.5270287877348743}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:13,615]\u001b[0m Trial 66 finished with value: -1610311.546621861 and parameters: {'colsample_bytree': 0.3104748300211434, 'learning_rate': 0.2531280250632853, 'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 200, 'reg_lambda': 0.16603307443063023, 'reg_alpha': 0.0003828628710544204, 'sub_sample': 0.5196214227289866}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:14,175]\u001b[0m Trial 67 finished with value: -1522151.7076085072 and parameters: {'colsample_bytree': 0.6746804984208468, 'learning_rate': 0.15602037659076107, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 159, 'reg_lambda': 0.0018850799995253908, 'reg_alpha': 0.00012186646614534719, 'sub_sample': 0.4501665864419131}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:14,800]\u001b[0m Trial 68 finished with value: -1489930.3315290746 and parameters: {'colsample_bytree': 0.532462722201839, 'learning_rate': 0.21289323702753, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 199, 'reg_lambda': 0.012033143219539744, 'reg_alpha': 2.6844962094467966e-05, 'sub_sample': 0.3911292041114758}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:15,194]\u001b[0m Trial 69 finished with value: -1582047.7555419493 and parameters: {'colsample_bytree': 0.4703845585830446, 'learning_rate': 0.21403179548464063, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 197, 'reg_lambda': 0.019716570265455084, 'reg_alpha': 0.0010322986340731322, 'sub_sample': 0.3156098235608749}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:15,833]\u001b[0m Trial 70 finished with value: -1534838.1404333718 and parameters: {'colsample_bytree': 0.5321983315191913, 'learning_rate': 0.13408191189684723, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 205, 'reg_lambda': 0.007668796643102399, 'reg_alpha': 5.625123989236326e-05, 'sub_sample': 0.393171365589064}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:16,588]\u001b[0m Trial 71 finished with value: -1497000.3289057203 and parameters: {'colsample_bytree': 0.771690346641363, 'learning_rate': 0.1725583805672218, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 206, 'reg_lambda': 0.045561660206191255, 'reg_alpha': 1.9826744877187007e-05, 'sub_sample': 0.4939862304945613}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:17,269]\u001b[0m Trial 72 finished with value: -1488462.136089066 and parameters: {'colsample_bytree': 0.7137700899088159, 'learning_rate': 0.20043446767613354, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 177, 'reg_lambda': 0.00015593835377306688, 'reg_alpha': 0.0002706832694593498, 'sub_sample': 0.5320335778372081}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:18,098]\u001b[0m Trial 73 finished with value: -1511389.7204745468 and parameters: {'colsample_bytree': 0.6434894574942761, 'learning_rate': 0.20248196867195253, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 182, 'reg_lambda': 0.0031565391945175647, 'reg_alpha': 0.000295523754871387, 'sub_sample': 0.5245986626261552}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:18,875]\u001b[0m Trial 74 finished with value: -1554776.3639018538 and parameters: {'colsample_bytree': 0.711913752742467, 'learning_rate': 0.30912224991623116, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 167, 'reg_lambda': 0.00021406340873605573, 'reg_alpha': 0.0009025036031502976, 'sub_sample': 0.4048534564175591}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:19,493]\u001b[0m Trial 75 finished with value: -1534922.6955187924 and parameters: {'colsample_bytree': 0.4138515781800688, 'learning_rate': 0.3635764449142117, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 147, 'reg_lambda': 0.000825191617570595, 'reg_alpha': 3.018875481499016e-05, 'sub_sample': 0.19697075742036468}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:20,145]\u001b[0m Trial 76 finished with value: -1496434.2376240494 and parameters: {'colsample_bytree': 0.5463074318237076, 'learning_rate': 0.26665480369400985, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 175, 'reg_lambda': 0.07723076068114673, 'reg_alpha': 0.0022011462317824545, 'sub_sample': 0.45465129000424565}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:20,915]\u001b[0m Trial 77 finished with value: -1530630.2943211603 and parameters: {'colsample_bytree': 0.5123633702368627, 'learning_rate': 0.12720449326544575, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 190, 'reg_lambda': 4.1457771540462344e-05, 'reg_alpha': 0.00017767930088829698, 'sub_sample': 0.33429948200173365}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:21,263]\u001b[0m Trial 78 finished with value: -1635750.052145436 and parameters: {'colsample_bytree': 0.6741018274906635, 'learning_rate': 0.23703419556842323, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 196, 'reg_lambda': 0.007982627692004371, 'reg_alpha': 7.621677953053165e-05, 'sub_sample': 0.6898377673588788}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:21,876]\u001b[0m Trial 79 finished with value: -1657784.1859637378 and parameters: {'colsample_bytree': 0.9159238958194301, 'learning_rate': 0.5523864597396306, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 228, 'reg_lambda': 0.0014867124459205215, 'reg_alpha': 0.011105731763453721, 'sub_sample': 0.2853481830605169}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:22,463]\u001b[0m Trial 80 finished with value: -1481268.4915535848 and parameters: {'colsample_bytree': 0.42825207575054686, 'learning_rate': 0.1907525386318606, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 220, 'reg_lambda': 0.23634989555283048, 'reg_alpha': 4.3288208271214134e-07, 'sub_sample': 0.5389223971132794}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:23,056]\u001b[0m Trial 81 finished with value: -1513163.763329347 and parameters: {'colsample_bytree': 0.37692822766589956, 'learning_rate': 0.19251833357082127, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 210, 'reg_lambda': 1.170311272583919, 'reg_alpha': 1.673005844346241e-07, 'sub_sample': 0.5375933968533525}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:23,629]\u001b[0m Trial 82 finished with value: -1569846.5301960346 and parameters: {'colsample_bytree': 0.33394572504566145, 'learning_rate': 0.16500485068092458, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 219, 'reg_lambda': 3.167776499536236, 'reg_alpha': 6.33177579306307e-08, 'sub_sample': 0.5748059129283833}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:24,227]\u001b[0m Trial 83 finished with value: -1498058.3197222163 and parameters: {'colsample_bytree': 0.4284353556665913, 'learning_rate': 0.2147179447840957, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 185, 'reg_lambda': 0.4180375175772303, 'reg_alpha': 1.1661588684526369e-06, 'sub_sample': 0.5068983250409572}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:24,830]\u001b[0m Trial 84 finished with value: -1758518.7003656935 and parameters: {'colsample_bytree': 0.4798895370713473, 'learning_rate': 0.1287658982502799, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 200, 'reg_lambda': 41.06440163073768, 'reg_alpha': 2.7896377245593484e-07, 'sub_sample': 0.632165353321601}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:25,446]\u001b[0m Trial 85 finished with value: -1479850.0837058863 and parameters: {'colsample_bytree': 0.4384036246165419, 'learning_rate': 0.18882843614911016, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 208, 'reg_lambda': 0.00042710061916177293, 'reg_alpha': 0.00046778722728362193, 'sub_sample': 0.4732702432469124}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:26,077]\u001b[0m Trial 86 finished with value: -1496883.9104074675 and parameters: {'colsample_bytree': 0.5618400005512698, 'learning_rate': 0.2350622980469238, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 224, 'reg_lambda': 0.0004240057601658252, 'reg_alpha': 0.0004564112143966749, 'sub_sample': 0.4342839665026992}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:26,726]\u001b[0m Trial 87 finished with value: -1609708.2106591158 and parameters: {'colsample_bytree': 0.4547692205615329, 'learning_rate': 0.2822442780388171, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 208, 'reg_lambda': 0.002358783583277561, 'reg_alpha': 4.962696677219266e-07, 'sub_sample': 0.4753275600773826}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:27,312]\u001b[0m Trial 88 finished with value: -1545739.9345277604 and parameters: {'colsample_bytree': 0.5101197724226401, 'learning_rate': 0.18901407842789036, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 171, 'reg_lambda': 0.00016190985217473059, 'reg_alpha': 8.015797340723488e-06, 'sub_sample': 0.3789235333489739}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:27,842]\u001b[0m Trial 89 finished with value: -1509831.0501932683 and parameters: {'colsample_bytree': 0.6019220138081539, 'learning_rate': 0.2575470636061003, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 133, 'reg_lambda': 0.15941112757349288, 'reg_alpha': 1.6008440100284496e-05, 'sub_sample': 0.5623184147251971}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:28,710]\u001b[0m Trial 90 finished with value: -1751377.4121339696 and parameters: {'colsample_bytree': 0.6405599885609901, 'learning_rate': 0.9088587441762224, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 189, 'reg_lambda': 0.024369122448168697, 'reg_alpha': 1.8123573364255354e-06, 'sub_sample': 0.4154731112860035}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:29,409]\u001b[0m Trial 91 finished with value: -1506070.0802308037 and parameters: {'colsample_bytree': 0.7015265646395539, 'learning_rate': 0.15525977178786574, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 201, 'reg_lambda': 1.909266479552883e-05, 'reg_alpha': 0.00020979332538309924, 'sub_sample': 0.600576940950464}. Best is trial 27 with value: -1476749.7631875838.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:30,019]\u001b[0m Trial 92 finished with value: -1469467.7601608743 and parameters: {'colsample_bytree': 0.44337553771952976, 'learning_rate': 0.18374143513627977, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 219, 'reg_lambda': 6.520544606670715e-05, 'reg_alpha': 8.519986823155171e-05, 'sub_sample': 0.5398449665009374}. Best is trial 92 with value: -1469467.7601608743.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:30,645]\u001b[0m Trial 93 finished with value: -1481865.0361458652 and parameters: {'colsample_bytree': 0.42476811289240857, 'learning_rate': 0.1848247557849396, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 229, 'reg_lambda': 0.0005332058999365528, 'reg_alpha': 3.630513165093528e-05, 'sub_sample': 0.534254827454086}. Best is trial 92 with value: -1469467.7601608743.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:31,237]\u001b[0m Trial 94 finished with value: -1481926.094866587 and parameters: {'colsample_bytree': 0.4316213363381256, 'learning_rate': 0.18434686668763284, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 218, 'reg_lambda': 0.0006576805390000563, 'reg_alpha': 4.6431489389613994e-05, 'sub_sample': 0.5415975952255386}. Best is trial 92 with value: -1469467.7601608743.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:31,861]\u001b[0m Trial 95 finished with value: -1486235.141698809 and parameters: {'colsample_bytree': 0.42603548940234715, 'learning_rate': 0.12534021309900978, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 218, 'reg_lambda': 6.802935798982815e-05, 'reg_alpha': 8.297674575107763e-05, 'sub_sample': 0.4976725734077111}. Best is trial 92 with value: -1469467.7601608743.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:32,440]\u001b[0m Trial 96 finished with value: -1528886.6740836867 and parameters: {'colsample_bytree': 0.3672399899303528, 'learning_rate': 0.18536496028060562, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 232, 'reg_lambda': 0.0006995848214500997, 'reg_alpha': 3.8639048571438166e-06, 'sub_sample': 0.5413117225755705}. Best is trial 92 with value: -1469467.7601608743.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:33,078]\u001b[0m Trial 97 finished with value: -1478842.0788787813 and parameters: {'colsample_bytree': 0.4627725629307251, 'learning_rate': 0.16966905020979467, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 229, 'reg_lambda': 0.0043811801308405954, 'reg_alpha': 0.0001272712687796276, 'sub_sample': 0.5882496820355512}. Best is trial 92 with value: -1469467.7601608743.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:33,801]\u001b[0m Trial 98 finished with value: -1650750.6178266178 and parameters: {'colsample_bytree': 0.4425545959670776, 'learning_rate': 0.5917537812040551, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 230, 'reg_lambda': 0.004547773188956617, 'reg_alpha': 3.4334959500587904e-05, 'sub_sample': 0.6531775199391731}. Best is trial 92 with value: -1469467.7601608743.\u001b[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:53:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 01:53:34,514]\u001b[0m Trial 99 finished with value: -1522544.1842180109 and parameters: {'colsample_bytree': 0.4636715878820775, 'learning_rate': 0.3135531886267748, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 222, 'reg_lambda': 0.0002786662775204591, 'reg_alpha': 1.1329912714103479e-05, 'sub_sample': 0.5871200487902459}. Best is trial 92 with value: -1469467.7601608743.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def xgb2(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, Z1_train, y1_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb2, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0c3a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.44337553771952976,\n",
       " 'learning_rate': 0.18374143513627977,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 219,\n",
       " 'reg_lambda': 6.520544606670715e-05,\n",
       " 'reg_alpha': 8.519986823155171e-05,\n",
       " 'sub_sample': 0.5398449665009374}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9eab7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1469467.7601608743"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c29c320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.981141679202066"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB2.score(Z1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ac794d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8650117157859861"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB2.score(Z1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30e18bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9606254179440374\n",
      "1209332285444.262\n",
      "1099696.4515011685\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = XGB.predict(Z_train)\n",
    "print(metrics.r2_score(y_train, y_pred3))\n",
    "print(metrics.mean_squared_error(y_train, y_pred3))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_train, y_pred3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96248f76",
   "metadata": {},
   "source": [
    "There is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd7279",
   "metadata": {},
   "source": [
    "### To investigate further into tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2511efb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1d34cfe85e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.scatterplot(y = merged_house1['unit price psf'], x = merged_house1['tenure'])\n",
    "plt.axvline(x=99, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e581d9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1d34d231910>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.scatterplot(y = merged_house2['unit price psf'], x = merged_house2['tenure'])\n",
    "plt.axvline(x=99, color = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e61f2",
   "metadata": {},
   "source": [
    "The over fitting can be because of the extreme skewness of left and right that cause the model to be unable to learn well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb52c0",
   "metadata": {},
   "source": [
    "## Splitting data into tenure up to 99 years and one with tenure up to 999 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07955a27",
   "metadata": {},
   "source": [
    "## Using merged_house_2 for lesser outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23edd2d",
   "metadata": {},
   "source": [
    "## For 99 years Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ac5e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_house99 = merged_house2[merged_house2['tenure'] <=99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c4a60b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488, 43)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house99.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a01c2ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.000e+00, 5.000e+00, 1.000e+00, 1.900e+01, 1.000e+00, 1.100e+01,\n",
       "        1.017e+03, 5.400e+01, 1.240e+02, 2.540e+02]),\n",
       " array([32. , 38.2, 44.4, 50.6, 56.8, 63. , 69.2, 75.4, 81.6, 87.8, 94. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tenure99 = merged_house99['tenure']\n",
    "\n",
    "plt.hist(tenure99, bins =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e106b34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "your_bins=10\n",
    "data= tenure99\n",
    "arr=plt.hist(data,bins=your_bins)\n",
    "for i in range(your_bins):\n",
    "    plt.text(arr[1][i],arr[0][i],str(arr[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa866c77",
   "metadata": {},
   "source": [
    "## For freehold tenures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e37accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_house999 = merged_house2[merged_house2['tenure'] >=99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb7ff3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8094, 43)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house999.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "454930e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.216e+03, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 4.490e+02,\n",
       "        0.000e+00, 6.000e+00, 0.000e+00, 6.423e+03]),\n",
       " array([852. , 866.7, 881.4, 896.1, 910.8, 925.5, 940.2, 954.9, 969.6,\n",
       "        984.3, 999. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tenure999 = merged_house999['tenure']\n",
    "\n",
    "plt.hist(tenure999, bins =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd6af09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "your_bins=10\n",
    "data= tenure999\n",
    "arr=plt.hist(data,bins=your_bins)\n",
    "for i in range(your_bins):\n",
    "    plt.text(arr[1][i],arr[0][i],str(arr[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe334ae",
   "metadata": {},
   "source": [
    "## Modelling for 99 years and 999 years (tenure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc95fe",
   "metadata": {},
   "source": [
    "### Modelling for 99 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "543e38bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project name</th>\n",
       "      <th>street name</th>\n",
       "      <th>tenure</th>\n",
       "      <th>type of sale</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>price</th>\n",
       "      <th>nett price</th>\n",
       "      <th>areasq</th>\n",
       "      <th>type of area</th>\n",
       "      <th>floor level</th>\n",
       "      <th>unit price psf</th>\n",
       "      <th>date of sale</th>\n",
       "      <th>market segment_CCR</th>\n",
       "      <th>market segment_OCR</th>\n",
       "      <th>market segment_RCR</th>\n",
       "      <th>postal district_2.0</th>\n",
       "      <th>postal district_3.0</th>\n",
       "      <th>postal district_4.0</th>\n",
       "      <th>postal district_5.0</th>\n",
       "      <th>postal district_8.0</th>\n",
       "      <th>postal district_9.0</th>\n",
       "      <th>postal district_10.0</th>\n",
       "      <th>postal district_11.0</th>\n",
       "      <th>postal district_12.0</th>\n",
       "      <th>postal district_13.0</th>\n",
       "      <th>postal district_14.0</th>\n",
       "      <th>postal district_15.0</th>\n",
       "      <th>postal district_16.0</th>\n",
       "      <th>postal district_17.0</th>\n",
       "      <th>postal district_18.0</th>\n",
       "      <th>postal district_19.0</th>\n",
       "      <th>postal district_20.0</th>\n",
       "      <th>postal district_21.0</th>\n",
       "      <th>postal district_22.0</th>\n",
       "      <th>postal district_23.0</th>\n",
       "      <th>postal district_25.0</th>\n",
       "      <th>postal district_26.0</th>\n",
       "      <th>postal district_27.0</th>\n",
       "      <th>postal district_28.0</th>\n",
       "      <th>type_Detached</th>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <th>type_Terrace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE DRIVE</td>\n",
       "      <td>84</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22800000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>7963.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2863.0</td>\n",
       "      <td>Aug-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>THE VILLAS @ SENTOSA COVE</td>\n",
       "      <td>OCEAN DRIVE</td>\n",
       "      <td>83</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>2569.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2724.0</td>\n",
       "      <td>Oct-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE DRIVE</td>\n",
       "      <td>85</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23988000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>9539.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>Nov-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE GROVE</td>\n",
       "      <td>86</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>9740.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>Feb-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>PARADISE ISLAND</td>\n",
       "      <td>PARADISE ISLAND</td>\n",
       "      <td>83</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19898000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>8137.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>Nov-2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                project name      street name  tenure type of sale  \\\n",
       "18      18  LANDED HOUSING DEVELOPMENT       COVE DRIVE      84       Resale   \n",
       "45      45   THE VILLAS @ SENTOSA COVE      OCEAN DRIVE      83       Resale   \n",
       "143    143  LANDED HOUSING DEVELOPMENT       COVE DRIVE      85       Resale   \n",
       "179    179  LANDED HOUSING DEVELOPMENT       COVE GROVE      86       Resale   \n",
       "185    185             PARADISE ISLAND  PARADISE ISLAND      83       Resale   \n",
       "\n",
       "     no. of units       price nett price  areasq type of area floor level  \\\n",
       "18            1.0  22800000.0          -  7963.0         Land           -   \n",
       "45            1.0   7000000.0          -  2569.0         Land           -   \n",
       "143           1.0  23988000.0          -  9539.0         Land           -   \n",
       "179           1.0  24000000.0          -  9740.0         Land           -   \n",
       "185           1.0  19898000.0          -  8137.0         Land           -   \n",
       "\n",
       "     unit price psf date of sale  market segment_CCR  market segment_OCR  \\\n",
       "18           2863.0     Aug-2020                   1                   0   \n",
       "45           2724.0     Oct-2021                   1                   0   \n",
       "143          2515.0     Nov-2018                   1                   0   \n",
       "179          2464.0     Feb-2020                   1                   0   \n",
       "185          2446.0     Nov-2017                   1                   0   \n",
       "\n",
       "     market segment_RCR  postal district_2.0  postal district_3.0  \\\n",
       "18                    0                    0                    0   \n",
       "45                    0                    0                    0   \n",
       "143                   0                    0                    0   \n",
       "179                   0                    0                    0   \n",
       "185                   0                    0                    0   \n",
       "\n",
       "     postal district_4.0  postal district_5.0  postal district_8.0  \\\n",
       "18                     1                    0                    0   \n",
       "45                     1                    0                    0   \n",
       "143                    1                    0                    0   \n",
       "179                    1                    0                    0   \n",
       "185                    1                    0                    0   \n",
       "\n",
       "     postal district_9.0  postal district_10.0  postal district_11.0  \\\n",
       "18                     0                     0                     0   \n",
       "45                     0                     0                     0   \n",
       "143                    0                     0                     0   \n",
       "179                    0                     0                     0   \n",
       "185                    0                     0                     0   \n",
       "\n",
       "     postal district_12.0  postal district_13.0  postal district_14.0  \\\n",
       "18                      0                     0                     0   \n",
       "45                      0                     0                     0   \n",
       "143                     0                     0                     0   \n",
       "179                     0                     0                     0   \n",
       "185                     0                     0                     0   \n",
       "\n",
       "     postal district_15.0  postal district_16.0  postal district_17.0  \\\n",
       "18                      0                     0                     0   \n",
       "45                      0                     0                     0   \n",
       "143                     0                     0                     0   \n",
       "179                     0                     0                     0   \n",
       "185                     0                     0                     0   \n",
       "\n",
       "     postal district_18.0  postal district_19.0  postal district_20.0  \\\n",
       "18                      0                     0                     0   \n",
       "45                      0                     0                     0   \n",
       "143                     0                     0                     0   \n",
       "179                     0                     0                     0   \n",
       "185                     0                     0                     0   \n",
       "\n",
       "     postal district_21.0  postal district_22.0  postal district_23.0  \\\n",
       "18                      0                     0                     0   \n",
       "45                      0                     0                     0   \n",
       "143                     0                     0                     0   \n",
       "179                     0                     0                     0   \n",
       "185                     0                     0                     0   \n",
       "\n",
       "     postal district_25.0  postal district_26.0  postal district_27.0  \\\n",
       "18                      0                     0                     0   \n",
       "45                      0                     0                     0   \n",
       "143                     0                     0                     0   \n",
       "179                     0                     0                     0   \n",
       "185                     0                     0                     0   \n",
       "\n",
       "     postal district_28.0  type_Detached  type_Semi-detached  type_Terrace  \n",
       "18                      0              1                   0             0  \n",
       "45                      0              0                   0             1  \n",
       "143                     0              1                   0             0  \n",
       "179                     0              1                   0             0  \n",
       "185                     0              1                   0             0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house99.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d9ac57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X99 = merged_house99.drop(columns = ['price','unit price psf','project name','street name','type of sale','nett price', 'type of area', 'floor level','date of sale', 'index'])\n",
    "y99 = merged_house99['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "840a833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits.\n",
    "X99_train, X99_test, y99_train, y99_test = train_test_split(X99, y99, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2fcc6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z99_train = sc.fit_transform(X99_train)\n",
    "Z99_test = sc.transform(X99_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae933024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "lr = LinearRegression()\n",
    "#fit using the training data\n",
    "lr.fit(Z99_train, y99_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46459f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982488913804038"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(Z99_train, y99_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d788320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.959561786749894e+23"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(Z99_test, y99_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc11c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982488913804038\n",
      "1148142561921.6719\n",
      "1071514.1445271135\n"
     ]
    }
   ],
   "source": [
    "y_pred99 = lr.predict(Z99_train)\n",
    "print(metrics.r2_score(y99_train, y_pred99))\n",
    "print(metrics.mean_squared_error(y99_train, y_pred99))\n",
    "print(np.sqrt(metrics.mean_squared_error(y99_train, y_pred99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f96fb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99 = XGBRegressor()\n",
    "XGB99.fit(Z99_train, y99_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a70a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-15 01:57:43,203]\u001b[0m A new study created in memory with name: no-name-48769963-d062-43a3-ae0d-6ea9f70bd102\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:43,463]\u001b[0m Trial 0 finished with value: -1503262.7346223115 and parameters: {'colsample_bytree': 0.4370861069626263, 'learning_rate': 0.9556428757689246, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 3.6323392569431376e-07, 'reg_alpha': 3.6303224667798554e-07, 'sub_sample': 0.15227525095137953}. Best is trial 0 with value: -1503262.7346223115.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:43,702]\u001b[0m Trial 1 finished with value: -1150170.6730254733 and parameters: {'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.6410035105688879, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 50.01479828856935, 'reg_alpha': 2.1106995036049625, 'sub_sample': 0.29110519961044856}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:43,846]\u001b[0m Trial 2 finished with value: -1208794.1389483078 and parameters: {'colsample_bytree': 0.26364247048639056, 'learning_rate': 0.2650640588680905, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00020866527711063722, 'reg_alpha': 8.171304639059403e-06, 'sub_sample': 0.6506676052501416}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:44,012]\u001b[0m Trial 3 finished with value: -1210826.9394459894 and parameters: {'colsample_bytree': 0.22554447458683766, 'learning_rate': 0.3629301836816964, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.7108199592296855, 'reg_alpha': 9.925166969962287e-07, 'sub_sample': 0.5628109945722505}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:44,275]\u001b[0m Trial 4 finished with value: -1296713.5747524651 and parameters: {'colsample_bytree': 0.6331731119758383, 'learning_rate': 0.14180537144799796, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.472145552469491e-08, 'reg_alpha': 30.821613670416532, 'sub_sample': 0.9690688297671034}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:44,413]\u001b[0m Trial 5 finished with value: -1301949.978406524 and parameters: {'colsample_bytree': 0.827557613304815, 'learning_rate': 0.3741523922560336, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.0002520721916536751, 'reg_alpha': 1.661048634233462e-07, 'sub_sample': 0.5456592191001431}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:44,583]\u001b[0m Trial 6 finished with value: -1394983.7893878263 and parameters: {'colsample_bytree': 0.13094966900369656, 'learning_rate': 0.9183883618709039, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 1.3095158546031483e-05, 'reg_alpha': 0.0015873774692781828, 'sub_sample': 0.5920392514089517}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:44,787]\u001b[0m Trial 7 finished with value: -1500065.54706168 and parameters: {'colsample_bytree': 0.26636900997297436, 'learning_rate': 0.9726261649881027, 'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 8.8771488946556, 'reg_alpha': 0.00952795699161383, 'sub_sample': 0.9296868115208051}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:44,935]\u001b[0m Trial 8 finished with value: -1232455.2018316747 and parameters: {'colsample_bytree': 0.17964325184672755, 'learning_rate': 0.27638457617723067, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 7.705004503489671e-05, 'reg_alpha': 5.169997317292732e-06, 'sub_sample': 0.8458637582367364}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:45,134]\u001b[0m Trial 9 finished with value: -1313934.502340464 and parameters: {'colsample_bytree': 0.4210779940242304, 'learning_rate': 0.3528410587186427, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.0518887432316704, 'reg_alpha': 5.5655288302015325e-08, 'sub_sample': 0.9881982429404655}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:45,465]\u001b[0m Trial 10 finished with value: -1455602.446632595 and parameters: {'colsample_bytree': 0.9809605894384237, 'learning_rate': 0.689800474550518, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.033011518943798196, 'reg_alpha': 11.930206277066471, 'sub_sample': 0.1727988637364622}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:45,698]\u001b[0m Trial 11 finished with value: -1329332.4205289313 and parameters: {'colsample_bytree': 0.6812603329738649, 'learning_rate': 0.6134930783935151, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.01092746380249255, 'reg_alpha': 0.08770957592660929, 'sub_sample': 0.36301461895178766}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:45,897]\u001b[0m Trial 12 finished with value: -1517042.6836031629 and parameters: {'colsample_bytree': 0.994399266443525, 'learning_rate': 0.7791819487952071, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 3.1670637814736824e-06, 'reg_alpha': 5.263100267466551e-05, 'sub_sample': 0.7406625860993338}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:46,165]\u001b[0m Trial 13 finished with value: -1460811.8236354175 and parameters: {'colsample_bytree': 0.41112437072344, 'learning_rate': 0.521834696999058, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 45.388492058419395, 'reg_alpha': 0.5239572301313041, 'sub_sample': 0.32601232616460374}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:46,392]\u001b[0m Trial 14 finished with value: -1506282.2409344653 and parameters: {'colsample_bytree': 0.8229254869578947, 'learning_rate': 0.5108890209858664, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.0052048101083046715, 'reg_alpha': 0.00014656449868479725, 'sub_sample': 0.3810114423299048}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:46,581]\u001b[0m Trial 15 finished with value: -1210306.1806005235 and parameters: {'colsample_bytree': 0.5472824513980494, 'learning_rate': 0.11182628414602758, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.24042710177233279, 'reg_alpha': 0.6407523083558733, 'sub_sample': 0.6939410233197266}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:46,840]\u001b[0m Trial 16 finished with value: -1304919.642524238 and parameters: {'colsample_bytree': 0.3325032107964724, 'learning_rate': 0.7935232826296945, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00043392916424676, 'reg_alpha': 1.2059932616197178e-08, 'sub_sample': 0.4494436071105368}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:47,015]\u001b[0m Trial 17 finished with value: -1237868.7725021148 and parameters: {'colsample_bytree': 0.8067323250928929, 'learning_rate': 0.24551794975531538, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 6.235853855341269e-06, 'reg_alpha': 1.5802497706519067e-05, 'sub_sample': 0.2628961996743277}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:47,301]\u001b[0m Trial 18 finished with value: -1528059.45545346 and parameters: {'colsample_bytree': 0.543064693353509, 'learning_rate': 0.4548523041801831, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 1.0923837443062426e-08, 'reg_alpha': 0.0012929447120910219, 'sub_sample': 0.699882075376947}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:47,535]\u001b[0m Trial 19 finished with value: -1391871.7614499966 and parameters: {'colsample_bytree': 0.7027938312247927, 'learning_rate': 0.6273714030121061, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.0024701753817909376, 'reg_alpha': 0.026820959225055646, 'sub_sample': 0.47727048327543947}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:47,773]\u001b[0m Trial 20 finished with value: -1519926.7902161712 and parameters: {'colsample_bytree': 0.9060199894521436, 'learning_rate': 0.7700472152783937, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.060325066123025364, 'reg_alpha': 5.570594179109627, 'sub_sample': 0.2631616762525045}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:47,948]\u001b[0m Trial 21 finished with value: -1199837.3295753868 and parameters: {'colsample_bytree': 0.55131131388013, 'learning_rate': 0.10647687524241853, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.4091546647372176, 'reg_alpha': 1.0447017464510215, 'sub_sample': 0.7060120341889914}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:48,170]\u001b[0m Trial 22 finished with value: -1600771.2495285242 and parameters: {'colsample_bytree': 0.4886720073997092, 'learning_rate': 0.22393049209767973, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 73.5639107703932, 'reg_alpha': 2.042654306581319, 'sub_sample': 0.7686914466802824}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:48,371]\u001b[0m Trial 23 finished with value: -1258612.080613079 and parameters: {'colsample_bytree': 0.30391377813270676, 'learning_rate': 0.14221473200765905, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 3.0878508363829944, 'reg_alpha': 55.30165513115487, 'sub_sample': 0.625194790827392}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:48,545]\u001b[0m Trial 24 finished with value: -1262260.686032601 and parameters: {'colsample_bytree': 0.7450471687608262, 'learning_rate': 0.20183636300186075, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 6.279391659818849, 'reg_alpha': 0.1410753915699317, 'sub_sample': 0.8655554193771716}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:48,782]\u001b[0m Trial 25 finished with value: -1278191.3269895292 and parameters: {'colsample_bytree': 0.3568948375189369, 'learning_rate': 0.4434844704380323, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 22.729628669539025, 'reg_alpha': 0.00022642092841446409, 'sub_sample': 0.6596489179775697}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:48,982]\u001b[0m Trial 26 finished with value: -1365128.330537341 and parameters: {'colsample_bytree': 0.6365750593477941, 'learning_rate': 0.2913200598025512, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.494894847751889e-05, 'reg_alpha': 0.005969179865207776, 'sub_sample': 0.4691607209665547}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:49,220]\u001b[0m Trial 27 finished with value: -1257300.7669983523 and parameters: {'colsample_bytree': 0.9099077940501046, 'learning_rate': 0.18154255252844198, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.1784906606447734, 'reg_alpha': 1.4069297241574135, 'sub_sample': 0.7759794258841715}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:49,415]\u001b[0m Trial 28 finished with value: -1252991.1400419162 and parameters: {'colsample_bytree': 0.12058693489473726, 'learning_rate': 0.6535709561776076, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.0010658494919460507, 'reg_alpha': 2.7885495071767154e-06, 'sub_sample': 0.5205080937153611}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:49,690]\u001b[0m Trial 29 finished with value: -1377613.6905646892 and parameters: {'colsample_bytree': 0.47927299711700594, 'learning_rate': 0.5734799715408092, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 8.381610736329476e-07, 'reg_alpha': 0.13833984904270907, 'sub_sample': 0.8647233806052192}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:49,985]\u001b[0m Trial 30 finished with value: -1252483.816649861 and parameters: {'colsample_bytree': 0.3799415487991106, 'learning_rate': 0.3058576569902467, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.9016893795304437, 'reg_alpha': 7.881313450531114, 'sub_sample': 0.1198039032668019}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:50,200]\u001b[0m Trial 31 finished with value: -1202565.9605272864 and parameters: {'colsample_bytree': 0.5363370106196876, 'learning_rate': 0.13314455907362785, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.306872513187559, 'reg_alpha': 1.1473726874823442, 'sub_sample': 0.6537950074653933}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:50,425]\u001b[0m Trial 32 finished with value: -1236180.5734998635 and parameters: {'colsample_bytree': 0.23557456334559917, 'learning_rate': 0.10288327550391971, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.022711879376759718, 'reg_alpha': 0.042961223870928766, 'sub_sample': 0.620546637920046}. Best is trial 1 with value: -1150170.6730254733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:50,678]\u001b[0m Trial 33 finished with value: -1119836.9782695747 and parameters: {'colsample_bytree': 0.6269718027125277, 'learning_rate': 0.16258418074788505, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.14454535570679294, 'reg_alpha': 33.26456466540704, 'sub_sample': 0.8137769580687532}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:50,878]\u001b[0m Trial 34 finished with value: -1221989.5408934343 and parameters: {'colsample_bytree': 0.5833200209791748, 'learning_rate': 0.177424580677157, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.17537554378991696, 'reg_alpha': 66.54569047875172, 'sub_sample': 0.808860014741112}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:51,063]\u001b[0m Trial 35 finished with value: -1371756.4010089382 and parameters: {'colsample_bytree': 0.6030660832302324, 'learning_rate': 0.7192634675870696, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 2.0992327336605374, 'reg_alpha': 3.826915468713972, 'sub_sample': 0.710640324876739}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:51,264]\u001b[0m Trial 36 finished with value: -1224764.685818645 and parameters: {'colsample_bytree': 0.4980446460689077, 'learning_rate': 0.15980267443201712, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 8.864663882942034, 'reg_alpha': 19.427821261692547, 'sub_sample': 0.5801721977787911}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:51,479]\u001b[0m Trial 37 finished with value: -1476563.5587115854 and parameters: {'colsample_bytree': 0.7653139413142371, 'learning_rate': 0.8618959466230738, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.37959391750762583, 'reg_alpha': 96.12489129100986, 'sub_sample': 0.6648249807953243}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:51,758]\u001b[0m Trial 38 finished with value: -1349879.5589005477 and parameters: {'colsample_bytree': 0.65932681037536, 'learning_rate': 0.4315900208893262, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.07113061923614554, 'reg_alpha': 0.336923672864865, 'sub_sample': 0.9070668258357103}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:51,946]\u001b[0m Trial 39 finished with value: -1263906.1877827954 and parameters: {'colsample_bytree': 0.8955566540075524, 'learning_rate': 0.3436984395724971, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 21.43504375655642, 'reg_alpha': 2.235792151703672, 'sub_sample': 0.802596922711834}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:52,196]\u001b[0m Trial 40 finished with value: -1234450.204381587 and parameters: {'colsample_bytree': 0.7316188648760563, 'learning_rate': 0.22262585961269346, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 2.0892038156012123, 'reg_alpha': 22.01445361298979, 'sub_sample': 0.5472423345235127}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:52,408]\u001b[0m Trial 41 finished with value: -1199072.9902479209 and parameters: {'colsample_bytree': 0.4591422172389446, 'learning_rate': 0.1015109841150422, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 5.402461393593474e-05, 'reg_alpha': 8.365882160463544e-07, 'sub_sample': 0.7384052176574935}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:52,609]\u001b[0m Trial 42 finished with value: -1317361.837975805 and parameters: {'colsample_bytree': 0.4603328147029867, 'learning_rate': 0.12394091484830295, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 4.1879014657922815e-05, 'reg_alpha': 0.011050246950175986, 'sub_sample': 0.745240227939133}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:52,816]\u001b[0m Trial 43 finished with value: -1132379.2659124003 and parameters: {'colsample_bytree': 0.5316801517781908, 'learning_rate': 0.15503449168002903, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.01281063752303917, 'reg_alpha': 1.4797240306256921e-07, 'sub_sample': 0.8219095964334227}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:53,023]\u001b[0m Trial 44 finished with value: -1154801.0101902853 and parameters: {'colsample_bytree': 0.6037633388968007, 'learning_rate': 0.17485364202826134, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.011095255106855263, 'reg_alpha': 4.913729312375821e-07, 'sub_sample': 0.9241615589092567}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:53,265]\u001b[0m Trial 45 finished with value: -1446268.5258420762 and parameters: {'colsample_bytree': 0.597242378163852, 'learning_rate': 0.25920196030448434, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 0.007209857395961539, 'reg_alpha': 2.468628741509058e-07, 'sub_sample': 0.9270153089590569}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:53,477]\u001b[0m Trial 46 finished with value: -1287167.738255512 and parameters: {'colsample_bytree': 0.40233229156320127, 'learning_rate': 0.1893817243139322, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.00016905954159860868, 'reg_alpha': 7.520834987154448e-07, 'sub_sample': 0.9704664375951988}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:53,649]\u001b[0m Trial 47 finished with value: -1259451.593209694 and parameters: {'colsample_bytree': 0.442955964288557, 'learning_rate': 0.3161793632765531, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.0014128909869412657, 'reg_alpha': 4.938444411411619e-08, 'sub_sample': 0.8887611614233728}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:53,955]\u001b[0m Trial 48 finished with value: -1368781.4726020521 and parameters: {'colsample_bytree': 0.5174358225409347, 'learning_rate': 0.4062016924493683, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.003648769944258203, 'reg_alpha': 1.2579180106696765e-06, 'sub_sample': 0.9977014108202379}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:54,197]\u001b[0m Trial 49 finished with value: -1285069.254053504 and parameters: {'colsample_bytree': 0.8621550257503912, 'learning_rate': 0.5570468868497753, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00047188651323108656, 'reg_alpha': 3.959487760262846e-08, 'sub_sample': 0.8429918583904021}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:54,375]\u001b[0m Trial 50 finished with value: -1295167.343150207 and parameters: {'colsample_bytree': 0.6298998075256023, 'learning_rate': 0.24274736260933405, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 1.6487981600043967e-05, 'reg_alpha': 1.8710691292869894e-05, 'sub_sample': 0.9419267148686521}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:54,575]\u001b[0m Trial 51 finished with value: -1192275.574283918 and parameters: {'colsample_bytree': 0.5744076955576369, 'learning_rate': 0.16037211425401277, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.05592485526901534, 'reg_alpha': 1.5872550711989068e-07, 'sub_sample': 0.8160518993983317}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:54,762]\u001b[0m Trial 52 finished with value: -1186799.9724841057 and parameters: {'colsample_bytree': 0.5779940028214786, 'learning_rate': 0.15892331758788547, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.019551771858161083, 'reg_alpha': 1.2383168370128175e-08, 'sub_sample': 0.8263093174646428}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:54,959]\u001b[0m Trial 53 finished with value: -1164938.3069796355 and parameters: {'colsample_bytree': 0.6584217104466317, 'learning_rate': 0.15781516344661894, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.02566741430817968, 'reg_alpha': 1.0929141210327503e-07, 'sub_sample': 0.8290084082260002}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:55,203]\u001b[0m Trial 54 finished with value: -1251458.271785126 and parameters: {'colsample_bytree': 0.6998936274793855, 'learning_rate': 0.21823378805402316, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.020310924204411378, 'reg_alpha': 1.1640384129203349e-08, 'sub_sample': 0.2073310570797514}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:55,395]\u001b[0m Trial 55 finished with value: -1148009.2225029345 and parameters: {'colsample_bytree': 0.6660161475656639, 'learning_rate': 0.2781659443098879, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.013659573429616238, 'reg_alpha': 2.9576099260712286e-08, 'sub_sample': 0.8351997599206176}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:55,560]\u001b[0m Trial 56 finished with value: -1310281.344575888 and parameters: {'colsample_bytree': 0.670169007832342, 'learning_rate': 0.26162473759009724, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.002569418200471772, 'reg_alpha': 6.760704850595494e-08, 'sub_sample': 0.9459172608684564}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:55,767]\u001b[0m Trial 57 finished with value: -1176061.3472490413 and parameters: {'colsample_bytree': 0.796886043590822, 'learning_rate': 0.33862563035151894, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.008277703067318384, 'reg_alpha': 1.1856153640757654e-07, 'sub_sample': 0.8997965474956182}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:56,056]\u001b[0m Trial 58 finished with value: -1363232.7117064244 and parameters: {'colsample_bytree': 0.9445011583485116, 'learning_rate': 0.38124865460404367, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.06788657908154681, 'reg_alpha': 3.473893005052794e-06, 'sub_sample': 0.8715113409319972}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:56,273]\u001b[0m Trial 59 finished with value: -1429166.7116684704 and parameters: {'colsample_bytree': 0.7116058286971774, 'learning_rate': 0.507327248706466, 'max_depth': 2, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 0.011915588506755365, 'reg_alpha': 2.408017849459589e-08, 'sub_sample': 0.7800377419088141}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:56,493]\u001b[0m Trial 60 finished with value: -1502266.4671710827 and parameters: {'colsample_bytree': 0.6299908367921646, 'learning_rate': 0.6903656979949587, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.1276870094451076, 'reg_alpha': 3.5127028282883864e-07, 'sub_sample': 0.35465615907267145}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:56,687]\u001b[0m Trial 61 finished with value: -1252586.9956336464 and parameters: {'colsample_bytree': 0.814507791513437, 'learning_rate': 0.27992866882311096, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.004262440535671103, 'reg_alpha': 1.1661335888729105e-07, 'sub_sample': 0.9190382918457948}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:56,890]\u001b[0m Trial 62 finished with value: -1217728.2100450355 and parameters: {'colsample_bytree': 0.7586071913260248, 'learning_rate': 0.20289950008614088, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.010231460598827716, 'reg_alpha': 9.991635515725297e-08, 'sub_sample': 0.897706785962042}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:57,095]\u001b[0m Trial 63 finished with value: -1170912.6248393396 and parameters: {'colsample_bytree': 0.7949683093032892, 'learning_rate': 0.3304099207624065, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.03661700081956807, 'reg_alpha': 3.731718718836523e-07, 'sub_sample': 0.42440124414785774}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:57,308]\u001b[0m Trial 64 finished with value: -1251311.0783420082 and parameters: {'colsample_bytree': 0.8675956703373594, 'learning_rate': 0.23698610150371718, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.03627106205528529, 'reg_alpha': 1.062008809910664e-05, 'sub_sample': 0.3036052176906978}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:57,485]\u001b[0m Trial 65 finished with value: -1297358.8828781385 and parameters: {'colsample_bytree': 0.7857908408740758, 'learning_rate': 0.6056243571510654, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.0006741373963732985, 'reg_alpha': 1.5201753319780777e-06, 'sub_sample': 0.4014198785706355}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:57,706]\u001b[0m Trial 66 finished with value: -1266153.116866395 and parameters: {'colsample_bytree': 0.6495822611533788, 'learning_rate': 0.31450110139166865, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.0002052703731755253, 'reg_alpha': 3.8533846734993666e-07, 'sub_sample': 0.20149844920634646}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:57,946]\u001b[0m Trial 67 finished with value: -1196593.3765367724 and parameters: {'colsample_bytree': 0.8428713214461367, 'learning_rate': 0.14010703899022733, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.7579133670954469, 'reg_alpha': 2.69339246718725e-08, 'sub_sample': 0.25371064566184354}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:58,153]\u001b[0m Trial 68 finished with value: -1309140.7464488202 and parameters: {'colsample_bytree': 0.9669060753165561, 'learning_rate': 0.19041329429214618, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.002018664666337611, 'reg_alpha': 8.760763559068501e-05, 'sub_sample': 0.4935772591918781}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:58,461]\u001b[0m Trial 69 finished with value: -1365829.9746177227 and parameters: {'colsample_bytree': 0.6840914001247898, 'learning_rate': 0.48735721290704603, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.11148925178693077, 'reg_alpha': 0.0003560392761387107, 'sub_sample': 0.4119682147189103}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:58,652]\u001b[0m Trial 70 finished with value: -1252788.9060901655 and parameters: {'colsample_bytree': 0.5217966627159065, 'learning_rate': 0.27903227646640494, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.01695583807796706, 'reg_alpha': 6.506879512263207e-07, 'sub_sample': 0.849501181116168}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:58,856]\u001b[0m Trial 71 finished with value: -1174998.1454027686 and parameters: {'colsample_bytree': 0.7946473594264964, 'learning_rate': 0.3284098288675199, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00534627456725592, 'reg_alpha': 2.0499595346926023e-07, 'sub_sample': 0.9606456536935901}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:59,056]\u001b[0m Trial 72 finished with value: -1193917.4353972145 and parameters: {'colsample_bytree': 0.7337099447389673, 'learning_rate': 0.3858202369042807, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.038069037920565436, 'reg_alpha': 3.561940736953042e-07, 'sub_sample': 0.9646560639025413}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:59,254]\u001b[0m Trial 73 finished with value: -1164372.933144331 and parameters: {'colsample_bytree': 0.6185710361481707, 'learning_rate': 0.1550277713860996, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.006667911112827802, 'reg_alpha': 2.6551987880753972e-06, 'sub_sample': 0.8752074178080967}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:59,459]\u001b[0m Trial 74 finished with value: -1161672.288692277 and parameters: {'colsample_bytree': 0.6073838579415123, 'learning_rate': 0.17415987654883547, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.001137794519624628, 'reg_alpha': 1.6000907389209834e-06, 'sub_sample': 0.7843546628992922}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:59,670]\u001b[0m Trial 75 finished with value: -1151368.4205906964 and parameters: {'colsample_bytree': 0.6119021589770145, 'learning_rate': 0.15450178608876752, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.0017916105121307557, 'reg_alpha': 9.769571466860514e-06, 'sub_sample': 0.7881990994189361}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:57:59,861]\u001b[0m Trial 76 finished with value: -1208726.2074976433 and parameters: {'colsample_bytree': 0.60891045725216, 'learning_rate': 0.12929610428259872, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.001162214974482064, 'reg_alpha': 5.926407112860232e-06, 'sub_sample': 0.7791980825278979}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:57:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:00,095]\u001b[0m Trial 77 finished with value: -1364746.3151002785 and parameters: {'colsample_bytree': 0.5419835030324663, 'learning_rate': 0.2062502626581177, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.0003319550952173221, 'reg_alpha': 0.002407860676194443, 'sub_sample': 0.754246235666124}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:00,292]\u001b[0m Trial 78 finished with value: -1160279.9079333078 and parameters: {'colsample_bytree': 0.5574059787808694, 'learning_rate': 0.17490677181741582, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.0019547377176560503, 'reg_alpha': 4.778004294649997e-05, 'sub_sample': 0.8765927439884011}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:00,484]\u001b[0m Trial 79 finished with value: -1191671.3682895473 and parameters: {'colsample_bytree': 0.5640747580239126, 'learning_rate': 0.12067146030186618, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.0019066659494154535, 'reg_alpha': 3.2301681889310426e-05, 'sub_sample': 0.7178556421963023}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:00,681]\u001b[0m Trial 80 finished with value: -1141212.9321514668 and parameters: {'colsample_bytree': 0.5025712433574094, 'learning_rate': 0.18710054929823483, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 9.952034695626383e-05, 'reg_alpha': 5.4639492934530145e-05, 'sub_sample': 0.7878062506467359}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:00,859]\u001b[0m Trial 81 finished with value: -1150769.7505667803 and parameters: {'colsample_bytree': 0.5058224704193207, 'learning_rate': 0.17811864859767534, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00012503830536406482, 'reg_alpha': 0.0003472588200492078, 'sub_sample': 0.7975642938088461}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:01,070]\u001b[0m Trial 82 finished with value: -1217425.073331822 and parameters: {'colsample_bytree': 0.5002931137143319, 'learning_rate': 0.21987013857351345, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 2.4304706719976363e-05, 'reg_alpha': 0.000841428451358527, 'sub_sample': 0.8069911712469643}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:01,261]\u001b[0m Trial 83 finished with value: -1137462.335296026 and parameters: {'colsample_bytree': 0.4740633455390283, 'learning_rate': 0.18435724030564268, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 6.326217644840466e-06, 'reg_alpha': 5.696497021818159e-05, 'sub_sample': 0.8495823342001725}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:01,443]\u001b[0m Trial 84 finished with value: -1162575.4644462466 and parameters: {'colsample_bytree': 0.41420876686919245, 'learning_rate': 0.2431008154391678, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 2.3876428182746834e-06, 'reg_alpha': 2.1638139146352377e-05, 'sub_sample': 0.7237418313793478}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:01,684]\u001b[0m Trial 85 finished with value: -1192265.7469795302 and parameters: {'colsample_bytree': 0.4824134789690346, 'learning_rate': 0.10114290847807027, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 4.934418694017155e-06, 'reg_alpha': 0.0003970207203936205, 'sub_sample': 0.679337073859846}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:01,863]\u001b[0m Trial 86 finished with value: -1166090.7110116994 and parameters: {'colsample_bytree': 0.4400082570012743, 'learning_rate': 0.13701229756802666, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00016551569998195798, 'reg_alpha': 9.543968823684611e-05, 'sub_sample': 0.7939571446644677}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:02,026]\u001b[0m Trial 87 finished with value: -1262730.462786626 and parameters: {'colsample_bytree': 0.5211305863569714, 'learning_rate': 0.20947622539327768, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 9.825553331079781e-05, 'reg_alpha': 0.0002537233298141033, 'sub_sample': 0.8426775959841609}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:02,243]\u001b[0m Trial 88 finished with value: -1315391.2950574001 and parameters: {'colsample_bytree': 0.38807881663576305, 'learning_rate': 0.6553167853644032, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 5.326397123512928e-07, 'reg_alpha': 0.0005878636647324728, 'sub_sample': 0.758752564230282}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:02,443]\u001b[0m Trial 89 finished with value: -1146165.8684334652 and parameters: {'colsample_bytree': 0.46404312077790766, 'learning_rate': 0.18299036815502087, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 7.033738709372067e-05, 'reg_alpha': 0.0021997064631307734, 'sub_sample': 0.8516042748867354}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:02,642]\u001b[0m Trial 90 finished with value: -1230823.1263058365 and parameters: {'colsample_bytree': 0.4715927670537502, 'learning_rate': 0.29577601751050553, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00010144753168812761, 'reg_alpha': 0.0035488848017516395, 'sub_sample': 0.8486620333454129}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:02,830]\u001b[0m Trial 91 finished with value: -1188802.4577833097 and parameters: {'colsample_bytree': 0.5073799415009221, 'learning_rate': 0.2611923076125679, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 9.71029794063892e-06, 'reg_alpha': 8.709386567547363e-05, 'sub_sample': 0.8240857577256978}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:03,039]\u001b[0m Trial 92 finished with value: -1158192.1154890698 and parameters: {'colsample_bytree': 0.43466190604713195, 'learning_rate': 0.18786675916337459, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.0005901252191788333, 'reg_alpha': 0.0001729216428751397, 'sub_sample': 0.8596230559246927}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:03,234]\u001b[0m Trial 93 finished with value: -1151805.336504726 and parameters: {'colsample_bytree': 0.5371531466431233, 'learning_rate': 0.14854316447215385, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 7.804792140547139e-08, 'reg_alpha': 10.982810866417903, 'sub_sample': 0.6303160328678467}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:03,424]\u001b[0m Trial 94 finished with value: -1129044.933126682 and parameters: {'colsample_bytree': 0.5383665475747813, 'learning_rate': 0.15129339958063134, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 1.2853245349321368e-08, 'reg_alpha': 10.873703485316062, 'sub_sample': 0.6320755086654559}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:03,624]\u001b[0m Trial 95 finished with value: -1196506.5583215624 and parameters: {'colsample_bytree': 0.45780440343249057, 'learning_rate': 0.2277932781348582, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 1.292209994818302e-06, 'reg_alpha': 31.31005600157123, 'sub_sample': 0.6856493566654185}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:03,812]\u001b[0m Trial 96 finished with value: -1292911.8197802613 and parameters: {'colsample_bytree': 0.3537041290740882, 'learning_rate': 0.1207768423767085, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 1.0933776284723598e-07, 'reg_alpha': 2.9088969626131806, 'sub_sample': 0.10022492701658184}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:04,080]\u001b[0m Trial 97 finished with value: -1269164.469486098 and parameters: {'colsample_bytree': 0.5866028190475026, 'learning_rate': 0.19697202785511364, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 1.127046524370576e-08, 'reg_alpha': 30.816552165950846, 'sub_sample': 0.5789080264264304}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:04,282]\u001b[0m Trial 98 finished with value: -1202892.756778575 and parameters: {'colsample_bytree': 0.4893219580051771, 'learning_rate': 0.16529647530934316, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 2.1782445597481482e-05, 'reg_alpha': 0.5962110108405473, 'sub_sample': 0.7357980665265302}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:04,458]\u001b[0m Trial 99 finished with value: -1246969.9836926654 and parameters: {'colsample_bytree': 0.18597907000538128, 'learning_rate': 0.1414550550743955, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 6.374198658528004e-05, 'reg_alpha': 4.382188602642653, 'sub_sample': 0.7986268993673694}. Best is trial 33 with value: -1119836.9782695747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def xgb99(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300, 500)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, Z99_train, y99_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb99, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8dd7440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6269718027125277,\n",
       " 'learning_rate': 0.16258418074788505,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 100,\n",
       " 'reg_lambda': 0.14454535570679294,\n",
       " 'reg_alpha': 33.26456466540704,\n",
       " 'sub_sample': 0.8137769580687532}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc3f9e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1119836.9782695747"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4e3782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.6269718027125277,\n",
       "             enable_categorical=False, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.16258418074788505,\n",
       "             max_delta_step=0, max_depth=2, min_child_weight=3, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=33.26456466540704, reg_lambda=0.14454535570679294,\n",
       "             scale_pos_weight=1, sub_sample=0.8137769580687532, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99 = XGBRegressor(colsample_bytree=  0.6269718027125277, learning_rate= 0.16258418074788505, max_depth= 2 , min_child_weight= 3, n_estimators= 100,\n",
    "reg_alpha= 33.26456466540704, reg_lambda= 0.14454535570679294, sub_sample=  0.8137769580687532)\n",
    "XGB99.fit(Z99_train, y99_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a5594ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9654211026913094"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99.score(Z99_train, y99_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e74dc4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386560111604331"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99.score(Z99_test, y99_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89b66051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9654211026913094\n",
      "390182517743.8931\n",
      "624645.9138935378\n"
     ]
    }
   ],
   "source": [
    "y_pred99 = XGB99.predict(Z99_train)\n",
    "print(metrics.r2_score(y99_train, y_pred99))\n",
    "print(metrics.mean_squared_error(y99_train, y_pred99))\n",
    "print(np.sqrt(metrics.mean_squared_error(y99_train, y_pred99)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a786274",
   "metadata": {},
   "source": [
    "## Overfitting model still require removal of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7417f92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 36., 448., 398., 157., 166.,  59.,  32.,  65.,  26.,  14.,   5.,\n",
       "          6.,   0.,   3.,   2.,   0.,   2.,   1.,   3.,   1.,   1.,   5.,\n",
       "          1.,   1.,   3.,   3.,   1.,   2.,   4.,   1.,   6.,   2.,   8.,\n",
       "          0.,   2.,   1.,   3.,   3.,   1.,   1.,   0.,   0.,   0.,   0.,\n",
       "          4.,   0.,   1.,   1.,   0.,   0.,   0.,   1.,   0.,   1.,   1.,\n",
       "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   1.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          1.]),\n",
       " array([  900000.,  1327660.,  1755320.,  2182980.,  2610640.,  3038300.,\n",
       "         3465960.,  3893620.,  4321280.,  4748940.,  5176600.,  5604260.,\n",
       "         6031920.,  6459580.,  6887240.,  7314900.,  7742560.,  8170220.,\n",
       "         8597880.,  9025540.,  9453200.,  9880860., 10308520., 10736180.,\n",
       "        11163840., 11591500., 12019160., 12446820., 12874480., 13302140.,\n",
       "        13729800., 14157460., 14585120., 15012780., 15440440., 15868100.,\n",
       "        16295760., 16723420., 17151080., 17578740., 18006400., 18434060.,\n",
       "        18861720., 19289380., 19717040., 20144700., 20572360., 21000020.,\n",
       "        21427680., 21855340., 22283000., 22710660., 23138320., 23565980.,\n",
       "        23993640., 24421300., 24848960., 25276620., 25704280., 26131940.,\n",
       "        26559600., 26987260., 27414920., 27842580., 28270240., 28697900.,\n",
       "        29125560., 29553220., 29980880., 30408540., 30836200., 31263860.,\n",
       "        31691520., 32119180., 32546840., 32974500., 33402160., 33829820.,\n",
       "        34257480., 34685140., 35112800., 35540460., 35968120., 36395780.,\n",
       "        36823440., 37251100., 37678760., 38106420., 38534080., 38961740.,\n",
       "        39389400., 39817060., 40244720., 40672380., 41100040., 41527700.,\n",
       "        41955360., 42383020., 42810680., 43238340., 43666000.]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "price99 = merged_house99['price']\n",
    "\n",
    "plt.hist(price99, bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c4ec5c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "your_bins=10\n",
    "data= price99\n",
    "arr=plt.hist(data,bins=your_bins)\n",
    "for i in range(your_bins):\n",
    "    plt.text(arr[1][i],arr[0][i],str(arr[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e94da",
   "metadata": {},
   "source": [
    "#remove the top 9 outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06eb9312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project name</th>\n",
       "      <th>street name</th>\n",
       "      <th>tenure</th>\n",
       "      <th>type of sale</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>price</th>\n",
       "      <th>nett price</th>\n",
       "      <th>areasq</th>\n",
       "      <th>type of area</th>\n",
       "      <th>floor level</th>\n",
       "      <th>unit price psf</th>\n",
       "      <th>date of sale</th>\n",
       "      <th>market segment_CCR</th>\n",
       "      <th>market segment_OCR</th>\n",
       "      <th>market segment_RCR</th>\n",
       "      <th>postal district_2.0</th>\n",
       "      <th>postal district_3.0</th>\n",
       "      <th>postal district_4.0</th>\n",
       "      <th>postal district_5.0</th>\n",
       "      <th>postal district_8.0</th>\n",
       "      <th>postal district_9.0</th>\n",
       "      <th>postal district_10.0</th>\n",
       "      <th>postal district_11.0</th>\n",
       "      <th>postal district_12.0</th>\n",
       "      <th>postal district_13.0</th>\n",
       "      <th>postal district_14.0</th>\n",
       "      <th>postal district_15.0</th>\n",
       "      <th>postal district_16.0</th>\n",
       "      <th>postal district_17.0</th>\n",
       "      <th>postal district_18.0</th>\n",
       "      <th>postal district_19.0</th>\n",
       "      <th>postal district_20.0</th>\n",
       "      <th>postal district_21.0</th>\n",
       "      <th>postal district_22.0</th>\n",
       "      <th>postal district_23.0</th>\n",
       "      <th>postal district_25.0</th>\n",
       "      <th>postal district_26.0</th>\n",
       "      <th>postal district_27.0</th>\n",
       "      <th>postal district_28.0</th>\n",
       "      <th>type_Detached</th>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <th>type_Terrace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE DRIVE</td>\n",
       "      <td>84</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43666000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>18053.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2419.0</td>\n",
       "      <td>Feb-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>645</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>OCEAN DRIVE</td>\n",
       "      <td>83</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39333999.0</td>\n",
       "      <td>-</td>\n",
       "      <td>19551.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mar-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1344</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE GROVE</td>\n",
       "      <td>85</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33300000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>18555.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>Aug-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1431</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE DRIVE</td>\n",
       "      <td>84</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32000000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>18053.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>Apr-2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1486</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>LAKESHORE VIEW</td>\n",
       "      <td>83</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28000000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>15881.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>Sep-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>602</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>PEARL ISLAND</td>\n",
       "      <td>86</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25375000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>12486.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>Dec-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE GROVE</td>\n",
       "      <td>86</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24000000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>9740.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>Feb-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE DRIVE</td>\n",
       "      <td>85</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23988000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>9539.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>Nov-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>COVE DRIVE</td>\n",
       "      <td>84</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22800000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>7963.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2863.0</td>\n",
       "      <td>Aug-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                project name     street name  tenure type of sale  \\\n",
       "203     203  LANDED HOUSING DEVELOPMENT      COVE DRIVE      84       Resale   \n",
       "645     645  LANDED HOUSING DEVELOPMENT     OCEAN DRIVE      83       Resale   \n",
       "1344   1344  LANDED HOUSING DEVELOPMENT      COVE GROVE      85       Resale   \n",
       "1431   1431  LANDED HOUSING DEVELOPMENT      COVE DRIVE      84       Resale   \n",
       "1486   1486  LANDED HOUSING DEVELOPMENT  LAKESHORE VIEW      83       Resale   \n",
       "602     602  LANDED HOUSING DEVELOPMENT    PEARL ISLAND      86       Resale   \n",
       "179     179  LANDED HOUSING DEVELOPMENT      COVE GROVE      86       Resale   \n",
       "143     143  LANDED HOUSING DEVELOPMENT      COVE DRIVE      85       Resale   \n",
       "18       18  LANDED HOUSING DEVELOPMENT      COVE DRIVE      84       Resale   \n",
       "\n",
       "      no. of units       price nett price   areasq type of area floor level  \\\n",
       "203            1.0  43666000.0          -  18053.0         Land           -   \n",
       "645            1.0  39333999.0          -  19551.0         Land           -   \n",
       "1344           1.0  33300000.0          -  18555.0         Land           -   \n",
       "1431           1.0  32000000.0          -  18053.0         Land           -   \n",
       "1486           1.0  28000000.0          -  15881.0         Land           -   \n",
       "602            1.0  25375000.0          -  12486.0         Land           -   \n",
       "179            1.0  24000000.0          -   9740.0         Land           -   \n",
       "143            1.0  23988000.0          -   9539.0         Land           -   \n",
       "18             1.0  22800000.0          -   7963.0         Land           -   \n",
       "\n",
       "      unit price psf date of sale  market segment_CCR  market segment_OCR  \\\n",
       "203           2419.0     Feb-2021                   1                   0   \n",
       "645           2012.0     Mar-2021                   1                   0   \n",
       "1344          1795.0     Aug-2018                   1                   0   \n",
       "1431          1773.0     Apr-2019                   1                   0   \n",
       "1486          1763.0     Sep-2021                   1                   0   \n",
       "602           2032.0     Dec-2020                   1                   0   \n",
       "179           2464.0     Feb-2020                   1                   0   \n",
       "143           2515.0     Nov-2018                   1                   0   \n",
       "18            2863.0     Aug-2020                   1                   0   \n",
       "\n",
       "      market segment_RCR  postal district_2.0  postal district_3.0  \\\n",
       "203                    0                    0                    0   \n",
       "645                    0                    0                    0   \n",
       "1344                   0                    0                    0   \n",
       "1431                   0                    0                    0   \n",
       "1486                   0                    0                    0   \n",
       "602                    0                    0                    0   \n",
       "179                    0                    0                    0   \n",
       "143                    0                    0                    0   \n",
       "18                     0                    0                    0   \n",
       "\n",
       "      postal district_4.0  postal district_5.0  postal district_8.0  \\\n",
       "203                     1                    0                    0   \n",
       "645                     1                    0                    0   \n",
       "1344                    1                    0                    0   \n",
       "1431                    1                    0                    0   \n",
       "1486                    1                    0                    0   \n",
       "602                     1                    0                    0   \n",
       "179                     1                    0                    0   \n",
       "143                     1                    0                    0   \n",
       "18                      1                    0                    0   \n",
       "\n",
       "      postal district_9.0  postal district_10.0  postal district_11.0  \\\n",
       "203                     0                     0                     0   \n",
       "645                     0                     0                     0   \n",
       "1344                    0                     0                     0   \n",
       "1431                    0                     0                     0   \n",
       "1486                    0                     0                     0   \n",
       "602                     0                     0                     0   \n",
       "179                     0                     0                     0   \n",
       "143                     0                     0                     0   \n",
       "18                      0                     0                     0   \n",
       "\n",
       "      postal district_12.0  postal district_13.0  postal district_14.0  \\\n",
       "203                      0                     0                     0   \n",
       "645                      0                     0                     0   \n",
       "1344                     0                     0                     0   \n",
       "1431                     0                     0                     0   \n",
       "1486                     0                     0                     0   \n",
       "602                      0                     0                     0   \n",
       "179                      0                     0                     0   \n",
       "143                      0                     0                     0   \n",
       "18                       0                     0                     0   \n",
       "\n",
       "      postal district_15.0  postal district_16.0  postal district_17.0  \\\n",
       "203                      0                     0                     0   \n",
       "645                      0                     0                     0   \n",
       "1344                     0                     0                     0   \n",
       "1431                     0                     0                     0   \n",
       "1486                     0                     0                     0   \n",
       "602                      0                     0                     0   \n",
       "179                      0                     0                     0   \n",
       "143                      0                     0                     0   \n",
       "18                       0                     0                     0   \n",
       "\n",
       "      postal district_18.0  postal district_19.0  postal district_20.0  \\\n",
       "203                      0                     0                     0   \n",
       "645                      0                     0                     0   \n",
       "1344                     0                     0                     0   \n",
       "1431                     0                     0                     0   \n",
       "1486                     0                     0                     0   \n",
       "602                      0                     0                     0   \n",
       "179                      0                     0                     0   \n",
       "143                      0                     0                     0   \n",
       "18                       0                     0                     0   \n",
       "\n",
       "      postal district_21.0  postal district_22.0  postal district_23.0  \\\n",
       "203                      0                     0                     0   \n",
       "645                      0                     0                     0   \n",
       "1344                     0                     0                     0   \n",
       "1431                     0                     0                     0   \n",
       "1486                     0                     0                     0   \n",
       "602                      0                     0                     0   \n",
       "179                      0                     0                     0   \n",
       "143                      0                     0                     0   \n",
       "18                       0                     0                     0   \n",
       "\n",
       "      postal district_25.0  postal district_26.0  postal district_27.0  \\\n",
       "203                      0                     0                     0   \n",
       "645                      0                     0                     0   \n",
       "1344                     0                     0                     0   \n",
       "1431                     0                     0                     0   \n",
       "1486                     0                     0                     0   \n",
       "602                      0                     0                     0   \n",
       "179                      0                     0                     0   \n",
       "143                      0                     0                     0   \n",
       "18                       0                     0                     0   \n",
       "\n",
       "      postal district_28.0  type_Detached  type_Semi-detached  type_Terrace  \n",
       "203                      0              1                   0             0  \n",
       "645                      0              1                   0             0  \n",
       "1344                     0              1                   0             0  \n",
       "1431                     0              1                   0             0  \n",
       "1486                     0              1                   0             0  \n",
       "602                      0              1                   0             0  \n",
       "179                      0              1                   0             0  \n",
       "143                      0              1                   0             0  \n",
       "18                       0              1                   0             0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house99.nlargest(9,'price', keep ='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca6c09",
   "metadata": {},
   "source": [
    "### All are inside sentosa area district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb60caef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488, 43)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house99.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "90a48b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_house99 = merged_house99[merged_house99['price'] <= 22800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6291f46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1480, 43)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house99.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "154f5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X99 = merged_house99.drop(columns = ['price','unit price psf','project name','street name','type of sale','nett price', 'type of area', 'floor level','date of sale', 'index'])\n",
    "y99 = merged_house99['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9503030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits.\n",
    "X99_train, X99_test, y99_train, y99_test = train_test_split(X99, y99, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46764ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z99_train = sc.fit_transform(X99_train)\n",
    "Z99_test = sc.transform(X99_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bda72d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99 = XGBRegressor()\n",
    "XGB99.fit(Z99_train, y99_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "12948e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-15 01:58:44,778]\u001b[0m A new study created in memory with name: no-name-12144b7d-fbe3-4639-be18-614a519608f0\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:45,010]\u001b[0m Trial 0 finished with value: -1098484.0505591547 and parameters: {'colsample_bytree': 0.4370861069626263, 'learning_rate': 0.9556428757689246, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 3.6323392569431376e-07, 'reg_alpha': 3.6303224667798554e-07, 'sub_sample': 0.15227525095137953}. Best is trial 0 with value: -1098484.0505591547.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:45,260]\u001b[0m Trial 1 finished with value: -924158.3419787814 and parameters: {'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.6410035105688879, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 50.01479828856935, 'reg_alpha': 2.1106995036049625, 'sub_sample': 0.29110519961044856}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:45,404]\u001b[0m Trial 2 finished with value: -954954.3587256679 and parameters: {'colsample_bytree': 0.26364247048639056, 'learning_rate': 0.2650640588680905, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00020866527711063722, 'reg_alpha': 8.171304639059403e-06, 'sub_sample': 0.6506676052501416}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:45,572]\u001b[0m Trial 3 finished with value: -956640.8823383249 and parameters: {'colsample_bytree': 0.22554447458683766, 'learning_rate': 0.3629301836816964, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.7108199592296855, 'reg_alpha': 9.925166969962287e-07, 'sub_sample': 0.5628109945722505}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:45,833]\u001b[0m Trial 4 finished with value: -948488.9392145074 and parameters: {'colsample_bytree': 0.6331731119758383, 'learning_rate': 0.14180537144799796, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.472145552469491e-08, 'reg_alpha': 30.821613670416532, 'sub_sample': 0.9690688297671034}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:45,974]\u001b[0m Trial 5 finished with value: -991511.1150861108 and parameters: {'colsample_bytree': 0.827557613304815, 'learning_rate': 0.3741523922560336, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.0002520721916536751, 'reg_alpha': 1.661048634233462e-07, 'sub_sample': 0.5456592191001431}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:46,122]\u001b[0m Trial 6 finished with value: -962059.0766549032 and parameters: {'colsample_bytree': 0.13094966900369656, 'learning_rate': 0.9183883618709039, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 1.3095158546031483e-05, 'reg_alpha': 0.0015873774692781828, 'sub_sample': 0.5920392514089517}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:46,338]\u001b[0m Trial 7 finished with value: -977344.9187259458 and parameters: {'colsample_bytree': 0.26636900997297436, 'learning_rate': 0.9726261649881027, 'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 8.8771488946556, 'reg_alpha': 0.00952795699161383, 'sub_sample': 0.9296868115208051}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:46,471]\u001b[0m Trial 8 finished with value: -1026325.9505076378 and parameters: {'colsample_bytree': 0.17964325184672755, 'learning_rate': 0.27638457617723067, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 7.705004503489671e-05, 'reg_alpha': 5.169997317292732e-06, 'sub_sample': 0.8458637582367364}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:46,672]\u001b[0m Trial 9 finished with value: -991256.9132551795 and parameters: {'colsample_bytree': 0.4210779940242304, 'learning_rate': 0.3528410587186427, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.0518887432316704, 'reg_alpha': 5.5655288302015325e-08, 'sub_sample': 0.9881982429404655}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:46,989]\u001b[0m Trial 10 finished with value: -1043743.5087551653 and parameters: {'colsample_bytree': 0.9809605894384237, 'learning_rate': 0.689800474550518, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.033011518943798196, 'reg_alpha': 11.930206277066471, 'sub_sample': 0.1727988637364622}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:47,306]\u001b[0m Trial 11 finished with value: -1099367.7972287221 and parameters: {'colsample_bytree': 0.7222892420658802, 'learning_rate': 0.6058740016871174, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.486118655157855e-08, 'reg_alpha': 51.13114449101003, 'sub_sample': 0.329250313424009}. Best is trial 1 with value: -924158.3419787814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:47,603]\u001b[0m Trial 12 finished with value: -914367.6667497614 and parameters: {'colsample_bytree': 0.6713076604878692, 'learning_rate': 0.11800464503015419, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.018608355742118065, 'reg_alpha': 0.4373143115015793, 'sub_sample': 0.3878537137930324}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:47,842]\u001b[0m Trial 13 finished with value: -946101.1817451154 and parameters: {'colsample_bytree': 0.8914501200222769, 'learning_rate': 0.7233870118234297, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 63.1410397141249, 'reg_alpha': 0.24822752533209536, 'sub_sample': 0.4085193594396847}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:48,107]\u001b[0m Trial 14 finished with value: -986230.7281817853 and parameters: {'colsample_bytree': 0.7126061435135371, 'learning_rate': 0.5108890209858664, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.015548151869782175, 'reg_alpha': 0.2244052725401182, 'sub_sample': 0.32290967232911094}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:48,389]\u001b[0m Trial 15 finished with value: -1080226.7148362095 and parameters: {'colsample_bytree': 0.5152643555381988, 'learning_rate': 0.7880873908361923, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.01607125576028399, 'reg_alpha': 0.5985715004028072, 'sub_sample': 0.389835417985338}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:48,629]\u001b[0m Trial 16 finished with value: -927866.4555996836 and parameters: {'colsample_bytree': 0.8039833872502669, 'learning_rate': 0.5260950582681524, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 95.28742451526429, 'reg_alpha': 0.016755538766832744, 'sub_sample': 0.23658748041676775}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:48,902]\u001b[0m Trial 17 finished with value: -960598.230915759 and parameters: {'colsample_bytree': 0.9386435761194064, 'learning_rate': 0.16246500609320325, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.28275954378438134, 'reg_alpha': 2.081380388674383, 'sub_sample': 0.4723253042396589}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:49,181]\u001b[0m Trial 18 finished with value: -1079359.8951393722 and parameters: {'colsample_bytree': 0.5982374599540455, 'learning_rate': 0.8191348195119579, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.0019317410862543097, 'reg_alpha': 7.721327045288563e-05, 'sub_sample': 0.699882075376947}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:49,440]\u001b[0m Trial 19 finished with value: -986335.6713821923 and parameters: {'colsample_bytree': 0.7172057341024688, 'learning_rate': 0.47828279325510925, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 5.557454190648966e-06, 'reg_alpha': 0.03236594754124655, 'sub_sample': 0.25783471020804505}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:49,692]\u001b[0m Trial 20 finished with value: -984730.876320732 and parameters: {'colsample_bytree': 0.8487827615539751, 'learning_rate': 0.6305837049043285, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 6.4084217131119745, 'reg_alpha': 0.00039798077073657784, 'sub_sample': 0.11885115343501795}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:49,924]\u001b[0m Trial 21 finished with value: -934277.4162076578 and parameters: {'colsample_bytree': 0.7824599775968901, 'learning_rate': 0.46327130460836474, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 75.51741867645897, 'reg_alpha': 0.02330508134060591, 'sub_sample': 0.2297198516295625}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:50,156]\u001b[0m Trial 22 finished with value: -1023789.2786409463 and parameters: {'colsample_bytree': 0.7846496480653243, 'learning_rate': 0.6150654401210985, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 7.938115213977341, 'reg_alpha': 2.195259727564039, 'sub_sample': 0.27382207112019297}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:50,422]\u001b[0m Trial 23 finished with value: -1113687.2988589103 and parameters: {'colsample_bytree': 0.9956034925459666, 'learning_rate': 0.8410194829602005, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.16561914756977456, 'reg_alpha': 0.003574790071424028, 'sub_sample': 0.4262445096202383}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:50,626]\u001b[0m Trial 24 finished with value: -982032.5558463788 and parameters: {'colsample_bytree': 0.6332891970114468, 'learning_rate': 0.10076832745564723, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 79.94607407200775, 'reg_alpha': 0.10066496166800648, 'sub_sample': 0.33983111341512834}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:50,863]\u001b[0m Trial 25 finished with value: -939869.2200109204 and parameters: {'colsample_bytree': 0.9098807888338065, 'learning_rate': 0.22969722411299306, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 2.335929739393319, 'reg_alpha': 2.84977486902548, 'sub_sample': 0.19114192210143693}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:51,125]\u001b[0m Trial 26 finished with value: -1065524.3586720184 and parameters: {'colsample_bytree': 0.5577311299694001, 'learning_rate': 0.4390334226412081, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0028165021315292196, 'reg_alpha': 0.00024492883751890877, 'sub_sample': 0.26907298045684214}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:51,420]\u001b[0m Trial 27 finished with value: -984744.743348248 and parameters: {'colsample_bytree': 0.6923381821715094, 'learning_rate': 0.5412596956578645, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 15.224818867095378, 'reg_alpha': 0.03326524069692381, 'sub_sample': 0.4909313643969732}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:51,700]\u001b[0m Trial 28 finished with value: -1033264.4478176497 and parameters: {'colsample_bytree': 0.7925551571348401, 'learning_rate': 0.756360984948035, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.05887596013453913, 'reg_alpha': 0.7319406572157423, 'sub_sample': 0.38728912319043146}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:51,917]\u001b[0m Trial 29 finished with value: -1065865.1826725914 and parameters: {'colsample_bytree': 0.4509330744884281, 'learning_rate': 0.9026705818966841, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 1.6108057222385324e-06, 'reg_alpha': 7.44215595881803, 'sub_sample': 0.13871357255059374}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:52,184]\u001b[0m Trial 30 finished with value: -1009291.2442874543 and parameters: {'colsample_bytree': 0.846269667134785, 'learning_rate': 0.41369376917127837, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 1.5446548008421994, 'reg_alpha': 1.0060536083290441e-08, 'sub_sample': 0.21469257790498247}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:52,412]\u001b[0m Trial 31 finished with value: -950264.9651875031 and parameters: {'colsample_bytree': 0.7744947377288812, 'learning_rate': 0.571202728321005, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 58.20606619782557, 'reg_alpha': 0.016770489907325187, 'sub_sample': 0.22275529814286768}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:52,607]\u001b[0m Trial 32 finished with value: -957204.2789337563 and parameters: {'colsample_bytree': 0.6575158213260057, 'learning_rate': 0.6620718378906957, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 27.786416398104862, 'reg_alpha': 0.06972086385347206, 'sub_sample': 0.10959507399427776}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:52,834]\u001b[0m Trial 33 finished with value: -1029497.6820000085 and parameters: {'colsample_bytree': 0.7599993690805611, 'learning_rate': 0.29068110375708295, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 3.0633706109861034, 'reg_alpha': 0.009661562368373932, 'sub_sample': 0.32803636870962843}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:53,031]\u001b[0m Trial 34 finished with value: -976597.3563431788 and parameters: {'colsample_bytree': 0.8865997723435186, 'learning_rate': 0.47831991310476485, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.4372843644702609, 'reg_alpha': 0.3885980726333832, 'sub_sample': 0.26067411461932644}. Best is trial 12 with value: -914367.6667497614.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:53,261]\u001b[0m Trial 35 finished with value: -911162.8352284315 and parameters: {'colsample_bytree': 0.8268908632293872, 'learning_rate': 0.2117559133878516, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 98.0815348698472, 'reg_alpha': 0.002836509427246045, 'sub_sample': 0.4622464764170875}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:53,603]\u001b[0m Trial 36 finished with value: -915983.5113806024 and parameters: {'colsample_bytree': 0.9371610112214227, 'learning_rate': 0.19877811174943294, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 13.976076080716531, 'reg_alpha': 5.242077448885869e-05, 'sub_sample': 0.502059621650843}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:53,937]\u001b[0m Trial 37 finished with value: -934885.6941583297 and parameters: {'colsample_bytree': 0.9464145455784424, 'learning_rate': 0.20616516710088337, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 21.874349444470756, 'reg_alpha': 0.00011192080455036745, 'sub_sample': 0.6661847000124463}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:54,237]\u001b[0m Trial 38 finished with value: -947746.1285600646 and parameters: {'colsample_bytree': 0.8669334301306336, 'learning_rate': 0.10195076439353645, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.00025258023548654126, 'reg_alpha': 2.004403451447112e-05, 'sub_sample': 0.5162416277559062}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:54,632]\u001b[0m Trial 39 finished with value: -1042010.0240956486 and parameters: {'colsample_bytree': 0.9399393280362799, 'learning_rate': 0.3330939530832995, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.08183115703805069, 'reg_alpha': 1.9859152849597666e-06, 'sub_sample': 0.6186716231012142}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:54,915]\u001b[0m Trial 40 finished with value: -969332.8960662582 and parameters: {'colsample_bytree': 0.8210801899707341, 'learning_rate': 0.17542934107395283, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 4.6956310169100535, 'reg_alpha': 1.7052850102034562e-05, 'sub_sample': 0.7640834921677011}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:54] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:55,160]\u001b[0m Trial 41 finished with value: -921845.2612396644 and parameters: {'colsample_bytree': 0.8199449039407981, 'learning_rate': 0.24242661778069002, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 21.011649518630456, 'reg_alpha': 0.001766917915952859, 'sub_sample': 0.5518740482899985}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:55,403]\u001b[0m Trial 42 finished with value: -913334.8641931602 and parameters: {'colsample_bytree': 0.9121368558520385, 'learning_rate': 0.23663578962379228, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 19.176785324502926, 'reg_alpha': 0.0008763827413375401, 'sub_sample': 0.5623015612221606}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:55,613]\u001b[0m Trial 43 finished with value: -979435.0364901414 and parameters: {'colsample_bytree': 0.9651408217212547, 'learning_rate': 0.21254202572239445, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.7787900071820352, 'reg_alpha': 0.0010855207963416523, 'sub_sample': 0.5615715604439536}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:55,855]\u001b[0m Trial 44 finished with value: -945589.0758934999 and parameters: {'colsample_bytree': 0.9018655140377037, 'learning_rate': 0.26147279170553295, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 11.961727318198783, 'reg_alpha': 0.0017004831710495706, 'sub_sample': 0.46278027341290695}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:56,054]\u001b[0m Trial 45 finished with value: -966680.843859048 and parameters: {'colsample_bytree': 0.7514993228228232, 'learning_rate': 0.31140058725175096, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.3652034300633671e-07, 'reg_alpha': 0.004483281336829803, 'sub_sample': 0.5951849281691342}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:55] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:56,271]\u001b[0m Trial 46 finished with value: -931284.2754776112 and parameters: {'colsample_bytree': 0.3490993918261719, 'learning_rate': 0.13597577064238192, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 29.02158597623125, 'reg_alpha': 4.903882818945692e-05, 'sub_sample': 0.43752376987388863}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:56,502]\u001b[0m Trial 47 finished with value: -992593.7952755857 and parameters: {'colsample_bytree': 0.6786870058862076, 'learning_rate': 0.26455846796698673, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.8762753581873115, 'reg_alpha': 2.7383234178666543e-06, 'sub_sample': 0.5143938937269483}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:56,737]\u001b[0m Trial 48 finished with value: -962231.9877710093 and parameters: {'colsample_bytree': 0.8354235448926206, 'learning_rate': 0.3845490732469832, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.0054851543652616516, 'reg_alpha': 0.00020202352364833475, 'sub_sample': 0.539500119462605}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:56,939]\u001b[0m Trial 49 finished with value: -967165.1941380311 and parameters: {'colsample_bytree': 0.9216485423305388, 'learning_rate': 0.18757746466266356, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.492153701758494e-05, 'reg_alpha': 4.825842453196849e-07, 'sub_sample': 0.7447960484661658}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:57,222]\u001b[0m Trial 50 finished with value: -927987.3350901575 and parameters: {'colsample_bytree': 0.9940177056340573, 'learning_rate': 0.2342767529140805, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 25.585716771259158, 'reg_alpha': 0.0005720062072032715, 'sub_sample': 0.3699382810826633}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:57,504]\u001b[0m Trial 51 finished with value: -943219.8180481488 and parameters: {'colsample_bytree': 0.8784119476249336, 'learning_rate': 0.1410999530914779, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 8.909069135541449, 'reg_alpha': 0.0032294366309486094, 'sub_sample': 0.6106634115268262}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:57,684]\u001b[0m Trial 52 finished with value: -1019830.1387900267 and parameters: {'colsample_bytree': 0.7398144997054477, 'learning_rate': 0.15892331758788547, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.132540576983525, 'reg_alpha': 20.49173241185145, 'sub_sample': 0.4736317771138692}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:57,928]\u001b[0m Trial 53 finished with value: -928800.9701064888 and parameters: {'colsample_bytree': 0.8602594541650576, 'learning_rate': 0.2496772172142125, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 30.926532383464206, 'reg_alpha': 0.001051005462757013, 'sub_sample': 0.64361235988502}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:58,222]\u001b[0m Trial 54 finished with value: -989344.9635384486 and parameters: {'colsample_bytree': 0.8172133900499279, 'learning_rate': 0.30430693156466787, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.6792877087884721, 'reg_alpha': 3.948454996708873e-05, 'sub_sample': 0.5517471180490693}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:58,492]\u001b[0m Trial 55 finished with value: -981120.2807801082 and parameters: {'colsample_bytree': 0.9558691934091645, 'learning_rate': 0.347834983506737, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.19237045619035295, 'reg_alpha': 7.357358741058141, 'sub_sample': 0.4503502757779218}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:58,875]\u001b[0m Trial 56 finished with value: -981694.5178225699 and parameters: {'colsample_bytree': 0.9218497480004783, 'learning_rate': 0.1867862812311561, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0005711408223248514, 'reg_alpha': 0.10615700510847746, 'sub_sample': 0.5034675794791772}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:59,157]\u001b[0m Trial 57 finished with value: -943402.8948642928 and parameters: {'colsample_bytree': 0.5800703272676132, 'learning_rate': 0.1267657214591962, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 89.81128795526816, 'reg_alpha': 72.14264638014433, 'sub_sample': 0.30502210369725824}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:59,432]\u001b[0m Trial 58 finished with value: -996402.5317637894 and parameters: {'colsample_bytree': 0.4978298875936215, 'learning_rate': 0.6964030037868143, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 7.700427250369708, 'reg_alpha': 6.852176475057332e-06, 'sub_sample': 0.35902741515515346}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:59,673]\u001b[0m Trial 59 finished with value: -918390.5903518739 and parameters: {'colsample_bytree': 0.6322349550567232, 'learning_rate': 0.21413361522318372, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 43.98379837633334, 'reg_alpha': 0.00014582985576265864, 'sub_sample': 0.5794278938927636}. Best is trial 35 with value: -911162.8352284315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:58:59,926]\u001b[0m Trial 60 finished with value: -901810.3294681909 and parameters: {'colsample_bytree': 0.6299908367921646, 'learning_rate': 0.20897137537337293, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 38.994561062820395, 'reg_alpha': 0.0006011267645073205, 'sub_sample': 0.5750074717240843}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:58:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:00,183]\u001b[0m Trial 61 finished with value: -917839.8757903345 and parameters: {'colsample_bytree': 0.6139314838927287, 'learning_rate': 0.2041562716762386, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 43.30275284083306, 'reg_alpha': 0.0005009285610956004, 'sub_sample': 0.5819207482943685}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:00,427]\u001b[0m Trial 62 finished with value: -934924.2933907292 and parameters: {'colsample_bytree': 0.607098283892293, 'learning_rate': 0.20716542698821674, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 47.78809911982102, 'reg_alpha': 0.00018206234012784153, 'sub_sample': 0.7088396163078391}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:00,674]\u001b[0m Trial 63 finished with value: -952523.9616123463 and parameters: {'colsample_bytree': 0.6228372413171748, 'learning_rate': 0.15144821704786068, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 10.690630556548356, 'reg_alpha': 0.0003354505248094793, 'sub_sample': 0.5737402561702054}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:00,914]\u001b[0m Trial 64 finished with value: -915877.0807387166 and parameters: {'colsample_bytree': 0.5322804682633729, 'learning_rate': 0.28050116989346063, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 49.87454093551001, 'reg_alpha': 7.337407797653706e-05, 'sub_sample': 0.6631363880912244}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:01,163]\u001b[0m Trial 65 finished with value: -935822.4381231838 and parameters: {'colsample_bytree': 0.5396660345442239, 'learning_rate': 0.2899530416938609, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 1.3151022637343992, 'reg_alpha': 0.0004935857843285482, 'sub_sample': 0.6451430082687712}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:01,402]\u001b[0m Trial 66 finished with value: -1030841.0472927352 and parameters: {'colsample_bytree': 0.4885519435028638, 'learning_rate': 0.10203174100867198, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 97.84153024683457, 'reg_alpha': 2.5906104373507598e-05, 'sub_sample': 0.4067833200153236}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:01,629]\u001b[0m Trial 67 finished with value: -967655.6087470971 and parameters: {'colsample_bytree': 0.4445497200125995, 'learning_rate': 0.17370346619701815, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 3.5437759645473337, 'reg_alpha': 9.413216947763886e-05, 'sub_sample': 0.6797252820547803}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:01,827]\u001b[0m Trial 68 finished with value: -957799.0682433721 and parameters: {'colsample_bytree': 0.5784956412817294, 'learning_rate': 0.27502414495876426, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 14.947600111142584, 'reg_alpha': 0.0033694585782964893, 'sub_sample': 0.8170114502803442}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:02,042]\u001b[0m Trial 69 finished with value: -917888.5402887989 and parameters: {'colsample_bytree': 0.38933498227002505, 'learning_rate': 0.3302432672737415, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 36.57855654508019, 'reg_alpha': 0.00678867378274127, 'sub_sample': 0.5287072243113583}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:02,265]\u001b[0m Trial 70 finished with value: -986339.5855958553 and parameters: {'colsample_bytree': 0.6808452475484694, 'learning_rate': 0.4053891793607771, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.015149808000391497, 'reg_alpha': 6.614602667476887e-05, 'sub_sample': 0.6214007117363826}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:02,464]\u001b[0m Trial 71 finished with value: -961151.7072090181 and parameters: {'colsample_bytree': 0.168175649058875, 'learning_rate': 0.3244681683466599, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 49.25550532975574, 'reg_alpha': 0.008879191486334618, 'sub_sample': 0.4978137450932295}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:02,672]\u001b[0m Trial 72 finished with value: -918115.3309357035 and parameters: {'colsample_bytree': 0.37971085041746666, 'learning_rate': 0.22586882855868312, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 5.769354018061824, 'reg_alpha': 0.0005011263433629667, 'sub_sample': 0.5209786758927878}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:02,910]\u001b[0m Trial 73 finished with value: -926210.9305161216 and parameters: {'colsample_bytree': 0.3387579949884661, 'learning_rate': 0.18842282655614337, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 15.338462863793316, 'reg_alpha': 1.2575556870618276e-05, 'sub_sample': 0.4274400162428629}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:03,101]\u001b[0m Trial 74 finished with value: -993598.3066931821 and parameters: {'colsample_bytree': 0.2344310773280975, 'learning_rate': 0.12759209942065836, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 39.65944956439016, 'reg_alpha': 0.000884213621205392, 'sub_sample': 0.5336816510425925}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:03,316]\u001b[0m Trial 75 finished with value: -932136.689648776 and parameters: {'colsample_bytree': 0.655833948364682, 'learning_rate': 0.26091043261664904, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 2.1398170470092306, 'reg_alpha': 0.004816065191027733, 'sub_sample': 0.47464485373387444}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:03,530]\u001b[0m Trial 76 finished with value: -940689.043958859 and parameters: {'colsample_bytree': 0.4697905423784805, 'learning_rate': 0.36198908928586854, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 90.49652559114882, 'reg_alpha': 0.009790062744075723, 'sub_sample': 0.589925422112728}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:03,793]\u001b[0m Trial 77 finished with value: -919644.7946869229 and parameters: {'colsample_bytree': 0.5329235204685352, 'learning_rate': 0.289402090545381, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 18.302283553145685, 'reg_alpha': 0.06200312368111382, 'sub_sample': 0.632745515840602}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:04,022]\u001b[0m Trial 78 finished with value: -981106.3877181835 and parameters: {'colsample_bytree': 0.7144245746444207, 'learning_rate': 0.1999058723766085, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 5.932626774527355, 'reg_alpha': 0.0018612737192991646, 'sub_sample': 0.6998388693408049}. Best is trial 60 with value: -901810.3294681909.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:04,240]\u001b[0m Trial 79 finished with value: -879016.3396119183 and parameters: {'colsample_bytree': 0.275066248143753, 'learning_rate': 0.23587876349283188, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.48320402574489874, 'reg_alpha': 0.00026849046767792403, 'sub_sample': 0.40913253052239884}. Best is trial 79 with value: -879016.3396119183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:04,487]\u001b[0m Trial 80 finished with value: -890787.3873662994 and parameters: {'colsample_bytree': 0.2782067876562684, 'learning_rate': 0.23904519775144914, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.40794625578718385, 'reg_alpha': 3.656577131675817e-05, 'sub_sample': 0.3755078072373207}. Best is trial 79 with value: -879016.3396119183.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:04,725]\u001b[0m Trial 81 finished with value: -886645.6294068658 and parameters: {'colsample_bytree': 0.2926401520207324, 'learning_rate': 0.23460653708590593, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.046509649208471913, 'reg_alpha': 0.0002687850182592797, 'sub_sample': 0.39176794268883136}. Best is trial 79 with value: -879016.3396119183.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:04,970]\u001b[0m Trial 82 finished with value: -881386.7954129764 and parameters: {'colsample_bytree': 0.2774697698010014, 'learning_rate': 0.23766223167155173, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.08306674086340082, 'reg_alpha': 4.204313493664433e-05, 'sub_sample': 0.3955942793972178}. Best is trial 79 with value: -879016.3396119183.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:05,211]\u001b[0m Trial 83 finished with value: -890129.3407876921 and parameters: {'colsample_bytree': 0.2643915637123719, 'learning_rate': 0.24086524439692392, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.08531893754482499, 'reg_alpha': 0.0002730494416582137, 'sub_sample': 0.3958086122949374}. Best is trial 79 with value: -879016.3396119183.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:05,453]\u001b[0m Trial 84 finished with value: -884259.223851489 and parameters: {'colsample_bytree': 0.27654801652274313, 'learning_rate': 0.24184631986004002, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.039280849815250526, 'reg_alpha': 2.8911934082083374e-05, 'sub_sample': 0.3971403237302428}. Best is trial 79 with value: -879016.3396119183.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:05,698]\u001b[0m Trial 85 finished with value: -892892.7057253111 and parameters: {'colsample_bytree': 0.28636448090542804, 'learning_rate': 0.23936251320992757, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0611975317726514, 'reg_alpha': 3.2452042122598755e-06, 'sub_sample': 0.40077227665157883}. Best is trial 79 with value: -879016.3396119183.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:05,942]\u001b[0m Trial 86 finished with value: -876406.7347119894 and parameters: {'colsample_bytree': 0.2979025529615903, 'learning_rate': 0.24442692853667908, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.06893180760859688, 'reg_alpha': 1.309235835720095e-06, 'sub_sample': 0.35230473361439624}. Best is trial 86 with value: -876406.7347119894.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:06,185]\u001b[0m Trial 87 finished with value: -871827.7874990578 and parameters: {'colsample_bytree': 0.28557842794775784, 'learning_rate': 0.24902969279248097, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.07671384071966524, 'reg_alpha': 3.0148625125011162e-06, 'sub_sample': 0.34530849302799593}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:06,433]\u001b[0m Trial 88 finished with value: -902441.0878900718 and parameters: {'colsample_bytree': 0.3015909816581936, 'learning_rate': 0.30568354039972034, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0714608514699173, 'reg_alpha': 7.304032039728822e-07, 'sub_sample': 0.3005991226085471}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:06,673]\u001b[0m Trial 89 finished with value: -898513.4227095593 and parameters: {'colsample_bytree': 0.27019019942500555, 'learning_rate': 0.24869195430540397, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.033828452649118594, 'reg_alpha': 1.335750026729025e-07, 'sub_sample': 0.37000687711456465}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:06,916]\u001b[0m Trial 90 finished with value: -910552.4558845019 and parameters: {'colsample_bytree': 0.21087379284320867, 'learning_rate': 0.16213832409983764, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.1369456462890633, 'reg_alpha': 3.812387655532911e-06, 'sub_sample': 0.34610278994875127}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:07,165]\u001b[0m Trial 91 finished with value: -881166.378193334 and parameters: {'colsample_bytree': 0.2947924496596675, 'learning_rate': 0.25220469100698, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.025241722136717208, 'reg_alpha': 2.7682917489823036e-07, 'sub_sample': 0.4001673331605504}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:07,413]\u001b[0m Trial 92 finished with value: -874523.7188887784 and parameters: {'colsample_bytree': 0.28244051057720193, 'learning_rate': 0.2507481566177782, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.3343625281961696, 'reg_alpha': 1.4911593672784071e-06, 'sub_sample': 0.41070883965025234}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:07,657]\u001b[0m Trial 93 finished with value: -872571.1813873225 and parameters: {'colsample_bytree': 0.3149526617916648, 'learning_rate': 0.2670183058619238, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.32631555129710543, 'reg_alpha': 1.3231551149046216e-06, 'sub_sample': 0.3823433672316678}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:07,895]\u001b[0m Trial 94 finished with value: -872126.8199124262 and parameters: {'colsample_bytree': 0.24736251655076424, 'learning_rate': 0.26048887384149366, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.008933106424790367, 'reg_alpha': 1.4828559094039658e-06, 'sub_sample': 0.3175164476222909}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:08,142]\u001b[0m Trial 95 finished with value: -929617.072209452 and parameters: {'colsample_bytree': 0.32271803933589266, 'learning_rate': 0.27095755818857425, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.007481640639625029, 'reg_alpha': 1.652003585691925e-06, 'sub_sample': 0.318423917865348}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:08,377]\u001b[0m Trial 96 finished with value: -890241.9792797741 and parameters: {'colsample_bytree': 0.23640341901595827, 'learning_rate': 0.38118290449711123, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.02058204335696662, 'reg_alpha': 2.611994974939474e-07, 'sub_sample': 0.2749896825514075}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:08,623]\u001b[0m Trial 97 finished with value: -914438.9970840085 and parameters: {'colsample_bytree': 0.20370881338514996, 'learning_rate': 0.31532056821534904, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.030962286952422778, 'reg_alpha': 2.7686139945380244e-08, 'sub_sample': 0.3502353814479521}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:08,865]\u001b[0m Trial 98 finished with value: -874631.3227231608 and parameters: {'colsample_bytree': 0.2485799755783619, 'learning_rate': 0.35310785675940815, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.2786613202502033, 'reg_alpha': 1.0803159282294947e-06, 'sub_sample': 0.4190647855134578}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[01:59:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 01:59:09,079]\u001b[0m Trial 99 finished with value: -994543.7684449728 and parameters: {'colsample_bytree': 0.13082791809936467, 'learning_rate': 0.2975527693868725, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 0.22133028225044477, 'reg_alpha': 1.25314960962669e-06, 'sub_sample': 0.4262452816624676}. Best is trial 87 with value: -871827.7874990578.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def xgb99(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300, 500)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, Z99_train, y99_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb99, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2f3f444b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.28557842794775784,\n",
       " 'learning_rate': 0.24902969279248097,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 100,\n",
       " 'reg_lambda': 0.07671384071966524,\n",
       " 'reg_alpha': 3.0148625125011162e-06,\n",
       " 'sub_sample': 0.34530849302799593}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5d36e115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-871827.7874990578"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ac8f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:00:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.28557842794775784,\n",
       "             enable_categorical=False, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.24902969279248097,\n",
       "             max_delta_step=0, max_depth=4, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=3.0148625125011162e-06, reg_lambda=0.07671384071966524,\n",
       "             scale_pos_weight=1, sub_sample=0.34530849302799593, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99 = XGBRegressor(colsample_bytree=  0.28557842794775784, learning_rate= 0.24902969279248097, max_depth= 4 , min_child_weight= 1, n_estimators= 100,\n",
    "reg_alpha= 3.0148625125011162e-06, reg_lambda= 0.07671384071966524, sub_sample=  0.34530849302799593)\n",
    "XGB99.fit(Z99_train, y99_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ee132c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911149482046929"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99.score(Z99_train, y99_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6bf0415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882152762868764"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB99.score(Z99_test, y99_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "957c1127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='tenure', ylabel='price'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(y = merged_house99['price'], x = merged_house99['tenure'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3985625",
   "metadata": {},
   "source": [
    "What is the cause of the extra overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2579e",
   "metadata": {},
   "source": [
    "## Modelling for 999 years (tenure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4e115d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>project name</th>\n",
       "      <th>street name</th>\n",
       "      <th>tenure</th>\n",
       "      <th>type of sale</th>\n",
       "      <th>no. of units</th>\n",
       "      <th>price</th>\n",
       "      <th>nett price</th>\n",
       "      <th>areasq</th>\n",
       "      <th>type of area</th>\n",
       "      <th>floor level</th>\n",
       "      <th>unit price psf</th>\n",
       "      <th>date of sale</th>\n",
       "      <th>market segment_CCR</th>\n",
       "      <th>market segment_OCR</th>\n",
       "      <th>market segment_RCR</th>\n",
       "      <th>postal district_2.0</th>\n",
       "      <th>postal district_3.0</th>\n",
       "      <th>postal district_4.0</th>\n",
       "      <th>postal district_5.0</th>\n",
       "      <th>postal district_8.0</th>\n",
       "      <th>postal district_9.0</th>\n",
       "      <th>postal district_10.0</th>\n",
       "      <th>postal district_11.0</th>\n",
       "      <th>postal district_12.0</th>\n",
       "      <th>postal district_13.0</th>\n",
       "      <th>postal district_14.0</th>\n",
       "      <th>postal district_15.0</th>\n",
       "      <th>postal district_16.0</th>\n",
       "      <th>postal district_17.0</th>\n",
       "      <th>postal district_18.0</th>\n",
       "      <th>postal district_19.0</th>\n",
       "      <th>postal district_20.0</th>\n",
       "      <th>postal district_21.0</th>\n",
       "      <th>postal district_22.0</th>\n",
       "      <th>postal district_23.0</th>\n",
       "      <th>postal district_25.0</th>\n",
       "      <th>postal district_26.0</th>\n",
       "      <th>postal district_27.0</th>\n",
       "      <th>postal district_28.0</th>\n",
       "      <th>type_Detached</th>\n",
       "      <th>type_Semi-detached</th>\n",
       "      <th>type_Terrace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>DUBLIN ROAD</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5128000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2981.0</td>\n",
       "      <td>Jul-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>JALAN JINTAN</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4908000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2974.0</td>\n",
       "      <td>Jan-2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MACPHERSON GARDEN ESTATE</td>\n",
       "      <td>JALAN KEMAJUAN</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2680000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>903.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>Oct-2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EMERALD HILL CONSERVATION AREA</td>\n",
       "      <td>EMERALD HILL ROAD</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8300000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>2799.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>Sep-2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LANDED HOUSING DEVELOPMENT</td>\n",
       "      <td>NAMLY RISE</td>\n",
       "      <td>999</td>\n",
       "      <td>Resale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9500000.0</td>\n",
       "      <td>-</td>\n",
       "      <td>3209.0</td>\n",
       "      <td>Land</td>\n",
       "      <td>-</td>\n",
       "      <td>2961.0</td>\n",
       "      <td>Aug-2021</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    project name        street name  tenure  \\\n",
       "0      0      LANDED HOUSING DEVELOPMENT        DUBLIN ROAD     999   \n",
       "1      1      LANDED HOUSING DEVELOPMENT       JALAN JINTAN     999   \n",
       "2      2        MACPHERSON GARDEN ESTATE     JALAN KEMAJUAN     999   \n",
       "3      3  EMERALD HILL CONSERVATION AREA  EMERALD HILL ROAD     999   \n",
       "4      4      LANDED HOUSING DEVELOPMENT         NAMLY RISE     999   \n",
       "\n",
       "  type of sale  no. of units      price nett price  areasq type of area  \\\n",
       "0       Resale           1.0  5128000.0          -  1720.0         Land   \n",
       "1       Resale           1.0  4908000.0          -  1650.0         Land   \n",
       "2       Resale           1.0  2680000.0          -   903.0         Land   \n",
       "3       Resale           1.0  8300000.0          -  2799.0         Land   \n",
       "4       Resale           1.0  9500000.0          -  3209.0         Land   \n",
       "\n",
       "  floor level  unit price psf date of sale  market segment_CCR  \\\n",
       "0           -          2981.0     Jul-2021                   1   \n",
       "1           -          2974.0     Jan-2018                   1   \n",
       "2           -          2968.0     Oct-2021                   0   \n",
       "3           -          2966.0     Sep-2020                   1   \n",
       "4           -          2961.0     Aug-2021                   1   \n",
       "\n",
       "   market segment_OCR  market segment_RCR  postal district_2.0  \\\n",
       "0                   0                   0                    0   \n",
       "1                   0                   0                    0   \n",
       "2                   0                   1                    0   \n",
       "3                   0                   0                    0   \n",
       "4                   0                   0                    0   \n",
       "\n",
       "   postal district_3.0  postal district_4.0  postal district_5.0  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   postal district_8.0  postal district_9.0  postal district_10.0  \\\n",
       "0                    0                    1                     0   \n",
       "1                    0                    1                     0   \n",
       "2                    0                    0                     0   \n",
       "3                    0                    1                     0   \n",
       "4                    0                    0                     1   \n",
       "\n",
       "   postal district_11.0  postal district_12.0  postal district_13.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_14.0  postal district_15.0  postal district_16.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_17.0  postal district_18.0  postal district_19.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_20.0  postal district_21.0  postal district_22.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_23.0  postal district_25.0  postal district_26.0  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   postal district_27.0  postal district_28.0  type_Detached  \\\n",
       "0                     0                     0              0   \n",
       "1                     0                     0              0   \n",
       "2                     0                     0              0   \n",
       "3                     0                     0              0   \n",
       "4                     0                     0              0   \n",
       "\n",
       "   type_Semi-detached  type_Terrace  \n",
       "0                   0             1  \n",
       "1                   0             1  \n",
       "2                   0             1  \n",
       "3                   0             1  \n",
       "4                   1             0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_house999.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "73aa80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X999 = merged_house999.drop(columns = ['price','unit price psf','project name','street name','type of sale','nett price', 'type of area', 'floor level','date of sale', 'index'])\n",
    "y999 = merged_house999['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3304ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits.\n",
    "X999_train, X999_test, y999_train, y999_test = train_test_split(X999, y999, test_size =0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f885f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z999_train = sc.fit_transform(X999_train)\n",
    "Z999_test = sc.transform(X999_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c2facf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB999 = XGBRegressor()\n",
    "XGB999.fit(Z999_train, y999_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "317b010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-15 02:13:56,010]\u001b[0m A new study created in memory with name: no-name-31d841e0-1c5a-4fef-b6ff-b68bbf4be977\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:56,488]\u001b[0m Trial 0 finished with value: -2018657.6468467503 and parameters: {'colsample_bytree': 0.4370861069626263, 'learning_rate': 0.9556428757689246, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 3.6323392569431376e-07, 'reg_alpha': 3.6303224667798554e-07, 'sub_sample': 0.15227525095137953}. Best is trial 0 with value: -2018657.6468467503.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:57,072]\u001b[0m Trial 1 finished with value: -1724676.0533535199 and parameters: {'colsample_bytree': 0.8795585311974417, 'learning_rate': 0.6410035105688879, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 50.01479828856935, 'reg_alpha': 2.1106995036049625, 'sub_sample': 0.29110519961044856}. Best is trial 1 with value: -1724676.0533535199.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:56] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:57,377]\u001b[0m Trial 2 finished with value: -1785229.7762240716 and parameters: {'colsample_bytree': 0.26364247048639056, 'learning_rate': 0.2650640588680905, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.00020866527711063722, 'reg_alpha': 8.171304639059403e-06, 'sub_sample': 0.6506676052501416}. Best is trial 1 with value: -1724676.0533535199.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:57,668]\u001b[0m Trial 3 finished with value: -1769926.09410635 and parameters: {'colsample_bytree': 0.22554447458683766, 'learning_rate': 0.3629301836816964, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 0.7108199592296855, 'reg_alpha': 9.925166969962287e-07, 'sub_sample': 0.5628109945722505}. Best is trial 1 with value: -1724676.0533535199.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:57] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:58,224]\u001b[0m Trial 4 finished with value: -1679034.5450781987 and parameters: {'colsample_bytree': 0.6331731119758383, 'learning_rate': 0.14180537144799796, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.472145552469491e-08, 'reg_alpha': 30.821613670416532, 'sub_sample': 0.9690688297671034}. Best is trial 4 with value: -1679034.5450781987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:58,517]\u001b[0m Trial 5 finished with value: -1869715.857104061 and parameters: {'colsample_bytree': 0.827557613304815, 'learning_rate': 0.3741523922560336, 'max_depth': 1, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.0002520721916536751, 'reg_alpha': 1.661048634233462e-07, 'sub_sample': 0.5456592191001431}. Best is trial 4 with value: -1679034.5450781987.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:58,790]\u001b[0m Trial 6 finished with value: -1878551.9174158932 and parameters: {'colsample_bytree': 0.13094966900369656, 'learning_rate': 0.9183883618709039, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 1.3095158546031483e-05, 'reg_alpha': 0.0015873774692781828, 'sub_sample': 0.5920392514089517}. Best is trial 4 with value: -1679034.5450781987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:58] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:59,225]\u001b[0m Trial 7 finished with value: -1780707.8070115203 and parameters: {'colsample_bytree': 0.26636900997297436, 'learning_rate': 0.9726261649881027, 'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 8.8771488946556, 'reg_alpha': 0.00952795699161383, 'sub_sample': 0.9296868115208051}. Best is trial 4 with value: -1679034.5450781987.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:59,440]\u001b[0m Trial 8 finished with value: -1950649.8706441973 and parameters: {'colsample_bytree': 0.17964325184672755, 'learning_rate': 0.27638457617723067, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 7.705004503489671e-05, 'reg_alpha': 5.169997317292732e-06, 'sub_sample': 0.8458637582367364}. Best is trial 4 with value: -1679034.5450781987.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:13:59,870]\u001b[0m Trial 9 finished with value: -1638627.3927869077 and parameters: {'colsample_bytree': 0.4210779940242304, 'learning_rate': 0.3528410587186427, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.0518887432316704, 'reg_alpha': 5.5655288302015325e-08, 'sub_sample': 0.9881982429404655}. Best is trial 9 with value: -1638627.3927869077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:00,503]\u001b[0m Trial 10 finished with value: -1783869.1157250986 and parameters: {'colsample_bytree': 0.5242212935681206, 'learning_rate': 0.6018726732071462, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.0677754527135126, 'reg_alpha': 2.439225769909522e-08, 'sub_sample': 0.7573302056863086}. Best is trial 9 with value: -1638627.3927869077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:00,997]\u001b[0m Trial 11 finished with value: -1636502.979284703 and parameters: {'colsample_bytree': 0.6882339506939761, 'learning_rate': 0.11882097938069741, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.2219504959449609e-08, 'reg_alpha': 17.685525139999093, 'sub_sample': 0.9927551194707116}. Best is trial 11 with value: -1636502.979284703.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:01,483]\u001b[0m Trial 12 finished with value: -1624616.3984269004 and parameters: {'colsample_bytree': 0.7079467078007828, 'learning_rate': 0.1104823894330905, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.020120898049145516, 'reg_alpha': 0.19047082750352795, 'sub_sample': 0.9732449456921393}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:01,954]\u001b[0m Trial 13 finished with value: -1644309.8879639844 and parameters: {'colsample_bytree': 0.720582941008578, 'learning_rate': 0.11692090777841319, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.02913633740936808, 'reg_alpha': 0.16448720288181487, 'sub_sample': 0.7407800219920705}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:01] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:02,465]\u001b[0m Trial 14 finished with value: -1858967.3370947763 and parameters: {'colsample_bytree': 0.9706928351188541, 'learning_rate': 0.5108890209858664, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.006796284328447455, 'reg_alpha': 94.68450853913184, 'sub_sample': 0.3810114423299048}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:02] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:03,150]\u001b[0m Trial 15 finished with value: -1914899.5429065183 and parameters: {'colsample_bytree': 0.7169541473160407, 'learning_rate': 0.7568513465785311, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 1.2714353480628423e-06, 'reg_alpha': 0.2888922794290666, 'sub_sample': 0.8410418713756194}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:03,523]\u001b[0m Trial 16 finished with value: -1640790.2318494085 and parameters: {'colsample_bytree': 0.6029187247389829, 'learning_rate': 0.21012002001291077, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.6113999866204765e-08, 'reg_alpha': 0.8840028010515606, 'sub_sample': 0.880976333108043}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:04,022]\u001b[0m Trial 17 finished with value: -1745001.296397552 and parameters: {'colsample_bytree': 0.7645166283541808, 'learning_rate': 0.464317308265323, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.00641339595618812, 'reg_alpha': 0.016422665881242214, 'sub_sample': 0.727056364269285}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:03] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:04,587]\u001b[0m Trial 18 finished with value: -1716294.922622454 and parameters: {'colsample_bytree': 0.9719243544415159, 'learning_rate': 0.10229527767743353, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 4.319259457272476e-06, 'reg_alpha': 8.122659685498867, 'sub_sample': 0.4225512563114876}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:04,990]\u001b[0m Trial 19 finished with value: -1628739.0750886337 and parameters: {'colsample_bytree': 0.5498524566234004, 'learning_rate': 0.2312492950066269, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0013109662689871795, 'reg_alpha': 0.0002296139848966449, 'sub_sample': 0.8105166807244344}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:05,301]\u001b[0m Trial 20 finished with value: -1859280.924354386 and parameters: {'colsample_bytree': 0.3983601865329254, 'learning_rate': 0.21776542724827963, 'max_depth': 1, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 0.0018719184230731381, 'reg_alpha': 0.00021254755416616881, 'sub_sample': 0.7953956876686308}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:05,772]\u001b[0m Trial 21 finished with value: -1633299.4618609657 and parameters: {'colsample_bytree': 0.5369079822952283, 'learning_rate': 0.18312999474951286, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.10291690895238917, 'reg_alpha': 0.00019510976844393617, 'sub_sample': 0.9140924656968108}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:05] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:06,187]\u001b[0m Trial 22 finished with value: -1644602.0941779218 and parameters: {'colsample_bytree': 0.4886720073997092, 'learning_rate': 0.19338293814189444, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.1734297311839828, 'reg_alpha': 9.83780177484469e-05, 'sub_sample': 0.8981627904455217}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:06,620]\u001b[0m Trial 23 finished with value: -1662177.6247493757 and parameters: {'colsample_bytree': 0.5768757188146206, 'learning_rate': 0.3142869867084609, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.0030623193198114173, 'reg_alpha': 0.00016001874725580918, 'sub_sample': 0.7027437610724594}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:06,969]\u001b[0m Trial 24 finished with value: -1761798.132371284 and parameters: {'colsample_bytree': 0.3418116087425681, 'learning_rate': 0.4433806976489988, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.093996198198962, 'reg_alpha': 0.018970075132836346, 'sub_sample': 0.9102761448762955}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:06] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:07,486]\u001b[0m Trial 25 finished with value: -1671132.1389033806 and parameters: {'colsample_bytree': 0.6521001891491331, 'learning_rate': 0.19510393695376638, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.028125116106009776, 'reg_alpha': 1.853318980340043e-05, 'sub_sample': 0.8074576292521309}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:07,911]\u001b[0m Trial 26 finished with value: -1640821.2888604715 and parameters: {'colsample_bytree': 0.5334851028922165, 'learning_rate': 0.2425614725128479, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0005250870719726612, 'reg_alpha': 0.0019372632267296492, 'sub_sample': 0.6764771200290671}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:07] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:08,604]\u001b[0m Trial 27 finished with value: -1647310.59111983 and parameters: {'colsample_bytree': 0.7954971449966172, 'learning_rate': 0.16751222091689905, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 3.442924267152428e-05, 'reg_alpha': 0.0005284883350865722, 'sub_sample': 0.9288233058170263}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:09,004]\u001b[0m Trial 28 finished with value: -1743315.7492285485 and parameters: {'colsample_bytree': 0.48453765712959884, 'learning_rate': 0.43014478677949125, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.1994697609442185, 'reg_alpha': 0.09919197716956955, 'sub_sample': 0.8170680685901061}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:09,589]\u001b[0m Trial 29 finished with value: -1762035.9985056247 and parameters: {'colsample_bytree': 0.3428216960872717, 'learning_rate': 0.736149635838968, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 19.783587697600165, 'reg_alpha': 3.477920290714283e-05, 'sub_sample': 0.49621958214408757}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:09] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:10,362]\u001b[0m Trial 30 finished with value: -1712815.0449731618 and parameters: {'colsample_bytree': 0.8764010383367093, 'learning_rate': 0.3045823773238735, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 3.984818487536909, 'reg_alpha': 8.845033301804672e-07, 'sub_sample': 0.1198039032668019}. Best is trial 12 with value: -1624616.3984269004.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:11,044]\u001b[0m Trial 31 finished with value: -1619392.0882106135 and parameters: {'colsample_bytree': 0.6783742864662168, 'learning_rate': 0.12064922430073627, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.0105118217449701e-07, 'reg_alpha': 7.4666938044183615, 'sub_sample': 0.997479396374051}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:10] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:11,551]\u001b[0m Trial 32 finished with value: -1647928.8033098262 and parameters: {'colsample_bytree': 0.5769234252469662, 'learning_rate': 0.1706730051947794, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.788430166796479e-07, 'reg_alpha': 2.4777365443521324, 'sub_sample': 0.9972419738146049}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:11] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:12,307]\u001b[0m Trial 33 finished with value: -1639590.1174592385 and parameters: {'colsample_bytree': 0.6485441231867455, 'learning_rate': 0.10643588841719592, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.014286565292286111, 'reg_alpha': 0.004062559935638734, 'sub_sample': 0.22085542431673844}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:12,852]\u001b[0m Trial 34 finished with value: -1637638.3390098147 and parameters: {'colsample_bytree': 0.46937698135930483, 'learning_rate': 0.2535580344676742, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0009364825081614519, 'reg_alpha': 0.0606965548142244, 'sub_sample': 0.9385294533774117}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:12] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:13,352]\u001b[0m Trial 35 finished with value: -1844996.3494684082 and parameters: {'colsample_bytree': 0.7554305030939467, 'learning_rate': 0.3154972086669717, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 83.79506656241432, 'reg_alpha': 2.1649362350155648, 'sub_sample': 0.8689775190551486}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:13] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:14,122]\u001b[0m Trial 36 finished with value: -1695981.161656882 and parameters: {'colsample_bytree': 0.670265014573014, 'learning_rate': 0.15818398079980422, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.14625209676359516, 'reg_alpha': 0.6000986498088101, 'sub_sample': 0.9470512448357994}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:14,708]\u001b[0m Trial 37 finished with value: -1639773.5070063602 and parameters: {'colsample_bytree': 0.6078671466877379, 'learning_rate': 0.36666378822827916, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.00011975525252986182, 'reg_alpha': 5.860443040614633, 'sub_sample': 0.6204998408710736}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:14] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:15,447]\u001b[0m Trial 38 finished with value: -1805439.4433495807 and parameters: {'colsample_bytree': 0.8669334301306336, 'learning_rate': 0.23952656590336285, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'reg_lambda': 4.554753985188811e-07, 'reg_alpha': 4.813321489742179e-06, 'sub_sample': 0.7761829946167323}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:15,931]\u001b[0m Trial 39 finished with value: -1649661.371029141 and parameters: {'colsample_bytree': 0.5396817328799, 'learning_rate': 0.1513712031423987, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.9553446639101077e-05, 'reg_alpha': 0.0009057876987685045, 'sub_sample': 0.8830048664692323}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:15] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:16,322]\u001b[0m Trial 40 finished with value: -1753890.5542180808 and parameters: {'colsample_bytree': 0.808951564579382, 'learning_rate': 0.2832894711877642, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.6182713781070112, 'reg_alpha': 0.03001362070370327, 'sub_sample': 0.9555473275556607}. Best is trial 31 with value: -1619392.0882106135.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:16,948]\u001b[0m Trial 41 finished with value: -1618032.4717544264 and parameters: {'colsample_bytree': 0.7076956861834295, 'learning_rate': 0.10477887290225653, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 7.433544437216594e-08, 'reg_alpha': 19.166336004880616, 'sub_sample': 0.9657581937217371}. Best is trial 41 with value: -1618032.4717544264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:16] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:17,537]\u001b[0m Trial 42 finished with value: -1643090.1077952115 and parameters: {'colsample_bytree': 0.7066084219840294, 'learning_rate': 0.14667673205041948, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.6770222764695908e-07, 'reg_alpha': 70.73403077754703, 'sub_sample': 0.999369033694862}. Best is trial 41 with value: -1618032.4717544264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:17] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:18,448]\u001b[0m Trial 43 finished with value: -1721173.065665092 and parameters: {'colsample_bytree': 0.6251587362133227, 'learning_rate': 0.20657541029844828, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.558520912007146e-06, 'reg_alpha': 19.1970193003722, 'sub_sample': 0.8459951173666975}. Best is trial 41 with value: -1618032.4717544264.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:18] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:19,127]\u001b[0m Trial 44 finished with value: -1647185.3083878625 and parameters: {'colsample_bytree': 0.7451964641204392, 'learning_rate': 0.14559613371358393, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 9.748413068572739e-08, 'reg_alpha': 7.343856952887795, 'sub_sample': 0.9559607138952799}. Best is trial 41 with value: -1618032.4717544264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:19,567]\u001b[0m Trial 45 finished with value: -1771325.3770431213 and parameters: {'colsample_bytree': 0.5754487582530384, 'learning_rate': 0.8945406625549922, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 6.654835230015889e-07, 'reg_alpha': 0.006435946109688525, 'sub_sample': 0.9097175464589065}. Best is trial 41 with value: -1618032.4717544264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:19] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:20,186]\u001b[0m Trial 46 finished with value: -1612875.509499009 and parameters: {'colsample_bytree': 0.9189366823285986, 'learning_rate': 0.10653183337499816, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.7010048169555e-08, 'reg_alpha': 37.90008654122435, 'sub_sample': 0.8621658773688818}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:20,796]\u001b[0m Trial 47 finished with value: -1634102.9296076545 and parameters: {'colsample_bytree': 0.8483916054871645, 'learning_rate': 0.10019983371041366, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.126542641239118e-08, 'reg_alpha': 28.335964016176128, 'sub_sample': 0.8370613092779741}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:20] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:21,599]\u001b[0m Trial 48 finished with value: -1871708.9755168296 and parameters: {'colsample_bytree': 0.9352299601634946, 'learning_rate': 0.6119359298813309, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 2.0563215152053707e-06, 'reg_alpha': 66.91567948356588, 'sub_sample': 0.9697663645893911}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:21] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:22,713]\u001b[0m Trial 49 finished with value: -1731768.6193531537 and parameters: {'colsample_bytree': 0.9358477522821125, 'learning_rate': 0.13223105567765447, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 3.347171351577681e-08, 'reg_alpha': 0.5249290870512161, 'sub_sample': 0.8632426517711127}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:22] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:23,506]\u001b[0m Trial 50 finished with value: -1853863.8533641915 and parameters: {'colsample_bytree': 0.7821786203723561, 'learning_rate': 0.40221391628642694, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.2030235302562291e-08, 'reg_alpha': 1.4713173241277533, 'sub_sample': 0.7724425722738653}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:24,104]\u001b[0m Trial 51 finished with value: -1658157.3604117595 and parameters: {'colsample_bytree': 0.6823785598602905, 'learning_rate': 0.18338224842354434, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 8.185980964007767e-08, 'reg_alpha': 3.934320661567664, 'sub_sample': 0.8963878367954696}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:24,599]\u001b[0m Trial 52 finished with value: -1757711.639905809 and parameters: {'colsample_bytree': 0.44230475118607354, 'learning_rate': 0.23690500459298824, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 0.00030615983784079655, 'reg_alpha': 18.092273469035998, 'sub_sample': 0.9313013306170919}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:24] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:25,247]\u001b[0m Trial 53 finished with value: -1627815.710794212 and parameters: {'colsample_bytree': 0.5031637470005983, 'learning_rate': 0.13385204338515266, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0450045244391755, 'reg_alpha': 6.124809360933343e-05, 'sub_sample': 0.9797512678938087}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:25,796]\u001b[0m Trial 54 finished with value: -1650001.8417237422 and parameters: {'colsample_bytree': 0.37750189169828197, 'learning_rate': 0.13150697080719015, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0036748370321601667, 'reg_alpha': 3.9393769614403626e-05, 'sub_sample': 0.9790333231788273}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:25] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:26,470]\u001b[0m Trial 55 finished with value: -1629810.8431819726 and parameters: {'colsample_bytree': 0.9161813705901263, 'learning_rate': 0.10847909955159334, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.024468461095402554, 'reg_alpha': 3.2539939269471483e-06, 'sub_sample': 0.9597976936760689}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:27,061]\u001b[0m Trial 56 finished with value: -1653411.096311443 and parameters: {'colsample_bytree': 0.723428919222735, 'learning_rate': 0.21648776793266244, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.0102804491811907, 'reg_alpha': 0.2863582946571857, 'sub_sample': 0.9994700341351305}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:26] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:27,593]\u001b[0m Trial 57 finished with value: -1655459.5925868242 and parameters: {'colsample_bytree': 0.5088433597260625, 'learning_rate': 0.2786862596253089, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.001319223353755482, 'reg_alpha': 0.0003871121977365004, 'sub_sample': 0.8200553487100035}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:27] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:28,238]\u001b[0m Trial 58 finished with value: -1679048.058166995 and parameters: {'colsample_bytree': 0.9973790849247497, 'learning_rate': 0.1725970785206738, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.4120095872397132e-06, 'reg_alpha': 10.635286166603489, 'sub_sample': 0.7166648142898298}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:28,757]\u001b[0m Trial 59 finished with value: -1795414.7883217765 and parameters: {'colsample_bytree': 0.4429469441134969, 'learning_rate': 0.507327248706466, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 100, 'reg_lambda': 0.05857181326548293, 'reg_alpha': 47.90012337062002, 'sub_sample': 0.34083119335178436}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:29,436]\u001b[0m Trial 60 finished with value: -1693603.7157926154 and parameters: {'colsample_bytree': 0.5748451102156523, 'learning_rate': 0.33567488875964374, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.44230699904606796, 'reg_alpha': 1.0728757908488437e-05, 'sub_sample': 0.8798872816384813}. Best is trial 46 with value: -1612875.509499009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:29] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:30,115]\u001b[0m Trial 61 finished with value: -1612650.7827463835 and parameters: {'colsample_bytree': 0.9161634003213486, 'learning_rate': 0.1041875968158851, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.03144988488703807, 'reg_alpha': 2.9023523072167666e-06, 'sub_sample': 0.942197196161722}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:30,730]\u001b[0m Trial 62 finished with value: -1633706.6351070327 and parameters: {'colsample_bytree': 0.9144964181045143, 'learning_rate': 0.133122409588248, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 2.4265279547705387e-07, 'reg_alpha': 1.7452046370618764e-06, 'sub_sample': 0.9231415618305784}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:30] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:31,332]\u001b[0m Trial 63 finished with value: -1620835.3706765561 and parameters: {'colsample_bytree': 0.820093549537758, 'learning_rate': 0.10273174087787634, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 2.262412783526797, 'reg_alpha': 1.0622035533104419e-07, 'sub_sample': 0.9693643487230607}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:31,913]\u001b[0m Trial 64 finished with value: -1621731.7653877032 and parameters: {'colsample_bytree': 0.8412689569473183, 'learning_rate': 0.12995166660637608, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 3.3448877246978115, 'reg_alpha': 4.815775648979817e-08, 'sub_sample': 0.9715991648367506}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:31] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:32,501]\u001b[0m Trial 65 finished with value: -1625985.6665122465 and parameters: {'colsample_bytree': 0.83267277647489, 'learning_rate': 0.19612540633875522, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 2.4817610936450736, 'reg_alpha': 1.1032056718011091e-08, 'sub_sample': 0.9496867426681738}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:33,080]\u001b[0m Trial 66 finished with value: -1641033.0876255215 and parameters: {'colsample_bytree': 0.8194457461782345, 'learning_rate': 0.1019071838756652, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 3.4642189251955298, 'reg_alpha': 1.3242782534996638e-07, 'sub_sample': 0.8953324312826678}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:32] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:33,739]\u001b[0m Trial 67 finished with value: -1666740.267776124 and parameters: {'colsample_bytree': 0.8539637088567169, 'learning_rate': 0.6888237125593322, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 29.19458537213312, 'reg_alpha': 2.7702372928200125e-07, 'sub_sample': 0.47645265475881415}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:33] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:34,411]\u001b[0m Trial 68 finished with value: -1739623.1848819419 and parameters: {'colsample_bytree': 0.8999764509367977, 'learning_rate': 0.16616374087367258, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 100, 'reg_lambda': 2.176863090422535e-08, 'reg_alpha': 1.213666550740666e-07, 'sub_sample': 0.9242951100338134}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:34] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:35,189]\u001b[0m Trial 69 finished with value: -1733682.7247782443 and parameters: {'colsample_bytree': 0.7763020445438771, 'learning_rate': 0.1297752050175667, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 10.722817104727486, 'reg_alpha': 4.6566734765600123e-08, 'sub_sample': 0.8533047998074997}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:35,844]\u001b[0m Trial 70 finished with value: -1848636.4112558195 and parameters: {'colsample_bytree': 0.9523006847963217, 'learning_rate': 0.8173394595972612, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.8898542600431765, 'reg_alpha': 6.149311233364489e-07, 'sub_sample': 0.9678912855917151}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:35] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:36,426]\u001b[0m Trial 71 finished with value: -1630976.2686713068 and parameters: {'colsample_bytree': 0.8360191667971915, 'learning_rate': 0.18947621779387977, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 1.4871593005906345, 'reg_alpha': 1.6597734956545465e-08, 'sub_sample': 0.947658704031014}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:37,025]\u001b[0m Trial 72 finished with value: -1635518.9450760684 and parameters: {'colsample_bytree': 0.8877985652467617, 'learning_rate': 0.2018997814257389, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 4.985137489613799, 'reg_alpha': 1.0358093937571846e-08, 'sub_sample': 0.9699364434511006}. Best is trial 61 with value: -1612650.7827463835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:36] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:37,698]\u001b[0m Trial 73 finished with value: -1608022.21469974 and parameters: {'colsample_bytree': 0.7438278996789514, 'learning_rate': 0.10082309483804087, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.3875477159662404, 'reg_alpha': 4.8398232054175846e-08, 'sub_sample': 0.9308564054337892}. Best is trial 73 with value: -1608022.21469974.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:37] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:38,385]\u001b[0m Trial 74 finished with value: -1606688.3022375999 and parameters: {'colsample_bytree': 0.7349556938228837, 'learning_rate': 0.10239455781467538, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.49851978727692214, 'reg_alpha': 5.244646413914474e-08, 'sub_sample': 0.9077492000918596}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:38] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:39,083]\u001b[0m Trial 75 finished with value: -1722945.524112516 and parameters: {'colsample_bytree': 0.7369248713852796, 'learning_rate': 0.10003596154904822, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 7.548817013004857, 'reg_alpha': 5.72255262876056e-08, 'sub_sample': 0.9068902637629793}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:39,692]\u001b[0m Trial 76 finished with value: -1637948.945717692 and parameters: {'colsample_bytree': 0.8019330416294853, 'learning_rate': 0.15249110659810855, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.45155070184253815, 'reg_alpha': 3.85670852116009e-08, 'sub_sample': 0.8786790871269569}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:39] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:40,317]\u001b[0m Trial 77 finished with value: -1639691.369701304 and parameters: {'colsample_bytree': 0.7797034836019294, 'learning_rate': 0.12591828412917538, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.3745276984840678, 'reg_alpha': 2.8648280863621643e-07, 'sub_sample': 0.9207352999592101}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:40,877]\u001b[0m Trial 78 finished with value: -1656374.3885550012 and parameters: {'colsample_bytree': 0.6593443554901556, 'learning_rate': 0.16394472647476654, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 1.0644588718591257, 'reg_alpha': 3.472318500225021e-08, 'sub_sample': 0.8363628403678656}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:40] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:41,445]\u001b[0m Trial 79 finished with value: -1738177.957465975 and parameters: {'colsample_bytree': 0.7051216136312188, 'learning_rate': 0.2253256467739409, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 21.213612866108072, 'reg_alpha': 9.614486480079992e-08, 'sub_sample': 0.9962230269456571}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:42,066]\u001b[0m Trial 80 finished with value: -1688757.9934523422 and parameters: {'colsample_bytree': 0.872630471884527, 'learning_rate': 0.2556942156067171, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.2633796293257565, 'reg_alpha': 4.296594577820715e-07, 'sub_sample': 0.938492821861059}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:41] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:42,687]\u001b[0m Trial 81 finished with value: -1626850.0380703893 and parameters: {'colsample_bytree': 0.7594312299844539, 'learning_rate': 0.130724425234785, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 7.335386247755516e-08, 'reg_alpha': 2.145887668673227e-08, 'sub_sample': 0.9782774624377585}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:43,275]\u001b[0m Trial 82 finished with value: -1619512.2623081482 and parameters: {'colsample_bytree': 0.6964649300992214, 'learning_rate': 0.11755158165083146, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.0845298092658735, 'reg_alpha': 2.2136803330147614e-07, 'sub_sample': 0.8976014499406741}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:43,845]\u001b[0m Trial 83 finished with value: -1638616.1516458988 and parameters: {'colsample_bytree': 0.6938582029408371, 'learning_rate': 0.1571685007523142, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.6685053256832277, 'reg_alpha': 1.707992881243213e-06, 'sub_sample': 0.5617337364128074}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:43] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:44,403]\u001b[0m Trial 84 finished with value: -1628937.0101461513 and parameters: {'colsample_bytree': 0.6321291727733874, 'learning_rate': 0.1176964011063363, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.07268101322570969, 'reg_alpha': 1.7066277273515905e-07, 'sub_sample': 0.8672827778036983}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:44,984]\u001b[0m Trial 85 finished with value: -1645096.3492535413 and parameters: {'colsample_bytree': 0.7283114343027653, 'learning_rate': 0.17926255250263118, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.13127855984411102, 'reg_alpha': 6.76153646222986e-08, 'sub_sample': 0.788386732243927}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:45,706]\u001b[0m Trial 86 finished with value: -1677199.3810162595 and parameters: {'colsample_bytree': 0.8007559994873309, 'learning_rate': 0.14797396909396734, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.2110701764919994, 'reg_alpha': 2.0415954525978483e-08, 'sub_sample': 0.8996569804459974}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:45] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:46,153]\u001b[0m Trial 87 finished with value: -1649255.2682940238 and parameters: {'colsample_bytree': 0.6785558004183707, 'learning_rate': 0.1056417880629712, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.8545124796885271, 'reg_alpha': 2.0898346808620671e-07, 'sub_sample': 0.9324413227753234}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:46,767]\u001b[0m Trial 88 finished with value: -1663635.1473032925 and parameters: {'colsample_bytree': 0.9641341098043599, 'learning_rate': 0.1785714898601869, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 11.918816351676497, 'reg_alpha': 5.429542445114047e-07, 'sub_sample': 0.7535032562571254}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:46] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:47,182]\u001b[0m Trial 89 finished with value: -1943773.729074764 and parameters: {'colsample_bytree': 0.13024111899933277, 'learning_rate': 0.12115582153043228, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.041184200039792715, 'reg_alpha': 35.92762044017358, 'sub_sample': 0.951895327492133}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:47,805]\u001b[0m Trial 90 finished with value: -1690790.0695120895 and parameters: {'colsample_bytree': 0.7450808952920848, 'learning_rate': 0.21956027726712662, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 5.077125201126403e-07, 'reg_alpha': 6.09667466144987e-08, 'sub_sample': 0.2226876426434799}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:47] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:48,405]\u001b[0m Trial 91 finished with value: -1626286.5887454753 and parameters: {'colsample_bytree': 0.7134281479187163, 'learning_rate': 0.15051133286530124, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.005560490247354915, 'reg_alpha': 3.402017789980377, 'sub_sample': 0.9790616400702193}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:48] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:49,051]\u001b[0m Trial 92 finished with value: -1627299.0491010803 and parameters: {'colsample_bytree': 0.8580375925975341, 'learning_rate': 0.12350885249174276, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.09065829179331279, 'reg_alpha': 1.073299838355099e-06, 'sub_sample': 0.8920273783901591}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:49,654]\u001b[0m Trial 93 finished with value: -1621576.436879815 and parameters: {'colsample_bytree': 0.650533036120481, 'learning_rate': 0.10155397983949352, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.013629659167614785, 'reg_alpha': 7.936843709989381e-08, 'sub_sample': 0.9087339029829048}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:49] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:50,216]\u001b[0m Trial 94 finished with value: -1629243.8039544385 and parameters: {'colsample_bytree': 0.6493838370794852, 'learning_rate': 0.10173780499720818, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.017238938696074752, 'reg_alpha': 8.724755927877599e-08, 'sub_sample': 0.9099799866269078}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:50,812]\u001b[0m Trial 95 finished with value: -1630716.4806225973 and parameters: {'colsample_bytree': 0.7615973295040847, 'learning_rate': 0.14211582946947737, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 2.7058752419201428e-08, 'reg_alpha': 2.2887804220922282e-07, 'sub_sample': 0.8289529675216644}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:50] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:51,397]\u001b[0m Trial 96 finished with value: -1608994.3383141735 and parameters: {'colsample_bytree': 0.6145887096127438, 'learning_rate': 0.16982803673228763, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 2.256315600791923, 'reg_alpha': 2.9246076611767958e-08, 'sub_sample': 0.8583713809741751}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:51,987]\u001b[0m Trial 97 finished with value: -1644737.370024278 and parameters: {'colsample_bytree': 0.6135616711177545, 'learning_rate': 0.16627377913592115, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 0.009500899717023744, 'reg_alpha': 10.410646222896986, 'sub_sample': 0.8585634412389331}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:51] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:52,553]\u001b[0m Trial 98 finished with value: -1667385.3791905441 and parameters: {'colsample_bytree': 0.6650004582084224, 'learning_rate': 0.2023095514497582, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'reg_lambda': 0.03477800324292428, 'reg_alpha': 3.0025852005180254e-08, 'sub_sample': 0.7982833825105369}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n",
      "C:\\Users\\jiexi\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:560: UserWarning: The distribution is specified by [100, 300] and step=500, but the range is not divisible by `step`. It will be replaced by [100, 100].\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "\u001b[32m[I 2021-12-15 02:14:52,994]\u001b[0m Trial 99 finished with value: -1644036.4814159824 and parameters: {'colsample_bytree': 0.602737123517686, 'learning_rate': 0.11794097912020053, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 100, 'reg_lambda': 5.517929715058309e-08, 'reg_alpha': 1.5974262092096736e-08, 'sub_sample': 0.872941078542724}. Best is trial 74 with value: -1606688.3022375999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[02:14:52] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def xgb999(search):\n",
    "    colsample_bytree = search.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    learning_rate = search.suggest_float(\"learning_rate\", 0.1, 1.0) \n",
    "    max_depth = search.suggest_int(\"max_depth\",1, 5)\n",
    "    min_child_weight = search.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    n_estimator = search.suggest_int(\"n_estimators\", 100, 300, 500)\n",
    "    reg_lambda = search.suggest_loguniform(\"reg_lambda\", 1e-8, 100)\n",
    "    reg_alpha = search.suggest_loguniform(\"reg_alpha\", 1e-8, 100)\n",
    "    sub_sample = search.suggest_float(\"sub_sample\", 0.1, 1.0)\n",
    "    \n",
    "    model = XGBRegressor(random_state = 42,\n",
    "                         colsample_bytree = colsample_bytree,\n",
    "                         learning_rate = learning_rate,\n",
    "                         max_depth = max_depth,\n",
    "                         min_child_weight = min_child_weight,\n",
    "                         n_estimator = n_estimator,\n",
    "                         reg_lambda = reg_lambda, \n",
    "                         reg_alpha = reg_alpha,\n",
    "                         sub_sample = sub_sample,\n",
    "                         n_jobs = -1\n",
    "                        )\n",
    "    \n",
    "    score = cross_val_score(model, Z999_train, y999_train, scoring = 'neg_root_mean_squared_error', cv = 5, verbose = 1)\n",
    "    mean_score = score.mean()\n",
    "    std_score = score.std()\n",
    "    \n",
    "    accuracy = mean_score - std_score\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed =42))\n",
    "study.optimize(xgb999, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "49ce7635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7349556938228837,\n",
       " 'learning_rate': 0.10239455781467538,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 100,\n",
       " 'reg_lambda': 0.49851978727692214,\n",
       " 'reg_alpha': 5.244646413914474e-08,\n",
       " 'sub_sample': 0.9077492000918596}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "33d209aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1606688.3022375999"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "940edae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:18:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7349556938228837,\n",
       "             enable_categorical=False, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.10239455781467538,\n",
       "             max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=5.244646413914474e-08, reg_lambda=0.49851978727692214,\n",
       "             scale_pos_weight=1, sub_sample=0.9077492000918596, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB999 = XGBRegressor(colsample_bytree= 0.7349556938228837, learning_rate=0.10239455781467538, max_depth= 3 , min_child_weight= 1, n_estimators= 100,\n",
    "reg_alpha= 5.244646413914474e-08, reg_lambda= 0.49851978727692214, sub_sample=  0.9077492000918596)\n",
    "XGB999.fit(Z999_train, y999_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a7e5acef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443302887504351"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB999.score(Z999_train, y999_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b61d6f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8796635414280715"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB999.score(Z999_test, y999_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dcbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9656221",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB999.score(Z999_train, y999_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e074184",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB999.score(Z999_test, y999_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af27ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd7048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726421fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408d7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
